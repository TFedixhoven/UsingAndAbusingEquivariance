Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=11, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2556,                   Accuracy: 260/2000.0 (13.00%)



-= Testing valid =-
Test set: Average loss: 3.5622,                   Accuracy: 227/2000.0 (11.35%)



-= Testing valid =-
Test set: Average loss: 0.5519,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.3758,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2241,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1916,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1476,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1643,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 10 train accuracy: 96.44%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 20 train accuracy: 97.89%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 98.82%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 98.74%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 99.05%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0759,                   Accuracy: 58660/60000 (97.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1222,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2385,                   Accuracy: 55535/60000 (92.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4857,                   Accuracy: 51058/60000 (85.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7489,                   Accuracy: 46456/60000 (77.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7938,                   Accuracy: 45548/60000 (75.91%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5248,                   Accuracy: 50266/60000 (83.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2462,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1018,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0759,                   Accuracy: 58660/60000 (97.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1222,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2385,                   Accuracy: 55535/60000 (92.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4857,                   Accuracy: 51058/60000 (85.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7489,                   Accuracy: 46456/60000 (77.43%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7938,                   Accuracy: 45548/60000 (75.91%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5248,                   Accuracy: 50266/60000 (83.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2462,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1018,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0759,                   Accuracy: 58660/60000 (97.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1222,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2385,                   Accuracy: 55535/60000 (92.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4857,                   Accuracy: 51058/60000 (85.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7489,                   Accuracy: 46456/60000 (77.43%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7938,                   Accuracy: 45548/60000 (75.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5248,                   Accuracy: 50266/60000 (83.78%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2462,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1018,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0759,                   Accuracy: 58660/60000 (97.77%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1222,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2385,                   Accuracy: 55535/60000 (92.56%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4857,                   Accuracy: 51058/60000 (85.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7489,                   Accuracy: 46456/60000 (77.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7938,                   Accuracy: 45548/60000 (75.91%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5248,                   Accuracy: 50266/60000 (83.78%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2462,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1018,                   Accuracy: 58123/60000 (96.87%)
{0: tensor(97.7667), 10: tensor(96.2400), 20: tensor(92.5583), 30: tensor(85.0967), 40: tensor(77.4267), 50: tensor(75.9133), 60: tensor(83.7767), 70: tensor(92.3800), 80: tensor(96.8717), 90: tensor(97.7667), 100: tensor(96.2400), 110: tensor(92.5583), 120: tensor(85.0967), 130: tensor(77.4267), 140: tensor(75.9133), 150: tensor(83.7767), 160: tensor(92.3800), 170: tensor(96.8717), 180: tensor(97.7667), 190: tensor(96.2400), 200: tensor(92.5583), 210: tensor(85.0967), 220: tensor(77.4267), 230: tensor(75.9133), 240: tensor(83.7767), 250: tensor(92.3800), 260: tensor(96.8717), 270: tensor(97.7667), 280: tensor(96.2400), 290: tensor(92.5583), 300: tensor(85.0967), 310: tensor(77.4267), 320: tensor(75.9133), 330: tensor(83.7767), 340: tensor(92.3800), 350: tensor(96.8717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=12, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4735,                   Accuracy: 424/2000.0 (21.20%)



-= Testing valid =-
Test set: Average loss: 1.0609,                   Accuracy: 1300/2000.0 (65.00%)



-= Testing valid =-
Test set: Average loss: 0.6639,                   Accuracy: 1554/2000.0 (77.70%)



-= Testing valid =-
Test set: Average loss: 0.3803,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.2229,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.3070,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.1406,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1718,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 10 train accuracy: 96.40%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 20 train accuracy: 97.90%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 30 train accuracy: 98.41%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 98.74%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 50 train accuracy: 98.86%, valid accuracy 98.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0821,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1307,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2742,                   Accuracy: 54981/60000 (91.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5861,                   Accuracy: 49097/60000 (81.83%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9143,                   Accuracy: 43556/60000 (72.59%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0198,                   Accuracy: 42148/60000 (70.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7186,                   Accuracy: 47161/60000 (78.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3701,                   Accuracy: 53399/60000 (89.00%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1453,                   Accuracy: 57439/60000 (95.73%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0821,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1307,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2742,                   Accuracy: 54981/60000 (91.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5861,                   Accuracy: 49097/60000 (81.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9143,                   Accuracy: 43556/60000 (72.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0198,                   Accuracy: 42148/60000 (70.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7186,                   Accuracy: 47161/60000 (78.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3701,                   Accuracy: 53399/60000 (89.00%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1453,                   Accuracy: 57439/60000 (95.73%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0821,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1307,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2742,                   Accuracy: 54981/60000 (91.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5861,                   Accuracy: 49097/60000 (81.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9143,                   Accuracy: 43556/60000 (72.59%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0198,                   Accuracy: 42148/60000 (70.25%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7186,                   Accuracy: 47161/60000 (78.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3701,                   Accuracy: 53399/60000 (89.00%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1453,                   Accuracy: 57439/60000 (95.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0821,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1307,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2742,                   Accuracy: 54981/60000 (91.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5861,                   Accuracy: 49097/60000 (81.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9143,                   Accuracy: 43556/60000 (72.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0198,                   Accuracy: 42148/60000 (70.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7186,                   Accuracy: 47161/60000 (78.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3701,                   Accuracy: 53399/60000 (89.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1453,                   Accuracy: 57439/60000 (95.73%)
{0: tensor(97.5717), 10: tensor(96.0550), 20: tensor(91.6350), 30: tensor(81.8283), 40: tensor(72.5933), 50: tensor(70.2467), 60: tensor(78.6017), 70: tensor(88.9983), 80: tensor(95.7317), 90: tensor(97.5717), 100: tensor(96.0550), 110: tensor(91.6350), 120: tensor(81.8283), 130: tensor(72.5933), 140: tensor(70.2467), 150: tensor(78.6017), 160: tensor(88.9983), 170: tensor(95.7317), 180: tensor(97.5717), 190: tensor(96.0550), 200: tensor(91.6350), 210: tensor(81.8283), 220: tensor(72.5933), 230: tensor(70.2467), 240: tensor(78.6017), 250: tensor(88.9983), 260: tensor(95.7317), 270: tensor(97.5717), 280: tensor(96.0550), 290: tensor(91.6350), 300: tensor(81.8283), 310: tensor(72.5933), 320: tensor(70.2467), 330: tensor(78.6017), 340: tensor(88.9983), 350: tensor(95.7317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=13, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.6212,                   Accuracy: 250/2000.0 (12.50%)



-= Testing valid =-
Test set: Average loss: 1.7660,                   Accuracy: 717/2000.0 (35.85%)



-= Testing valid =-
Test set: Average loss: 0.7700,                   Accuracy: 1434/2000.0 (71.70%)



-= Testing valid =-
Test set: Average loss: 0.3457,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.3947,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.2451,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1948,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1825,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1805,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1593,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 10 train accuracy: 96.09%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 98.03%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 98.64%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 98.88%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.01%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0662,                   Accuracy: 58780/60000 (97.97%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1165,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2363,                   Accuracy: 55753/60000 (92.92%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5286,                   Accuracy: 50933/60000 (84.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7889,                   Accuracy: 46048/60000 (76.75%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8472,                   Accuracy: 44655/60000 (74.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5561,                   Accuracy: 49622/60000 (82.70%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2507,                   Accuracy: 55276/60000 (92.13%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1009,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0662,                   Accuracy: 58780/60000 (97.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1165,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2363,                   Accuracy: 55753/60000 (92.92%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5286,                   Accuracy: 50933/60000 (84.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7889,                   Accuracy: 46048/60000 (76.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8472,                   Accuracy: 44655/60000 (74.43%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5561,                   Accuracy: 49622/60000 (82.70%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2507,                   Accuracy: 55276/60000 (92.13%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1009,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0662,                   Accuracy: 58780/60000 (97.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1165,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2363,                   Accuracy: 55753/60000 (92.92%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5286,                   Accuracy: 50933/60000 (84.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7889,                   Accuracy: 46048/60000 (76.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8472,                   Accuracy: 44655/60000 (74.43%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5561,                   Accuracy: 49622/60000 (82.70%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2507,                   Accuracy: 55276/60000 (92.13%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1009,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0662,                   Accuracy: 58780/60000 (97.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1165,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2363,                   Accuracy: 55753/60000 (92.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5286,                   Accuracy: 50933/60000 (84.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7889,                   Accuracy: 46048/60000 (76.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8472,                   Accuracy: 44655/60000 (74.43%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5561,                   Accuracy: 49622/60000 (82.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2507,                   Accuracy: 55276/60000 (92.13%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1009,                   Accuracy: 58195/60000 (96.99%)
{0: tensor(97.9667), 10: tensor(96.4683), 20: tensor(92.9217), 30: tensor(84.8883), 40: tensor(76.7467), 50: tensor(74.4250), 60: tensor(82.7033), 70: tensor(92.1267), 80: tensor(96.9917), 90: tensor(97.9667), 100: tensor(96.4683), 110: tensor(92.9217), 120: tensor(84.8883), 130: tensor(76.7467), 140: tensor(74.4250), 150: tensor(82.7033), 160: tensor(92.1267), 170: tensor(96.9917), 180: tensor(97.9667), 190: tensor(96.4683), 200: tensor(92.9217), 210: tensor(84.8883), 220: tensor(76.7467), 230: tensor(74.4250), 240: tensor(82.7033), 250: tensor(92.1267), 260: tensor(96.9917), 270: tensor(97.9667), 280: tensor(96.4683), 290: tensor(92.9217), 300: tensor(84.8883), 310: tensor(76.7467), 320: tensor(74.4250), 330: tensor(82.7033), 340: tensor(92.1267), 350: tensor(96.9917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=14, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2421,                   Accuracy: 530/2000.0 (26.50%)



-= Testing valid =-
Test set: Average loss: 1.8570,                   Accuracy: 715/2000.0 (35.75%)



-= Testing valid =-
Test set: Average loss: 0.7930,                   Accuracy: 1452/2000.0 (72.60%)



-= Testing valid =-
Test set: Average loss: 0.2052,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2392,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2007,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.5185,                   Accuracy: 1638/2000.0 (81.90%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1707,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 10 train accuracy: 96.19%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 98.05%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 98.65%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 40 train accuracy: 98.97%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.09%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0748,                   Accuracy: 58702/60000 (97.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1307,                   Accuracy: 57656/60000 (96.09%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2616,                   Accuracy: 55298/60000 (92.16%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5930,                   Accuracy: 49503/60000 (82.50%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9750,                   Accuracy: 43283/60000 (72.14%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0716,                   Accuracy: 41895/60000 (69.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7003,                   Accuracy: 47752/60000 (79.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3029,                   Accuracy: 54543/60000 (90.90%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1200,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0748,                   Accuracy: 58702/60000 (97.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1307,                   Accuracy: 57656/60000 (96.09%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2616,                   Accuracy: 55298/60000 (92.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5930,                   Accuracy: 49503/60000 (82.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9750,                   Accuracy: 43283/60000 (72.14%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0716,                   Accuracy: 41895/60000 (69.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7003,                   Accuracy: 47752/60000 (79.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3029,                   Accuracy: 54543/60000 (90.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1200,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0748,                   Accuracy: 58702/60000 (97.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1307,                   Accuracy: 57656/60000 (96.09%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2616,                   Accuracy: 55298/60000 (92.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5930,                   Accuracy: 49503/60000 (82.50%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9750,                   Accuracy: 43283/60000 (72.14%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0716,                   Accuracy: 41895/60000 (69.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7003,                   Accuracy: 47752/60000 (79.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3029,                   Accuracy: 54543/60000 (90.90%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1200,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0748,                   Accuracy: 58702/60000 (97.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1307,                   Accuracy: 57656/60000 (96.09%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2616,                   Accuracy: 55298/60000 (92.16%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5930,                   Accuracy: 49503/60000 (82.50%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9750,                   Accuracy: 43283/60000 (72.14%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0716,                   Accuracy: 41895/60000 (69.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7003,                   Accuracy: 47752/60000 (79.59%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3029,                   Accuracy: 54543/60000 (90.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1200,                   Accuracy: 57835/60000 (96.39%)
{0: tensor(97.8367), 10: tensor(96.0933), 20: tensor(92.1633), 30: tensor(82.5050), 40: tensor(72.1383), 50: tensor(69.8250), 60: tensor(79.5867), 70: tensor(90.9050), 80: tensor(96.3917), 90: tensor(97.8367), 100: tensor(96.0933), 110: tensor(92.1633), 120: tensor(82.5050), 130: tensor(72.1383), 140: tensor(69.8250), 150: tensor(79.5867), 160: tensor(90.9050), 170: tensor(96.3917), 180: tensor(97.8367), 190: tensor(96.0933), 200: tensor(92.1633), 210: tensor(82.5050), 220: tensor(72.1383), 230: tensor(69.8250), 240: tensor(79.5867), 250: tensor(90.9050), 260: tensor(96.3917), 270: tensor(97.8367), 280: tensor(96.0933), 290: tensor(92.1633), 300: tensor(82.5050), 310: tensor(72.1383), 320: tensor(69.8250), 330: tensor(79.5867), 340: tensor(90.9050), 350: tensor(96.3917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=15, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4626,                   Accuracy: 566/2000.0 (28.30%)



-= Testing valid =-
Test set: Average loss: 1.5063,                   Accuracy: 896/2000.0 (44.80%)



-= Testing valid =-
Test set: Average loss: 0.8120,                   Accuracy: 1431/2000.0 (71.55%)



-= Testing valid =-
Test set: Average loss: 0.4890,                   Accuracy: 1677/2000.0 (83.85%)



-= Testing valid =-
Test set: Average loss: 0.3768,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.1393,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.2579,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.4839,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.2060,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 10 train accuracy: 96.90%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 98.05%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 98.82%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 98.99%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.18%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0719,                   Accuracy: 58761/60000 (97.93%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1257,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2532,                   Accuracy: 55648/60000 (92.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5452,                   Accuracy: 51007/60000 (85.01%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9253,                   Accuracy: 45311/60000 (75.52%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9641,                   Accuracy: 44209/60000 (73.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6180,                   Accuracy: 49100/60000 (81.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2976,                   Accuracy: 54617/60000 (91.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1228,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0719,                   Accuracy: 58761/60000 (97.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1257,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2532,                   Accuracy: 55648/60000 (92.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5452,                   Accuracy: 51007/60000 (85.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9253,                   Accuracy: 45311/60000 (75.52%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9641,                   Accuracy: 44209/60000 (73.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6180,                   Accuracy: 49100/60000 (81.83%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2976,                   Accuracy: 54617/60000 (91.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1228,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0719,                   Accuracy: 58761/60000 (97.93%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1257,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2532,                   Accuracy: 55648/60000 (92.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5452,                   Accuracy: 51007/60000 (85.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9253,                   Accuracy: 45311/60000 (75.52%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9641,                   Accuracy: 44209/60000 (73.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6180,                   Accuracy: 49100/60000 (81.83%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2976,                   Accuracy: 54617/60000 (91.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1228,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0719,                   Accuracy: 58761/60000 (97.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1257,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2532,                   Accuracy: 55648/60000 (92.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5452,                   Accuracy: 51007/60000 (85.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9253,                   Accuracy: 45311/60000 (75.52%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9641,                   Accuracy: 44209/60000 (73.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6180,                   Accuracy: 49100/60000 (81.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2976,                   Accuracy: 54617/60000 (91.03%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1228,                   Accuracy: 57772/60000 (96.29%)
{0: tensor(97.9350), 10: tensor(96.3633), 20: tensor(92.7467), 30: tensor(85.0117), 40: tensor(75.5183), 50: tensor(73.6817), 60: tensor(81.8333), 70: tensor(91.0283), 80: tensor(96.2867), 90: tensor(97.9350), 100: tensor(96.3633), 110: tensor(92.7467), 120: tensor(85.0117), 130: tensor(75.5183), 140: tensor(73.6817), 150: tensor(81.8333), 160: tensor(91.0283), 170: tensor(96.2867), 180: tensor(97.9350), 190: tensor(96.3633), 200: tensor(92.7467), 210: tensor(85.0117), 220: tensor(75.5183), 230: tensor(73.6817), 240: tensor(81.8333), 250: tensor(91.0283), 260: tensor(96.2867), 270: tensor(97.9350), 280: tensor(96.3633), 290: tensor(92.7467), 300: tensor(85.0117), 310: tensor(75.5183), 320: tensor(73.6817), 330: tensor(81.8333), 340: tensor(91.0283), 350: tensor(96.2867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=16, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9401,                   Accuracy: 421/2000.0 (21.05%)



-= Testing valid =-
Test set: Average loss: 1.6056,                   Accuracy: 789/2000.0 (39.45%)



-= Testing valid =-
Test set: Average loss: 3.1969,                   Accuracy: 580/2000.0 (29.00%)



-= Testing valid =-
Test set: Average loss: 0.6633,                   Accuracy: 1529/2000.0 (76.45%)



-= Testing valid =-
Test set: Average loss: 0.2534,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1938,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.2305,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.3089,                   Accuracy: 1819/2000.0 (90.95%)



Epoch 10 train accuracy: 96.57%, valid accuracy 90.95%
-= Testing valid =-
Test set: Average loss: 0.1692,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 20 train accuracy: 98.22%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 98.56%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 99.00%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 99.09%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0755,                   Accuracy: 58646/60000 (97.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1358,                   Accuracy: 57529/60000 (95.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2738,                   Accuracy: 55141/60000 (91.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6182,                   Accuracy: 49467/60000 (82.44%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8806,                   Accuracy: 44956/60000 (74.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8450,                   Accuracy: 45108/60000 (75.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5125,                   Accuracy: 50516/60000 (84.19%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2301,                   Accuracy: 55759/60000 (92.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1040,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0755,                   Accuracy: 58646/60000 (97.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1358,                   Accuracy: 57529/60000 (95.88%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2738,                   Accuracy: 55141/60000 (91.90%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6182,                   Accuracy: 49467/60000 (82.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8806,                   Accuracy: 44956/60000 (74.93%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8450,                   Accuracy: 45108/60000 (75.18%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5125,                   Accuracy: 50516/60000 (84.19%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2301,                   Accuracy: 55759/60000 (92.93%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1040,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0755,                   Accuracy: 58646/60000 (97.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1358,                   Accuracy: 57529/60000 (95.88%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2738,                   Accuracy: 55141/60000 (91.90%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6182,                   Accuracy: 49467/60000 (82.44%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8806,                   Accuracy: 44956/60000 (74.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8450,                   Accuracy: 45108/60000 (75.18%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5125,                   Accuracy: 50516/60000 (84.19%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2301,                   Accuracy: 55759/60000 (92.93%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1040,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0755,                   Accuracy: 58646/60000 (97.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1358,                   Accuracy: 57529/60000 (95.88%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2738,                   Accuracy: 55141/60000 (91.90%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6182,                   Accuracy: 49467/60000 (82.44%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8806,                   Accuracy: 44956/60000 (74.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8450,                   Accuracy: 45108/60000 (75.18%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5125,                   Accuracy: 50516/60000 (84.19%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2301,                   Accuracy: 55759/60000 (92.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1040,                   Accuracy: 58129/60000 (96.88%)
{0: tensor(97.7433), 10: tensor(95.8817), 20: tensor(91.9017), 30: tensor(82.4450), 40: tensor(74.9267), 50: tensor(75.1800), 60: tensor(84.1933), 70: tensor(92.9317), 80: tensor(96.8817), 90: tensor(97.7433), 100: tensor(95.8817), 110: tensor(91.9017), 120: tensor(82.4450), 130: tensor(74.9267), 140: tensor(75.1800), 150: tensor(84.1933), 160: tensor(92.9317), 170: tensor(96.8817), 180: tensor(97.7433), 190: tensor(95.8817), 200: tensor(91.9017), 210: tensor(82.4450), 220: tensor(74.9267), 230: tensor(75.1800), 240: tensor(84.1933), 250: tensor(92.9317), 260: tensor(96.8817), 270: tensor(97.7433), 280: tensor(95.8817), 290: tensor(91.9017), 300: tensor(82.4450), 310: tensor(74.9267), 320: tensor(75.1800), 330: tensor(84.1933), 340: tensor(92.9317), 350: tensor(96.8817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=17, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.3239,                   Accuracy: 308/2000.0 (15.40%)



-= Testing valid =-
Test set: Average loss: 2.3563,                   Accuracy: 528/2000.0 (26.40%)



-= Testing valid =-
Test set: Average loss: 2.5138,                   Accuracy: 524/2000.0 (26.20%)



-= Testing valid =-
Test set: Average loss: 0.4128,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.2284,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.3640,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.2696,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.2681,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 10 train accuracy: 96.56%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 20 train accuracy: 98.22%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 30 train accuracy: 98.80%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 40 train accuracy: 99.10%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 50 train accuracy: 99.35%, valid accuracy 98.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0755,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1170,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2539,                   Accuracy: 55451/60000 (92.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5761,                   Accuracy: 49989/60000 (83.32%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9016,                   Accuracy: 44549/60000 (74.25%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9389,                   Accuracy: 44053/60000 (73.42%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6242,                   Accuracy: 49318/60000 (82.20%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2963,                   Accuracy: 54849/60000 (91.42%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1204,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0755,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1170,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2539,                   Accuracy: 55451/60000 (92.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5761,                   Accuracy: 49989/60000 (83.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9016,                   Accuracy: 44549/60000 (74.25%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9389,                   Accuracy: 44053/60000 (73.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6242,                   Accuracy: 49318/60000 (82.20%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2963,                   Accuracy: 54849/60000 (91.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1204,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0755,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1170,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2539,                   Accuracy: 55451/60000 (92.42%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5761,                   Accuracy: 49989/60000 (83.32%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9016,                   Accuracy: 44549/60000 (74.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9389,                   Accuracy: 44053/60000 (73.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6242,                   Accuracy: 49318/60000 (82.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2963,                   Accuracy: 54849/60000 (91.42%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1204,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0755,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1170,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2539,                   Accuracy: 55451/60000 (92.42%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5761,                   Accuracy: 49989/60000 (83.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9016,                   Accuracy: 44549/60000 (74.25%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9389,                   Accuracy: 44053/60000 (73.42%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6242,                   Accuracy: 49318/60000 (82.20%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2963,                   Accuracy: 54849/60000 (91.42%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1204,                   Accuracy: 57861/60000 (96.43%)
{0: tensor(97.7567), 10: tensor(96.4450), 20: tensor(92.4183), 30: tensor(83.3150), 40: tensor(74.2483), 50: tensor(73.4217), 60: tensor(82.1967), 70: tensor(91.4150), 80: tensor(96.4350), 90: tensor(97.7567), 100: tensor(96.4450), 110: tensor(92.4183), 120: tensor(83.3150), 130: tensor(74.2483), 140: tensor(73.4217), 150: tensor(82.1967), 160: tensor(91.4150), 170: tensor(96.4350), 180: tensor(97.7567), 190: tensor(96.4450), 200: tensor(92.4183), 210: tensor(83.3150), 220: tensor(74.2483), 230: tensor(73.4217), 240: tensor(82.1967), 250: tensor(91.4150), 260: tensor(96.4350), 270: tensor(97.7567), 280: tensor(96.4450), 290: tensor(92.4183), 300: tensor(83.3150), 310: tensor(74.2483), 320: tensor(73.4217), 330: tensor(82.1967), 340: tensor(91.4150), 350: tensor(96.4350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=18, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6924,                   Accuracy: 379/2000.0 (18.95%)



-= Testing valid =-
Test set: Average loss: 1.9184,                   Accuracy: 761/2000.0 (38.05%)



-= Testing valid =-
Test set: Average loss: 1.5769,                   Accuracy: 793/2000.0 (39.65%)



-= Testing valid =-
Test set: Average loss: 0.4824,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.3848,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.1793,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.2513,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.1522,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1587,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1813,                   Accuracy: 1888/2000.0 (94.40%)



Epoch 10 train accuracy: 95.99%, valid accuracy 94.40%
-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1450,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 20 train accuracy: 97.94%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 98.53%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 99.00%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 98.96%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0765,                   Accuracy: 58664/60000 (97.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1234,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2512,                   Accuracy: 55683/60000 (92.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5655,                   Accuracy: 50890/60000 (84.82%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8423,                   Accuracy: 46521/60000 (77.54%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8147,                   Accuracy: 46603/60000 (77.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5428,                   Accuracy: 50590/60000 (84.32%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2612,                   Accuracy: 55322/60000 (92.20%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1095,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0765,                   Accuracy: 58664/60000 (97.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1234,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2512,                   Accuracy: 55683/60000 (92.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5655,                   Accuracy: 50890/60000 (84.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8423,                   Accuracy: 46521/60000 (77.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8147,                   Accuracy: 46603/60000 (77.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5428,                   Accuracy: 50590/60000 (84.32%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2612,                   Accuracy: 55322/60000 (92.20%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1095,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0765,                   Accuracy: 58664/60000 (97.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1234,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2512,                   Accuracy: 55683/60000 (92.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5655,                   Accuracy: 50890/60000 (84.82%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8423,                   Accuracy: 46521/60000 (77.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8147,                   Accuracy: 46603/60000 (77.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5428,                   Accuracy: 50590/60000 (84.32%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2612,                   Accuracy: 55322/60000 (92.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1095,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0765,                   Accuracy: 58664/60000 (97.77%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1234,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2512,                   Accuracy: 55683/60000 (92.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5655,                   Accuracy: 50890/60000 (84.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8423,                   Accuracy: 46521/60000 (77.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8147,                   Accuracy: 46603/60000 (77.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5428,                   Accuracy: 50590/60000 (84.32%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2612,                   Accuracy: 55322/60000 (92.20%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1095,                   Accuracy: 57987/60000 (96.64%)
{0: tensor(97.7733), 10: tensor(96.3600), 20: tensor(92.8050), 30: tensor(84.8167), 40: tensor(77.5350), 50: tensor(77.6717), 60: tensor(84.3167), 70: tensor(92.2033), 80: tensor(96.6450), 90: tensor(97.7733), 100: tensor(96.3600), 110: tensor(92.8050), 120: tensor(84.8167), 130: tensor(77.5350), 140: tensor(77.6717), 150: tensor(84.3167), 160: tensor(92.2033), 170: tensor(96.6450), 180: tensor(97.7733), 190: tensor(96.3600), 200: tensor(92.8050), 210: tensor(84.8167), 220: tensor(77.5350), 230: tensor(77.6717), 240: tensor(84.3167), 250: tensor(92.2033), 260: tensor(96.6450), 270: tensor(97.7733), 280: tensor(96.3600), 290: tensor(92.8050), 300: tensor(84.8167), 310: tensor(77.5350), 320: tensor(77.6717), 330: tensor(84.3167), 340: tensor(92.2033), 350: tensor(96.6450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=19, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8121,                   Accuracy: 363/2000.0 (18.15%)



-= Testing valid =-
Test set: Average loss: 1.4504,                   Accuracy: 973/2000.0 (48.65%)



-= Testing valid =-
Test set: Average loss: 2.6479,                   Accuracy: 680/2000.0 (34.00%)



-= Testing valid =-
Test set: Average loss: 0.3522,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3004,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2455,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2090,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1794,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1578,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1925,                   Accuracy: 1882/2000.0 (94.10%)



Epoch 10 train accuracy: 95.84%, valid accuracy 94.10%
-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 20 train accuracy: 97.81%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 30 train accuracy: 98.60%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 98.71%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 98.99%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0766,                   Accuracy: 58700/60000 (97.83%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1266,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2774,                   Accuracy: 55185/60000 (91.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5839,                   Accuracy: 50003/60000 (83.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8953,                   Accuracy: 44619/60000 (74.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9313,                   Accuracy: 43723/60000 (72.87%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5956,                   Accuracy: 49431/60000 (82.39%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2712,                   Accuracy: 55096/60000 (91.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1180,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0766,                   Accuracy: 58700/60000 (97.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1266,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2774,                   Accuracy: 55185/60000 (91.97%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5839,                   Accuracy: 50003/60000 (83.34%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8953,                   Accuracy: 44619/60000 (74.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9313,                   Accuracy: 43723/60000 (72.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5956,                   Accuracy: 49431/60000 (82.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2712,                   Accuracy: 55096/60000 (91.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1180,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0766,                   Accuracy: 58700/60000 (97.83%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1266,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2774,                   Accuracy: 55185/60000 (91.97%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5839,                   Accuracy: 50003/60000 (83.34%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8953,                   Accuracy: 44619/60000 (74.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9313,                   Accuracy: 43723/60000 (72.87%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5956,                   Accuracy: 49431/60000 (82.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2712,                   Accuracy: 55096/60000 (91.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1180,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0766,                   Accuracy: 58700/60000 (97.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1266,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2774,                   Accuracy: 55185/60000 (91.97%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5839,                   Accuracy: 50003/60000 (83.34%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8953,                   Accuracy: 44620/60000 (74.37%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9313,                   Accuracy: 43723/60000 (72.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5956,                   Accuracy: 49431/60000 (82.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2712,                   Accuracy: 55096/60000 (91.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1180,                   Accuracy: 57911/60000 (96.52%)
{0: tensor(97.8333), 10: tensor(96.3200), 20: tensor(91.9750), 30: tensor(83.3383), 40: tensor(74.3650), 50: tensor(72.8717), 60: tensor(82.3850), 70: tensor(91.8267), 80: tensor(96.5183), 90: tensor(97.8333), 100: tensor(96.3200), 110: tensor(91.9750), 120: tensor(83.3383), 130: tensor(74.3650), 140: tensor(72.8717), 150: tensor(82.3850), 160: tensor(91.8267), 170: tensor(96.5183), 180: tensor(97.8333), 190: tensor(96.3200), 200: tensor(91.9750), 210: tensor(83.3383), 220: tensor(74.3650), 230: tensor(72.8717), 240: tensor(82.3850), 250: tensor(91.8267), 260: tensor(96.5183), 270: tensor(97.8333), 280: tensor(96.3200), 290: tensor(91.9750), 300: tensor(83.3383), 310: tensor(74.3667), 320: tensor(72.8717), 330: tensor(82.3850), 340: tensor(91.8267), 350: tensor(96.5183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=20, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1182,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 1.8525,                   Accuracy: 934/2000.0 (46.70%)



-= Testing valid =-
Test set: Average loss: 0.7571,                   Accuracy: 1506/2000.0 (75.30%)



-= Testing valid =-
Test set: Average loss: 0.4569,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.4529,                   Accuracy: 1702/2000.0 (85.10%)



-= Testing valid =-
Test set: Average loss: 0.3760,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.2002,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.3631,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2282,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2179,                   Accuracy: 1851/2000.0 (92.55%)



Epoch 10 train accuracy: 96.32%, valid accuracy 92.55%
-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1254,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 20 train accuracy: 97.88%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 30 train accuracy: 98.60%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 98.99%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 99.05%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0753,                   Accuracy: 58658/60000 (97.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1148,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2576,                   Accuracy: 55272/60000 (92.12%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5321,                   Accuracy: 49993/60000 (83.32%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7792,                   Accuracy: 45473/60000 (75.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7842,                   Accuracy: 45533/60000 (75.89%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5288,                   Accuracy: 50276/60000 (83.79%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2627,                   Accuracy: 55173/60000 (91.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1071,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0753,                   Accuracy: 58658/60000 (97.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1148,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2576,                   Accuracy: 55272/60000 (92.12%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5321,                   Accuracy: 49993/60000 (83.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7792,                   Accuracy: 45473/60000 (75.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7842,                   Accuracy: 45533/60000 (75.89%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5288,                   Accuracy: 50276/60000 (83.79%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2627,                   Accuracy: 55173/60000 (91.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1071,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0753,                   Accuracy: 58658/60000 (97.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1148,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2576,                   Accuracy: 55272/60000 (92.12%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5321,                   Accuracy: 49993/60000 (83.32%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7792,                   Accuracy: 45473/60000 (75.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7842,                   Accuracy: 45533/60000 (75.89%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5288,                   Accuracy: 50276/60000 (83.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2627,                   Accuracy: 55173/60000 (91.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1071,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0753,                   Accuracy: 58658/60000 (97.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1148,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2576,                   Accuracy: 55272/60000 (92.12%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5321,                   Accuracy: 49993/60000 (83.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7792,                   Accuracy: 45473/60000 (75.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7842,                   Accuracy: 45533/60000 (75.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5288,                   Accuracy: 50276/60000 (83.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2627,                   Accuracy: 55173/60000 (91.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1071,                   Accuracy: 58030/60000 (96.72%)
{0: tensor(97.7633), 10: tensor(96.5700), 20: tensor(92.1200), 30: tensor(83.3217), 40: tensor(75.7883), 50: tensor(75.8883), 60: tensor(83.7933), 70: tensor(91.9550), 80: tensor(96.7167), 90: tensor(97.7633), 100: tensor(96.5700), 110: tensor(92.1200), 120: tensor(83.3217), 130: tensor(75.7883), 140: tensor(75.8883), 150: tensor(83.7933), 160: tensor(91.9550), 170: tensor(96.7167), 180: tensor(97.7633), 190: tensor(96.5700), 200: tensor(92.1200), 210: tensor(83.3217), 220: tensor(75.7883), 230: tensor(75.8883), 240: tensor(83.7933), 250: tensor(91.9550), 260: tensor(96.7167), 270: tensor(97.7633), 280: tensor(96.5700), 290: tensor(92.1200), 300: tensor(83.3217), 310: tensor(75.7883), 320: tensor(75.8883), 330: tensor(83.7933), 340: tensor(91.9550), 350: tensor(96.7167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=21, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1111,                   Accuracy: 245/2000.0 (12.25%)



-= Testing valid =-
Test set: Average loss: 1.5461,                   Accuracy: 875/2000.0 (43.75%)



-= Testing valid =-
Test set: Average loss: 0.6078,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.4429,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.4565,                   Accuracy: 1683/2000.0 (84.15%)



-= Testing valid =-
Test set: Average loss: 0.2098,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.3156,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.1841,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2622,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1770,                   Accuracy: 1892/2000.0 (94.60%)



Epoch 10 train accuracy: 96.18%, valid accuracy 94.60%
-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 20 train accuracy: 97.60%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 30 train accuracy: 98.46%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 98.91%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 99.00%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0772,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1421,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3154,                   Accuracy: 54495/60000 (90.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6542,                   Accuracy: 48737/60000 (81.23%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9538,                   Accuracy: 43509/60000 (72.51%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9694,                   Accuracy: 42930/60000 (71.55%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6056,                   Accuracy: 48876/60000 (81.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2630,                   Accuracy: 55031/60000 (91.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1182,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0772,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1421,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3154,                   Accuracy: 54495/60000 (90.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6542,                   Accuracy: 48737/60000 (81.23%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9538,                   Accuracy: 43509/60000 (72.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9694,                   Accuracy: 42930/60000 (71.55%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6056,                   Accuracy: 48876/60000 (81.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2630,                   Accuracy: 55031/60000 (91.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1182,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0772,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1421,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3154,                   Accuracy: 54495/60000 (90.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6542,                   Accuracy: 48737/60000 (81.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9538,                   Accuracy: 43509/60000 (72.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9694,                   Accuracy: 42930/60000 (71.55%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6056,                   Accuracy: 48876/60000 (81.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2630,                   Accuracy: 55031/60000 (91.72%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1182,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0772,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1421,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3154,                   Accuracy: 54495/60000 (90.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6542,                   Accuracy: 48737/60000 (81.23%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9538,                   Accuracy: 43509/60000 (72.51%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9694,                   Accuracy: 42930/60000 (71.55%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6056,                   Accuracy: 48876/60000 (81.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2630,                   Accuracy: 55031/60000 (91.72%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1182,                   Accuracy: 57819/60000 (96.36%)
{0: tensor(97.7367), 10: tensor(95.8250), 20: tensor(90.8250), 30: tensor(81.2283), 40: tensor(72.5150), 50: tensor(71.5500), 60: tensor(81.4600), 70: tensor(91.7183), 80: tensor(96.3650), 90: tensor(97.7367), 100: tensor(95.8250), 110: tensor(90.8250), 120: tensor(81.2283), 130: tensor(72.5150), 140: tensor(71.5500), 150: tensor(81.4600), 160: tensor(91.7183), 170: tensor(96.3650), 180: tensor(97.7367), 190: tensor(95.8250), 200: tensor(90.8250), 210: tensor(81.2283), 220: tensor(72.5150), 230: tensor(71.5500), 240: tensor(81.4600), 250: tensor(91.7183), 260: tensor(96.3650), 270: tensor(97.7367), 280: tensor(95.8250), 290: tensor(90.8250), 300: tensor(81.2283), 310: tensor(72.5150), 320: tensor(71.5500), 330: tensor(81.4600), 340: tensor(91.7183), 350: tensor(96.3650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=22, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0692,                   Accuracy: 317/2000.0 (15.85%)



-= Testing valid =-
Test set: Average loss: 2.7066,                   Accuracy: 494/2000.0 (24.70%)



-= Testing valid =-
Test set: Average loss: 1.0890,                   Accuracy: 1232/2000.0 (61.60%)



-= Testing valid =-
Test set: Average loss: 1.4651,                   Accuracy: 1085/2000.0 (54.25%)



-= Testing valid =-
Test set: Average loss: 0.2449,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.4312,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.2205,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1554,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1430,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 10 train accuracy: 96.22%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 20 train accuracy: 97.91%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 30 train accuracy: 98.47%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 98.86%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 98.78%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0764,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1231,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2436,                   Accuracy: 55598/60000 (92.66%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5813,                   Accuracy: 48983/60000 (81.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8603,                   Accuracy: 44570/60000 (74.28%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8833,                   Accuracy: 44595/60000 (74.32%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6000,                   Accuracy: 49423/60000 (82.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2926,                   Accuracy: 54786/60000 (91.31%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1168,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0764,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1231,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2436,                   Accuracy: 55598/60000 (92.66%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5813,                   Accuracy: 48983/60000 (81.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8603,                   Accuracy: 44570/60000 (74.28%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8833,                   Accuracy: 44595/60000 (74.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6000,                   Accuracy: 49423/60000 (82.37%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2926,                   Accuracy: 54786/60000 (91.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1168,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0764,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1231,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2436,                   Accuracy: 55598/60000 (92.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5813,                   Accuracy: 48983/60000 (81.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8603,                   Accuracy: 44570/60000 (74.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8833,                   Accuracy: 44595/60000 (74.32%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6000,                   Accuracy: 49423/60000 (82.37%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2926,                   Accuracy: 54786/60000 (91.31%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1168,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0764,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1231,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2436,                   Accuracy: 55598/60000 (92.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5813,                   Accuracy: 48983/60000 (81.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8603,                   Accuracy: 44570/60000 (74.28%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8833,                   Accuracy: 44595/60000 (74.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6000,                   Accuracy: 49423/60000 (82.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2926,                   Accuracy: 54786/60000 (91.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1168,                   Accuracy: 57870/60000 (96.45%)
{0: tensor(97.7267), 10: tensor(96.3067), 20: tensor(92.6633), 30: tensor(81.6383), 40: tensor(74.2833), 50: tensor(74.3250), 60: tensor(82.3717), 70: tensor(91.3100), 80: tensor(96.4500), 90: tensor(97.7267), 100: tensor(96.3067), 110: tensor(92.6633), 120: tensor(81.6383), 130: tensor(74.2833), 140: tensor(74.3250), 150: tensor(82.3717), 160: tensor(91.3100), 170: tensor(96.4500), 180: tensor(97.7267), 190: tensor(96.3067), 200: tensor(92.6633), 210: tensor(81.6383), 220: tensor(74.2833), 230: tensor(74.3250), 240: tensor(82.3717), 250: tensor(91.3100), 260: tensor(96.4500), 270: tensor(97.7267), 280: tensor(96.3067), 290: tensor(92.6633), 300: tensor(81.6383), 310: tensor(74.2833), 320: tensor(74.3250), 330: tensor(82.3717), 340: tensor(91.3100), 350: tensor(96.4500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=23, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1456,                   Accuracy: 427/2000.0 (21.35%)



-= Testing valid =-
Test set: Average loss: 1.1427,                   Accuracy: 1177/2000.0 (58.85%)



-= Testing valid =-
Test set: Average loss: 1.7402,                   Accuracy: 722/2000.0 (36.10%)



-= Testing valid =-
Test set: Average loss: 0.9707,                   Accuracy: 1265/2000.0 (63.25%)



-= Testing valid =-
Test set: Average loss: 0.2933,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.5772,                   Accuracy: 1607/2000.0 (80.35%)



-= Testing valid =-
Test set: Average loss: 0.3370,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3150,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3811,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.1454,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 10 train accuracy: 95.96%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1451,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 20 train accuracy: 97.86%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 98.54%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 98.91%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 99.07%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0805,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1463,                   Accuracy: 57257/60000 (95.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2936,                   Accuracy: 54546/60000 (90.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6481,                   Accuracy: 48229/60000 (80.38%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9876,                   Accuracy: 42554/60000 (70.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0280,                   Accuracy: 42197/60000 (70.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6356,                   Accuracy: 48546/60000 (80.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3197,                   Accuracy: 54210/60000 (90.35%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1317,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0805,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1463,                   Accuracy: 57257/60000 (95.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2936,                   Accuracy: 54546/60000 (90.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6481,                   Accuracy: 48229/60000 (80.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9876,                   Accuracy: 42554/60000 (70.92%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0280,                   Accuracy: 42197/60000 (70.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6356,                   Accuracy: 48546/60000 (80.91%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3197,                   Accuracy: 54210/60000 (90.35%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1317,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0805,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1463,                   Accuracy: 57257/60000 (95.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2936,                   Accuracy: 54546/60000 (90.91%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6481,                   Accuracy: 48229/60000 (80.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9876,                   Accuracy: 42554/60000 (70.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0280,                   Accuracy: 42197/60000 (70.33%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6356,                   Accuracy: 48546/60000 (80.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3197,                   Accuracy: 54210/60000 (90.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1317,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0805,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1463,                   Accuracy: 57257/60000 (95.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2936,                   Accuracy: 54546/60000 (90.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6481,                   Accuracy: 48229/60000 (80.38%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9876,                   Accuracy: 42554/60000 (70.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0280,                   Accuracy: 42197/60000 (70.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6356,                   Accuracy: 48546/60000 (80.91%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3197,                   Accuracy: 54210/60000 (90.35%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1317,                   Accuracy: 57661/60000 (96.10%)
{0: tensor(97.5500), 10: tensor(95.4283), 20: tensor(90.9100), 30: tensor(80.3817), 40: tensor(70.9233), 50: tensor(70.3283), 60: tensor(80.9100), 70: tensor(90.3500), 80: tensor(96.1017), 90: tensor(97.5500), 100: tensor(95.4283), 110: tensor(90.9100), 120: tensor(80.3817), 130: tensor(70.9233), 140: tensor(70.3283), 150: tensor(80.9100), 160: tensor(90.3500), 170: tensor(96.1017), 180: tensor(97.5500), 190: tensor(95.4283), 200: tensor(90.9100), 210: tensor(80.3817), 220: tensor(70.9233), 230: tensor(70.3283), 240: tensor(80.9100), 250: tensor(90.3500), 260: tensor(96.1017), 270: tensor(97.5500), 280: tensor(95.4283), 290: tensor(90.9100), 300: tensor(80.3817), 310: tensor(70.9233), 320: tensor(70.3283), 330: tensor(80.9100), 340: tensor(90.3500), 350: tensor(96.1017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=24, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.2092,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 1.2971,                   Accuracy: 1026/2000.0 (51.30%)



-= Testing valid =-
Test set: Average loss: 0.8541,                   Accuracy: 1369/2000.0 (68.45%)



-= Testing valid =-
Test set: Average loss: 0.4381,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.3178,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2013,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1397,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 10 train accuracy: 96.35%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 20 train accuracy: 97.93%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 30 train accuracy: 98.74%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 98.99%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 50 train accuracy: 99.04%, valid accuracy 98.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0814,                   Accuracy: 58567/60000 (97.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1291,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2723,                   Accuracy: 55165/60000 (91.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6060,                   Accuracy: 49685/60000 (82.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9289,                   Accuracy: 44559/60000 (74.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9465,                   Accuracy: 44127/60000 (73.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6066,                   Accuracy: 49270/60000 (82.12%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2732,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1101,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0814,                   Accuracy: 58567/60000 (97.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1291,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2723,                   Accuracy: 55165/60000 (91.94%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6060,                   Accuracy: 49685/60000 (82.81%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9289,                   Accuracy: 44559/60000 (74.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9465,                   Accuracy: 44127/60000 (73.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6066,                   Accuracy: 49270/60000 (82.12%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2732,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1101,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0814,                   Accuracy: 58567/60000 (97.61%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1291,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2723,                   Accuracy: 55165/60000 (91.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6060,                   Accuracy: 49685/60000 (82.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9289,                   Accuracy: 44559/60000 (74.26%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9465,                   Accuracy: 44127/60000 (73.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6066,                   Accuracy: 49270/60000 (82.12%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2732,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1101,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0814,                   Accuracy: 58567/60000 (97.61%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1291,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2723,                   Accuracy: 55165/60000 (91.94%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6060,                   Accuracy: 49685/60000 (82.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9289,                   Accuracy: 44559/60000 (74.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9465,                   Accuracy: 44127/60000 (73.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6066,                   Accuracy: 49270/60000 (82.12%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2732,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1101,                   Accuracy: 58015/60000 (96.69%)
{0: tensor(97.6117), 10: tensor(96.0717), 20: tensor(91.9417), 30: tensor(82.8083), 40: tensor(74.2650), 50: tensor(73.5450), 60: tensor(82.1167), 70: tensor(91.9133), 80: tensor(96.6917), 90: tensor(97.6117), 100: tensor(96.0717), 110: tensor(91.9417), 120: tensor(82.8083), 130: tensor(74.2650), 140: tensor(73.5450), 150: tensor(82.1167), 160: tensor(91.9133), 170: tensor(96.6917), 180: tensor(97.6117), 190: tensor(96.0717), 200: tensor(91.9417), 210: tensor(82.8083), 220: tensor(74.2650), 230: tensor(73.5450), 240: tensor(82.1167), 250: tensor(91.9133), 260: tensor(96.6917), 270: tensor(97.6117), 280: tensor(96.0717), 290: tensor(91.9417), 300: tensor(82.8083), 310: tensor(74.2650), 320: tensor(73.5450), 330: tensor(82.1167), 340: tensor(91.9133), 350: tensor(96.6917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=25, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1626,                   Accuracy: 476/2000.0 (23.80%)



-= Testing valid =-
Test set: Average loss: 1.2713,                   Accuracy: 1150/2000.0 (57.50%)



-= Testing valid =-
Test set: Average loss: 1.2045,                   Accuracy: 1135/2000.0 (56.75%)



-= Testing valid =-
Test set: Average loss: 1.0429,                   Accuracy: 1270/2000.0 (63.50%)



-= Testing valid =-
Test set: Average loss: 0.4116,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3702,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.1560,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1670,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.2260,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 10 train accuracy: 95.94%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 97.54%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 98.45%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 40 train accuracy: 98.84%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 98.95%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0764,                   Accuracy: 58693/60000 (97.82%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1202,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2588,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5686,                   Accuracy: 49739/60000 (82.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9206,                   Accuracy: 43741/60000 (72.90%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0143,                   Accuracy: 41849/60000 (69.75%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6645,                   Accuracy: 47733/60000 (79.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3090,                   Accuracy: 54323/60000 (90.54%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1187,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0764,                   Accuracy: 58693/60000 (97.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1202,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2588,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5686,                   Accuracy: 49739/60000 (82.90%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9206,                   Accuracy: 43741/60000 (72.90%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0143,                   Accuracy: 41849/60000 (69.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6645,                   Accuracy: 47733/60000 (79.56%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3090,                   Accuracy: 54323/60000 (90.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1187,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0764,                   Accuracy: 58693/60000 (97.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1202,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2588,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5686,                   Accuracy: 49739/60000 (82.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9206,                   Accuracy: 43741/60000 (72.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0143,                   Accuracy: 41849/60000 (69.75%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6645,                   Accuracy: 47733/60000 (79.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3090,                   Accuracy: 54323/60000 (90.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1187,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0764,                   Accuracy: 58693/60000 (97.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1202,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2588,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5686,                   Accuracy: 49739/60000 (82.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9206,                   Accuracy: 43741/60000 (72.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0143,                   Accuracy: 41849/60000 (69.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6645,                   Accuracy: 47733/60000 (79.56%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3090,                   Accuracy: 54323/60000 (90.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1187,                   Accuracy: 57908/60000 (96.51%)
{0: tensor(97.8217), 10: tensor(96.5217), 20: tensor(92.2600), 30: tensor(82.8983), 40: tensor(72.9017), 50: tensor(69.7483), 60: tensor(79.5550), 70: tensor(90.5383), 80: tensor(96.5133), 90: tensor(97.8217), 100: tensor(96.5217), 110: tensor(92.2600), 120: tensor(82.8983), 130: tensor(72.9017), 140: tensor(69.7483), 150: tensor(79.5550), 160: tensor(90.5383), 170: tensor(96.5133), 180: tensor(97.8217), 190: tensor(96.5217), 200: tensor(92.2600), 210: tensor(82.8983), 220: tensor(72.9017), 230: tensor(69.7483), 240: tensor(79.5550), 250: tensor(90.5383), 260: tensor(96.5133), 270: tensor(97.8217), 280: tensor(96.5217), 290: tensor(92.2600), 300: tensor(82.8983), 310: tensor(72.9017), 320: tensor(69.7483), 330: tensor(79.5550), 340: tensor(90.5383), 350: tensor(96.5133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=26, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8625,                   Accuracy: 636/2000.0 (31.80%)



-= Testing valid =-
Test set: Average loss: 2.3441,                   Accuracy: 360/2000.0 (18.00%)



-= Testing valid =-
Test set: Average loss: 0.8371,                   Accuracy: 1348/2000.0 (67.40%)



-= Testing valid =-
Test set: Average loss: 0.8764,                   Accuracy: 1444/2000.0 (72.20%)



-= Testing valid =-
Test set: Average loss: 0.6411,                   Accuracy: 1588/2000.0 (79.40%)



-= Testing valid =-
Test set: Average loss: 0.4097,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.2820,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1921,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.4673,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.1488,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 10 train accuracy: 95.90%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1450,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1247,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 97.97%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1379,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 98.57%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 98.96%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 99.06%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0931,                   Accuracy: 58444/60000 (97.41%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1357,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2317,                   Accuracy: 56014/60000 (93.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4843,                   Accuracy: 51512/60000 (85.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7058,                   Accuracy: 47747/60000 (79.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7344,                   Accuracy: 47453/60000 (79.09%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4992,                   Accuracy: 51197/60000 (85.33%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2565,                   Accuracy: 55543/60000 (92.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1323,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0931,                   Accuracy: 58444/60000 (97.41%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1357,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2317,                   Accuracy: 56014/60000 (93.36%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4843,                   Accuracy: 51512/60000 (85.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7058,                   Accuracy: 47747/60000 (79.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7344,                   Accuracy: 47453/60000 (79.09%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4992,                   Accuracy: 51197/60000 (85.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2565,                   Accuracy: 55543/60000 (92.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1323,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0931,                   Accuracy: 58444/60000 (97.41%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1357,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2317,                   Accuracy: 56014/60000 (93.36%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4843,                   Accuracy: 51512/60000 (85.85%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7058,                   Accuracy: 47747/60000 (79.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7344,                   Accuracy: 47453/60000 (79.09%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4992,                   Accuracy: 51197/60000 (85.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2565,                   Accuracy: 55543/60000 (92.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1323,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0931,                   Accuracy: 58444/60000 (97.41%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1357,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2317,                   Accuracy: 56014/60000 (93.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4843,                   Accuracy: 51512/60000 (85.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7058,                   Accuracy: 47747/60000 (79.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7344,                   Accuracy: 47453/60000 (79.09%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4992,                   Accuracy: 51197/60000 (85.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2565,                   Accuracy: 55543/60000 (92.57%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1323,                   Accuracy: 57819/60000 (96.36%)
{0: tensor(97.4067), 10: tensor(96.1717), 20: tensor(93.3567), 30: tensor(85.8533), 40: tensor(79.5783), 50: tensor(79.0883), 60: tensor(85.3283), 70: tensor(92.5717), 80: tensor(96.3650), 90: tensor(97.4067), 100: tensor(96.1717), 110: tensor(93.3567), 120: tensor(85.8533), 130: tensor(79.5783), 140: tensor(79.0883), 150: tensor(85.3283), 160: tensor(92.5717), 170: tensor(96.3650), 180: tensor(97.4067), 190: tensor(96.1717), 200: tensor(93.3567), 210: tensor(85.8533), 220: tensor(79.5783), 230: tensor(79.0883), 240: tensor(85.3283), 250: tensor(92.5717), 260: tensor(96.3650), 270: tensor(97.4067), 280: tensor(96.1717), 290: tensor(93.3567), 300: tensor(85.8533), 310: tensor(79.5783), 320: tensor(79.0883), 330: tensor(85.3283), 340: tensor(92.5717), 350: tensor(96.3650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=27, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3270,                   Accuracy: 340/2000.0 (17.00%)



-= Testing valid =-
Test set: Average loss: 1.4834,                   Accuracy: 843/2000.0 (42.15%)



-= Testing valid =-
Test set: Average loss: 1.2878,                   Accuracy: 1212/2000.0 (60.60%)



-= Testing valid =-
Test set: Average loss: 0.4331,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.2150,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1644,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.2861,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.1572,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.2039,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1558,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 10 train accuracy: 96.51%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 20 train accuracy: 98.14%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 98.81%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 99.01%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 99.09%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0706,                   Accuracy: 58721/60000 (97.87%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1054,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2197,                   Accuracy: 56066/60000 (93.44%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5482,                   Accuracy: 50533/60000 (84.22%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9274,                   Accuracy: 44350/60000 (73.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9686,                   Accuracy: 43098/60000 (71.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6152,                   Accuracy: 48586/60000 (80.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2706,                   Accuracy: 54923/60000 (91.54%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1061,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0706,                   Accuracy: 58721/60000 (97.87%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1054,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2197,                   Accuracy: 56066/60000 (93.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5482,                   Accuracy: 50533/60000 (84.22%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9274,                   Accuracy: 44350/60000 (73.92%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9686,                   Accuracy: 43098/60000 (71.83%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6152,                   Accuracy: 48586/60000 (80.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2706,                   Accuracy: 54923/60000 (91.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1061,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0706,                   Accuracy: 58721/60000 (97.87%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1054,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2197,                   Accuracy: 56066/60000 (93.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5482,                   Accuracy: 50533/60000 (84.22%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9274,                   Accuracy: 44350/60000 (73.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9686,                   Accuracy: 43098/60000 (71.83%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6152,                   Accuracy: 48586/60000 (80.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2706,                   Accuracy: 54923/60000 (91.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1061,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0706,                   Accuracy: 58721/60000 (97.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1054,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2197,                   Accuracy: 56066/60000 (93.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5482,                   Accuracy: 50533/60000 (84.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9274,                   Accuracy: 44350/60000 (73.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9686,                   Accuracy: 43098/60000 (71.83%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6152,                   Accuracy: 48586/60000 (80.98%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2706,                   Accuracy: 54923/60000 (91.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1061,                   Accuracy: 58025/60000 (96.71%)
{0: tensor(97.8683), 10: tensor(96.8383), 20: tensor(93.4433), 30: tensor(84.2217), 40: tensor(73.9167), 50: tensor(71.8300), 60: tensor(80.9767), 70: tensor(91.5383), 80: tensor(96.7083), 90: tensor(97.8683), 100: tensor(96.8383), 110: tensor(93.4433), 120: tensor(84.2217), 130: tensor(73.9167), 140: tensor(71.8300), 150: tensor(80.9767), 160: tensor(91.5383), 170: tensor(96.7083), 180: tensor(97.8683), 190: tensor(96.8383), 200: tensor(93.4433), 210: tensor(84.2217), 220: tensor(73.9167), 230: tensor(71.8300), 240: tensor(80.9767), 250: tensor(91.5383), 260: tensor(96.7083), 270: tensor(97.8683), 280: tensor(96.8383), 290: tensor(93.4433), 300: tensor(84.2217), 310: tensor(73.9167), 320: tensor(71.8300), 330: tensor(80.9767), 340: tensor(91.5383), 350: tensor(96.7083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=28, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6270,                   Accuracy: 412/2000.0 (20.60%)



-= Testing valid =-
Test set: Average loss: 0.9627,                   Accuracy: 1304/2000.0 (65.20%)



-= Testing valid =-
Test set: Average loss: 1.1858,                   Accuracy: 1279/2000.0 (63.95%)



-= Testing valid =-
Test set: Average loss: 0.2961,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.9349,                   Accuracy: 1391/2000.0 (69.55%)



-= Testing valid =-
Test set: Average loss: 0.3865,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3208,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.2686,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 10 train accuracy: 96.32%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1541,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1425,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 97.82%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 98.76%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 98.93%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 99.20%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0873,                   Accuracy: 58505/60000 (97.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1320,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2511,                   Accuracy: 55623/60000 (92.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5779,                   Accuracy: 50083/60000 (83.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8935,                   Accuracy: 45553/60000 (75.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8942,                   Accuracy: 45538/60000 (75.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5805,                   Accuracy: 50138/60000 (83.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2781,                   Accuracy: 55062/60000 (91.77%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1110,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0873,                   Accuracy: 58505/60000 (97.51%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1320,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2511,                   Accuracy: 55623/60000 (92.71%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5779,                   Accuracy: 50083/60000 (83.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8935,                   Accuracy: 45553/60000 (75.92%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8942,                   Accuracy: 45538/60000 (75.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5805,                   Accuracy: 50138/60000 (83.56%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2781,                   Accuracy: 55062/60000 (91.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1110,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0873,                   Accuracy: 58505/60000 (97.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1320,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2511,                   Accuracy: 55623/60000 (92.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5779,                   Accuracy: 50083/60000 (83.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8935,                   Accuracy: 45553/60000 (75.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8942,                   Accuracy: 45538/60000 (75.90%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5805,                   Accuracy: 50138/60000 (83.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2781,                   Accuracy: 55062/60000 (91.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1110,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0873,                   Accuracy: 58505/60000 (97.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1320,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2511,                   Accuracy: 55623/60000 (92.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5779,                   Accuracy: 50083/60000 (83.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8935,                   Accuracy: 45553/60000 (75.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8942,                   Accuracy: 45538/60000 (75.90%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5805,                   Accuracy: 50138/60000 (83.56%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2781,                   Accuracy: 55062/60000 (91.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1110,                   Accuracy: 58018/60000 (96.70%)
{0: tensor(97.5083), 10: tensor(96.1817), 20: tensor(92.7050), 30: tensor(83.4717), 40: tensor(75.9217), 50: tensor(75.8967), 60: tensor(83.5633), 70: tensor(91.7700), 80: tensor(96.6967), 90: tensor(97.5083), 100: tensor(96.1817), 110: tensor(92.7050), 120: tensor(83.4717), 130: tensor(75.9217), 140: tensor(75.8967), 150: tensor(83.5633), 160: tensor(91.7700), 170: tensor(96.6967), 180: tensor(97.5083), 190: tensor(96.1817), 200: tensor(92.7050), 210: tensor(83.4717), 220: tensor(75.9217), 230: tensor(75.8967), 240: tensor(83.5633), 250: tensor(91.7700), 260: tensor(96.6967), 270: tensor(97.5083), 280: tensor(96.1817), 290: tensor(92.7050), 300: tensor(83.4717), 310: tensor(75.9217), 320: tensor(75.8967), 330: tensor(83.5633), 340: tensor(91.7700), 350: tensor(96.6967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=29, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7503,                   Accuracy: 689/2000.0 (34.45%)



-= Testing valid =-
Test set: Average loss: 1.1763,                   Accuracy: 1169/2000.0 (58.45%)



-= Testing valid =-
Test set: Average loss: 1.0670,                   Accuracy: 1299/2000.0 (64.95%)



-= Testing valid =-
Test set: Average loss: 0.3505,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.2466,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2049,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1460,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1843,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 10 train accuracy: 96.57%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 20 train accuracy: 98.25%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 98.71%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 40 train accuracy: 99.11%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.06%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0767,                   Accuracy: 58675/60000 (97.79%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1286,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2645,                   Accuracy: 55360/60000 (92.27%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5524,                   Accuracy: 50630/60000 (84.38%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9146,                   Accuracy: 45034/60000 (75.06%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9523,                   Accuracy: 44449/60000 (74.08%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5946,                   Accuracy: 49760/60000 (82.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2563,                   Accuracy: 55371/60000 (92.29%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1060,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0767,                   Accuracy: 58675/60000 (97.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1286,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2645,                   Accuracy: 55360/60000 (92.27%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5524,                   Accuracy: 50630/60000 (84.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9146,                   Accuracy: 45034/60000 (75.06%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9523,                   Accuracy: 44449/60000 (74.08%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5946,                   Accuracy: 49760/60000 (82.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2563,                   Accuracy: 55371/60000 (92.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1060,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0767,                   Accuracy: 58675/60000 (97.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1286,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2645,                   Accuracy: 55360/60000 (92.27%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5524,                   Accuracy: 50630/60000 (84.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9146,                   Accuracy: 45034/60000 (75.06%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9523,                   Accuracy: 44449/60000 (74.08%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5946,                   Accuracy: 49760/60000 (82.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2563,                   Accuracy: 55371/60000 (92.29%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1060,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0767,                   Accuracy: 58675/60000 (97.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1286,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2645,                   Accuracy: 55360/60000 (92.27%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5524,                   Accuracy: 50630/60000 (84.38%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9146,                   Accuracy: 45034/60000 (75.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9523,                   Accuracy: 44449/60000 (74.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5946,                   Accuracy: 49760/60000 (82.93%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2563,                   Accuracy: 55371/60000 (92.29%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1060,                   Accuracy: 58107/60000 (96.85%)
{0: tensor(97.7917), 10: tensor(96.1733), 20: tensor(92.2667), 30: tensor(84.3833), 40: tensor(75.0567), 50: tensor(74.0817), 60: tensor(82.9333), 70: tensor(92.2850), 80: tensor(96.8450), 90: tensor(97.7917), 100: tensor(96.1733), 110: tensor(92.2667), 120: tensor(84.3833), 130: tensor(75.0567), 140: tensor(74.0817), 150: tensor(82.9333), 160: tensor(92.2850), 170: tensor(96.8450), 180: tensor(97.7917), 190: tensor(96.1733), 200: tensor(92.2667), 210: tensor(84.3833), 220: tensor(75.0567), 230: tensor(74.0817), 240: tensor(82.9333), 250: tensor(92.2850), 260: tensor(96.8450), 270: tensor(97.7917), 280: tensor(96.1733), 290: tensor(92.2667), 300: tensor(84.3833), 310: tensor(75.0567), 320: tensor(74.0817), 330: tensor(82.9333), 340: tensor(92.2850), 350: tensor(96.8450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=30, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 9.1324,                   Accuracy: 196/2000.0 (9.80%)



-= Testing valid =-
Test set: Average loss: 1.3375,                   Accuracy: 1088/2000.0 (54.40%)



-= Testing valid =-
Test set: Average loss: 0.4101,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.7147,                   Accuracy: 1524/2000.0 (76.20%)



-= Testing valid =-
Test set: Average loss: 0.3617,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3319,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.4832,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.2383,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 10 train accuracy: 96.06%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 20 train accuracy: 97.81%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 30 train accuracy: 98.43%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 98.85%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 50 train accuracy: 99.11%, valid accuracy 98.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0788,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1216,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2497,                   Accuracy: 55598/60000 (92.66%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5682,                   Accuracy: 50426/60000 (84.04%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9164,                   Accuracy: 45036/60000 (75.06%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9546,                   Accuracy: 44430/60000 (74.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6177,                   Accuracy: 49543/60000 (82.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2777,                   Accuracy: 55121/60000 (91.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1144,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0788,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1216,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2497,                   Accuracy: 55598/60000 (92.66%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5682,                   Accuracy: 50426/60000 (84.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9164,                   Accuracy: 45036/60000 (75.06%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9546,                   Accuracy: 44430/60000 (74.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6177,                   Accuracy: 49543/60000 (82.57%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2777,                   Accuracy: 55121/60000 (91.87%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1144,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0788,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1216,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2497,                   Accuracy: 55598/60000 (92.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5682,                   Accuracy: 50426/60000 (84.04%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9164,                   Accuracy: 45036/60000 (75.06%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9546,                   Accuracy: 44430/60000 (74.05%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6177,                   Accuracy: 49543/60000 (82.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2777,                   Accuracy: 55121/60000 (91.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1144,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0788,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1216,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2497,                   Accuracy: 55598/60000 (92.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5682,                   Accuracy: 50426/60000 (84.04%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9164,                   Accuracy: 45036/60000 (75.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9546,                   Accuracy: 44430/60000 (74.05%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6177,                   Accuracy: 49543/60000 (82.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2777,                   Accuracy: 55121/60000 (91.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1144,                   Accuracy: 57965/60000 (96.61%)
{0: tensor(97.6867), 10: tensor(96.3900), 20: tensor(92.6633), 30: tensor(84.0433), 40: tensor(75.0600), 50: tensor(74.0500), 60: tensor(82.5717), 70: tensor(91.8683), 80: tensor(96.6083), 90: tensor(97.6867), 100: tensor(96.3900), 110: tensor(92.6633), 120: tensor(84.0433), 130: tensor(75.0600), 140: tensor(74.0500), 150: tensor(82.5717), 160: tensor(91.8683), 170: tensor(96.6083), 180: tensor(97.6867), 190: tensor(96.3900), 200: tensor(92.6633), 210: tensor(84.0433), 220: tensor(75.0600), 230: tensor(74.0500), 240: tensor(82.5717), 250: tensor(91.8683), 260: tensor(96.6083), 270: tensor(97.6867), 280: tensor(96.3900), 290: tensor(92.6633), 300: tensor(84.0433), 310: tensor(75.0600), 320: tensor(74.0500), 330: tensor(82.5717), 340: tensor(91.8683), 350: tensor(96.6083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=31, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6643,                   Accuracy: 305/2000.0 (15.25%)



-= Testing valid =-
Test set: Average loss: 1.6435,                   Accuracy: 816/2000.0 (40.80%)



-= Testing valid =-
Test set: Average loss: 0.3537,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2397,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2376,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.3228,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.1561,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1487,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 10 train accuracy: 96.34%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 20 train accuracy: 97.95%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 98.56%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 98.99%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.14%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0688,                   Accuracy: 58784/60000 (97.97%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1285,                   Accuracy: 57683/60000 (96.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2569,                   Accuracy: 55431/60000 (92.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5254,                   Accuracy: 50950/60000 (84.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8583,                   Accuracy: 45054/60000 (75.09%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9572,                   Accuracy: 43315/60000 (72.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6778,                   Accuracy: 47905/60000 (79.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3480,                   Accuracy: 53693/60000 (89.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1167,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0688,                   Accuracy: 58784/60000 (97.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1285,                   Accuracy: 57683/60000 (96.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2569,                   Accuracy: 55431/60000 (92.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5254,                   Accuracy: 50950/60000 (84.92%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8583,                   Accuracy: 45054/60000 (75.09%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9572,                   Accuracy: 43315/60000 (72.19%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6778,                   Accuracy: 47905/60000 (79.84%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3480,                   Accuracy: 53693/60000 (89.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1167,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0688,                   Accuracy: 58784/60000 (97.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1285,                   Accuracy: 57683/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2569,                   Accuracy: 55431/60000 (92.39%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5254,                   Accuracy: 50950/60000 (84.92%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8583,                   Accuracy: 45054/60000 (75.09%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9572,                   Accuracy: 43315/60000 (72.19%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6778,                   Accuracy: 47905/60000 (79.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3480,                   Accuracy: 53693/60000 (89.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1167,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0688,                   Accuracy: 58784/60000 (97.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1285,                   Accuracy: 57683/60000 (96.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2569,                   Accuracy: 55431/60000 (92.39%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5254,                   Accuracy: 50950/60000 (84.92%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8583,                   Accuracy: 45054/60000 (75.09%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9572,                   Accuracy: 43315/60000 (72.19%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6778,                   Accuracy: 47905/60000 (79.84%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3480,                   Accuracy: 53693/60000 (89.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1167,                   Accuracy: 57932/60000 (96.55%)
{0: tensor(97.9733), 10: tensor(96.1383), 20: tensor(92.3850), 30: tensor(84.9167), 40: tensor(75.0900), 50: tensor(72.1917), 60: tensor(79.8417), 70: tensor(89.4883), 80: tensor(96.5533), 90: tensor(97.9733), 100: tensor(96.1383), 110: tensor(92.3850), 120: tensor(84.9167), 130: tensor(75.0900), 140: tensor(72.1917), 150: tensor(79.8417), 160: tensor(89.4883), 170: tensor(96.5533), 180: tensor(97.9733), 190: tensor(96.1383), 200: tensor(92.3850), 210: tensor(84.9167), 220: tensor(75.0900), 230: tensor(72.1917), 240: tensor(79.8417), 250: tensor(89.4883), 260: tensor(96.5533), 270: tensor(97.9733), 280: tensor(96.1383), 290: tensor(92.3850), 300: tensor(84.9167), 310: tensor(75.0900), 320: tensor(72.1917), 330: tensor(79.8417), 340: tensor(89.4883), 350: tensor(96.5533)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=32, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2035,                   Accuracy: 234/2000.0 (11.70%)



-= Testing valid =-
Test set: Average loss: 1.2761,                   Accuracy: 1036/2000.0 (51.80%)



-= Testing valid =-
Test set: Average loss: 0.4874,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.2701,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2674,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.1636,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.2486,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1948,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 10 train accuracy: 96.16%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1991,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 20 train accuracy: 98.04%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 98.70%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 98.96%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 50 train accuracy: 98.96%, valid accuracy 98.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0823,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1234,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2784,                   Accuracy: 55086/60000 (91.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5804,                   Accuracy: 50002/60000 (83.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9220,                   Accuracy: 44521/60000 (74.20%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9941,                   Accuracy: 43113/60000 (71.86%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7032,                   Accuracy: 47538/60000 (79.23%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3271,                   Accuracy: 53932/60000 (89.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1302,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0823,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1234,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2784,                   Accuracy: 55086/60000 (91.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5804,                   Accuracy: 50002/60000 (83.34%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9220,                   Accuracy: 44521/60000 (74.20%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9941,                   Accuracy: 43113/60000 (71.86%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7032,                   Accuracy: 47538/60000 (79.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3271,                   Accuracy: 53932/60000 (89.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1302,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0823,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1234,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2784,                   Accuracy: 55086/60000 (91.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5804,                   Accuracy: 50002/60000 (83.34%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9220,                   Accuracy: 44521/60000 (74.20%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9941,                   Accuracy: 43113/60000 (71.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7032,                   Accuracy: 47538/60000 (79.23%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3271,                   Accuracy: 53932/60000 (89.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1302,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0823,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1234,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2784,                   Accuracy: 55086/60000 (91.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5804,                   Accuracy: 50002/60000 (83.34%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9220,                   Accuracy: 44521/60000 (74.20%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9941,                   Accuracy: 43113/60000 (71.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7032,                   Accuracy: 47538/60000 (79.23%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3271,                   Accuracy: 53932/60000 (89.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1302,                   Accuracy: 57643/60000 (96.07%)
{0: tensor(97.6667), 10: tensor(96.4333), 20: tensor(91.8100), 30: tensor(83.3367), 40: tensor(74.2017), 50: tensor(71.8550), 60: tensor(79.2300), 70: tensor(89.8867), 80: tensor(96.0717), 90: tensor(97.6667), 100: tensor(96.4333), 110: tensor(91.8100), 120: tensor(83.3367), 130: tensor(74.2017), 140: tensor(71.8550), 150: tensor(79.2300), 160: tensor(89.8867), 170: tensor(96.0717), 180: tensor(97.6667), 190: tensor(96.4333), 200: tensor(91.8100), 210: tensor(83.3367), 220: tensor(74.2017), 230: tensor(71.8550), 240: tensor(79.2300), 250: tensor(89.8867), 260: tensor(96.0717), 270: tensor(97.6667), 280: tensor(96.4333), 290: tensor(91.8100), 300: tensor(83.3367), 310: tensor(74.2017), 320: tensor(71.8550), 330: tensor(79.2300), 340: tensor(89.8867), 350: tensor(96.0717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=33, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2947,                   Accuracy: 350/2000.0 (17.50%)



-= Testing valid =-
Test set: Average loss: 3.7120,                   Accuracy: 257/2000.0 (12.85%)



-= Testing valid =-
Test set: Average loss: 0.6006,                   Accuracy: 1573/2000.0 (78.65%)



-= Testing valid =-
Test set: Average loss: 0.2332,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2272,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1835,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1375,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.3667,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 10 train accuracy: 96.30%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 97.81%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 98.41%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 98.84%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 98.80%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0702,                   Accuracy: 58747/60000 (97.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1170,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2582,                   Accuracy: 55322/60000 (92.20%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4881,                   Accuracy: 51276/60000 (85.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7751,                   Accuracy: 46434/60000 (77.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8383,                   Accuracy: 45405/60000 (75.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5688,                   Accuracy: 49830/60000 (83.05%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2988,                   Accuracy: 54443/60000 (90.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1211,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0702,                   Accuracy: 58747/60000 (97.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1170,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2582,                   Accuracy: 55322/60000 (92.20%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4881,                   Accuracy: 51276/60000 (85.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7751,                   Accuracy: 46434/60000 (77.39%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8383,                   Accuracy: 45406/60000 (75.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5688,                   Accuracy: 49830/60000 (83.05%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2988,                   Accuracy: 54443/60000 (90.74%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1211,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0702,                   Accuracy: 58747/60000 (97.91%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1170,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2582,                   Accuracy: 55322/60000 (92.20%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4881,                   Accuracy: 51276/60000 (85.46%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7751,                   Accuracy: 46434/60000 (77.39%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8383,                   Accuracy: 45405/60000 (75.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5688,                   Accuracy: 49830/60000 (83.05%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2988,                   Accuracy: 54443/60000 (90.74%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1211,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0702,                   Accuracy: 58747/60000 (97.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1170,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2582,                   Accuracy: 55322/60000 (92.20%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4881,                   Accuracy: 51276/60000 (85.46%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7751,                   Accuracy: 46434/60000 (77.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8383,                   Accuracy: 45406/60000 (75.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5688,                   Accuracy: 49830/60000 (83.05%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2988,                   Accuracy: 54443/60000 (90.74%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1211,                   Accuracy: 57794/60000 (96.32%)
{0: tensor(97.9117), 10: tensor(96.4600), 20: tensor(92.2033), 30: tensor(85.4600), 40: tensor(77.3900), 50: tensor(75.6750), 60: tensor(83.0500), 70: tensor(90.7383), 80: tensor(96.3233), 90: tensor(97.9117), 100: tensor(96.4600), 110: tensor(92.2033), 120: tensor(85.4600), 130: tensor(77.3900), 140: tensor(75.6767), 150: tensor(83.0500), 160: tensor(90.7383), 170: tensor(96.3233), 180: tensor(97.9117), 190: tensor(96.4600), 200: tensor(92.2033), 210: tensor(85.4600), 220: tensor(77.3900), 230: tensor(75.6750), 240: tensor(83.0500), 250: tensor(90.7383), 260: tensor(96.3233), 270: tensor(97.9117), 280: tensor(96.4600), 290: tensor(92.2033), 300: tensor(85.4600), 310: tensor(77.3900), 320: tensor(75.6767), 330: tensor(83.0500), 340: tensor(90.7383), 350: tensor(96.3233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=34, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0087,                   Accuracy: 468/2000.0 (23.40%)



-= Testing valid =-
Test set: Average loss: 3.4390,                   Accuracy: 489/2000.0 (24.45%)



-= Testing valid =-
Test set: Average loss: 2.0023,                   Accuracy: 641/2000.0 (32.05%)



-= Testing valid =-
Test set: Average loss: 1.0308,                   Accuracy: 1328/2000.0 (66.40%)



-= Testing valid =-
Test set: Average loss: 0.5342,                   Accuracy: 1651/2000.0 (82.55%)



-= Testing valid =-
Test set: Average loss: 0.2052,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1818,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1609,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.3913,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 10 train accuracy: 95.85%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1311,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 20 train accuracy: 98.05%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 98.61%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 98.90%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 99.15%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0696,                   Accuracy: 58777/60000 (97.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1123,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2303,                   Accuracy: 55984/60000 (93.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5206,                   Accuracy: 50860/60000 (84.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8203,                   Accuracy: 45937/60000 (76.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8459,                   Accuracy: 45199/60000 (75.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5592,                   Accuracy: 49898/60000 (83.16%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2624,                   Accuracy: 55335/60000 (92.22%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1082,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0696,                   Accuracy: 58777/60000 (97.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1123,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2303,                   Accuracy: 55984/60000 (93.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5206,                   Accuracy: 50860/60000 (84.77%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8203,                   Accuracy: 45937/60000 (76.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8459,                   Accuracy: 45199/60000 (75.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5592,                   Accuracy: 49898/60000 (83.16%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2624,                   Accuracy: 55335/60000 (92.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1082,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0696,                   Accuracy: 58777/60000 (97.96%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1123,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2303,                   Accuracy: 55984/60000 (93.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5206,                   Accuracy: 50860/60000 (84.77%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8203,                   Accuracy: 45937/60000 (76.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8459,                   Accuracy: 45199/60000 (75.33%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5592,                   Accuracy: 49898/60000 (83.16%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2624,                   Accuracy: 55335/60000 (92.22%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1082,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0696,                   Accuracy: 58777/60000 (97.96%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1123,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2303,                   Accuracy: 55984/60000 (93.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5206,                   Accuracy: 50860/60000 (84.77%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8203,                   Accuracy: 45937/60000 (76.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8459,                   Accuracy: 45199/60000 (75.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5592,                   Accuracy: 49898/60000 (83.16%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2624,                   Accuracy: 55335/60000 (92.22%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1082,                   Accuracy: 58081/60000 (96.80%)
{0: tensor(97.9617), 10: tensor(96.6750), 20: tensor(93.3067), 30: tensor(84.7667), 40: tensor(76.5617), 50: tensor(75.3317), 60: tensor(83.1633), 70: tensor(92.2250), 80: tensor(96.8017), 90: tensor(97.9617), 100: tensor(96.6750), 110: tensor(93.3067), 120: tensor(84.7667), 130: tensor(76.5617), 140: tensor(75.3317), 150: tensor(83.1633), 160: tensor(92.2250), 170: tensor(96.8017), 180: tensor(97.9617), 190: tensor(96.6750), 200: tensor(93.3067), 210: tensor(84.7667), 220: tensor(76.5617), 230: tensor(75.3317), 240: tensor(83.1633), 250: tensor(92.2250), 260: tensor(96.8017), 270: tensor(97.9617), 280: tensor(96.6750), 290: tensor(93.3067), 300: tensor(84.7667), 310: tensor(76.5617), 320: tensor(75.3317), 330: tensor(83.1633), 340: tensor(92.2250), 350: tensor(96.8017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=35, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9454,                   Accuracy: 484/2000.0 (24.20%)



-= Testing valid =-
Test set: Average loss: 2.2603,                   Accuracy: 545/2000.0 (27.25%)



-= Testing valid =-
Test set: Average loss: 0.7802,                   Accuracy: 1510/2000.0 (75.50%)



-= Testing valid =-
Test set: Average loss: 0.7752,                   Accuracy: 1495/2000.0 (74.75%)



-= Testing valid =-
Test set: Average loss: 0.9923,                   Accuracy: 1289/2000.0 (64.45%)



-= Testing valid =-
Test set: Average loss: 0.2312,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2289,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1672,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1926,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 10 train accuracy: 96.22%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 20 train accuracy: 97.72%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 98.31%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 98.88%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 98.97%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0786,                   Accuracy: 58622/60000 (97.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1163,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2360,                   Accuracy: 55685/60000 (92.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5428,                   Accuracy: 50365/60000 (83.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8662,                   Accuracy: 44628/60000 (74.38%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9401,                   Accuracy: 43131/60000 (71.89%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6526,                   Accuracy: 48200/60000 (80.33%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3037,                   Accuracy: 54252/60000 (90.42%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1204,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0786,                   Accuracy: 58622/60000 (97.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1163,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2360,                   Accuracy: 55685/60000 (92.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5428,                   Accuracy: 50365/60000 (83.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8662,                   Accuracy: 44628/60000 (74.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9401,                   Accuracy: 43131/60000 (71.89%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6526,                   Accuracy: 48200/60000 (80.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3037,                   Accuracy: 54252/60000 (90.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1204,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0786,                   Accuracy: 58622/60000 (97.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1163,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2360,                   Accuracy: 55685/60000 (92.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5428,                   Accuracy: 50365/60000 (83.94%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8662,                   Accuracy: 44628/60000 (74.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9401,                   Accuracy: 43131/60000 (71.89%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6526,                   Accuracy: 48200/60000 (80.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3037,                   Accuracy: 54252/60000 (90.42%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1204,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0786,                   Accuracy: 58622/60000 (97.70%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1163,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2360,                   Accuracy: 55685/60000 (92.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5428,                   Accuracy: 50365/60000 (83.94%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8662,                   Accuracy: 44628/60000 (74.38%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9401,                   Accuracy: 43131/60000 (71.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6526,                   Accuracy: 48200/60000 (80.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3037,                   Accuracy: 54252/60000 (90.42%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1204,                   Accuracy: 57786/60000 (96.31%)
{0: tensor(97.7033), 10: tensor(96.5350), 20: tensor(92.8083), 30: tensor(83.9417), 40: tensor(74.3800), 50: tensor(71.8850), 60: tensor(80.3333), 70: tensor(90.4200), 80: tensor(96.3100), 90: tensor(97.7033), 100: tensor(96.5350), 110: tensor(92.8083), 120: tensor(83.9417), 130: tensor(74.3800), 140: tensor(71.8850), 150: tensor(80.3333), 160: tensor(90.4200), 170: tensor(96.3100), 180: tensor(97.7033), 190: tensor(96.5350), 200: tensor(92.8083), 210: tensor(83.9417), 220: tensor(74.3800), 230: tensor(71.8850), 240: tensor(80.3333), 250: tensor(90.4200), 260: tensor(96.3100), 270: tensor(97.7033), 280: tensor(96.5350), 290: tensor(92.8083), 300: tensor(83.9417), 310: tensor(74.3800), 320: tensor(71.8850), 330: tensor(80.3333), 340: tensor(90.4200), 350: tensor(96.3100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=36, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.0407,                   Accuracy: 278/2000.0 (13.90%)



-= Testing valid =-
Test set: Average loss: 1.7429,                   Accuracy: 680/2000.0 (34.00%)



-= Testing valid =-
Test set: Average loss: 1.4992,                   Accuracy: 943/2000.0 (47.15%)



-= Testing valid =-
Test set: Average loss: 0.5488,                   Accuracy: 1678/2000.0 (83.90%)



-= Testing valid =-
Test set: Average loss: 0.6126,                   Accuracy: 1596/2000.0 (79.80%)



-= Testing valid =-
Test set: Average loss: 0.1594,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.2054,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1972,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2079,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 10 train accuracy: 96.45%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 20 train accuracy: 97.70%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 30 train accuracy: 98.60%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 40 train accuracy: 98.88%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 98.84%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0827,                   Accuracy: 58588/60000 (97.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1217,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2631,                   Accuracy: 55477/60000 (92.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5969,                   Accuracy: 50097/60000 (83.50%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9408,                   Accuracy: 45184/60000 (75.31%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9974,                   Accuracy: 44102/60000 (73.50%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6295,                   Accuracy: 49266/60000 (82.11%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2673,                   Accuracy: 55263/60000 (92.11%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1195,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0827,                   Accuracy: 58588/60000 (97.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1217,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2631,                   Accuracy: 55477/60000 (92.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5969,                   Accuracy: 50097/60000 (83.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9408,                   Accuracy: 45184/60000 (75.31%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9974,                   Accuracy: 44102/60000 (73.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6295,                   Accuracy: 49266/60000 (82.11%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2673,                   Accuracy: 55263/60000 (92.11%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1195,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0827,                   Accuracy: 58588/60000 (97.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1217,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2631,                   Accuracy: 55477/60000 (92.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5969,                   Accuracy: 50097/60000 (83.50%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9408,                   Accuracy: 45184/60000 (75.31%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9974,                   Accuracy: 44102/60000 (73.50%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6295,                   Accuracy: 49266/60000 (82.11%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2673,                   Accuracy: 55263/60000 (92.11%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1195,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0827,                   Accuracy: 58588/60000 (97.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1217,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2631,                   Accuracy: 55477/60000 (92.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5969,                   Accuracy: 50097/60000 (83.50%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9408,                   Accuracy: 45184/60000 (75.31%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9974,                   Accuracy: 44102/60000 (73.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6295,                   Accuracy: 49266/60000 (82.11%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2673,                   Accuracy: 55263/60000 (92.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1195,                   Accuracy: 57901/60000 (96.50%)
{0: tensor(97.6467), 10: tensor(96.3900), 20: tensor(92.4617), 30: tensor(83.4950), 40: tensor(75.3067), 50: tensor(73.5033), 60: tensor(82.1100), 70: tensor(92.1050), 80: tensor(96.5017), 90: tensor(97.6467), 100: tensor(96.3900), 110: tensor(92.4617), 120: tensor(83.4950), 130: tensor(75.3067), 140: tensor(73.5033), 150: tensor(82.1100), 160: tensor(92.1050), 170: tensor(96.5017), 180: tensor(97.6467), 190: tensor(96.3900), 200: tensor(92.4617), 210: tensor(83.4950), 220: tensor(75.3067), 230: tensor(73.5033), 240: tensor(82.1100), 250: tensor(92.1050), 260: tensor(96.5017), 270: tensor(97.6467), 280: tensor(96.3900), 290: tensor(92.4617), 300: tensor(83.4950), 310: tensor(75.3067), 320: tensor(73.5033), 330: tensor(82.1100), 340: tensor(92.1050), 350: tensor(96.5017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=37, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8478,                   Accuracy: 358/2000.0 (17.90%)



-= Testing valid =-
Test set: Average loss: 1.3190,                   Accuracy: 1017/2000.0 (50.85%)



-= Testing valid =-
Test set: Average loss: 0.6624,                   Accuracy: 1589/2000.0 (79.45%)



-= Testing valid =-
Test set: Average loss: 0.4884,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.2423,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1442,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.3306,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.2640,                   Accuracy: 1836/2000.0 (91.80%)



Epoch 10 train accuracy: 96.51%, valid accuracy 91.80%
-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 20 train accuracy: 98.06%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 30 train accuracy: 98.72%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.16%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 98.96%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0677,                   Accuracy: 58797/60000 (98.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1090,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2568,                   Accuracy: 55687/60000 (92.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5564,                   Accuracy: 50462/60000 (84.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8581,                   Accuracy: 45204/60000 (75.34%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9121,                   Accuracy: 43547/60000 (72.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6262,                   Accuracy: 48133/60000 (80.22%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2814,                   Accuracy: 54660/60000 (91.10%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1027,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0677,                   Accuracy: 58797/60000 (98.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1090,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2568,                   Accuracy: 55687/60000 (92.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5564,                   Accuracy: 50462/60000 (84.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8581,                   Accuracy: 45204/60000 (75.34%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9121,                   Accuracy: 43547/60000 (72.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6262,                   Accuracy: 48133/60000 (80.22%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2814,                   Accuracy: 54660/60000 (91.10%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1027,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0677,                   Accuracy: 58797/60000 (98.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1090,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2568,                   Accuracy: 55687/60000 (92.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5564,                   Accuracy: 50462/60000 (84.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8581,                   Accuracy: 45204/60000 (75.34%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9121,                   Accuracy: 43547/60000 (72.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6262,                   Accuracy: 48133/60000 (80.22%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2814,                   Accuracy: 54660/60000 (91.10%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1027,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0677,                   Accuracy: 58797/60000 (98.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1090,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2568,                   Accuracy: 55687/60000 (92.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5564,                   Accuracy: 50462/60000 (84.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8581,                   Accuracy: 45204/60000 (75.34%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9121,                   Accuracy: 43547/60000 (72.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6262,                   Accuracy: 48133/60000 (80.22%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2814,                   Accuracy: 54660/60000 (91.10%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1027,                   Accuracy: 58109/60000 (96.85%)
{0: tensor(97.9950), 10: tensor(96.8433), 20: tensor(92.8117), 30: tensor(84.1033), 40: tensor(75.3400), 50: tensor(72.5783), 60: tensor(80.2217), 70: tensor(91.1000), 80: tensor(96.8483), 90: tensor(97.9950), 100: tensor(96.8433), 110: tensor(92.8117), 120: tensor(84.1033), 130: tensor(75.3400), 140: tensor(72.5783), 150: tensor(80.2217), 160: tensor(91.1000), 170: tensor(96.8483), 180: tensor(97.9950), 190: tensor(96.8433), 200: tensor(92.8117), 210: tensor(84.1033), 220: tensor(75.3400), 230: tensor(72.5783), 240: tensor(80.2217), 250: tensor(91.1000), 260: tensor(96.8483), 270: tensor(97.9950), 280: tensor(96.8433), 290: tensor(92.8117), 300: tensor(84.1033), 310: tensor(75.3400), 320: tensor(72.5783), 330: tensor(80.2217), 340: tensor(91.1000), 350: tensor(96.8483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=38, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8989,                   Accuracy: 319/2000.0 (15.95%)



-= Testing valid =-
Test set: Average loss: 2.0640,                   Accuracy: 475/2000.0 (23.75%)



-= Testing valid =-
Test set: Average loss: 0.5367,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.5824,                   Accuracy: 1579/2000.0 (78.95%)



-= Testing valid =-
Test set: Average loss: 0.1943,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2648,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2288,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1559,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1571,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 10 train accuracy: 95.68%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.1584,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 20 train accuracy: 97.69%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 98.60%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 40 train accuracy: 98.81%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 99.07%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0784,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1473,                   Accuracy: 57319/60000 (95.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2838,                   Accuracy: 54956/60000 (91.59%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5808,                   Accuracy: 49684/60000 (82.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7756,                   Accuracy: 46231/60000 (77.05%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7776,                   Accuracy: 45660/60000 (76.10%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5359,                   Accuracy: 49778/60000 (82.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2574,                   Accuracy: 55249/60000 (92.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1217,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0784,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1473,                   Accuracy: 57319/60000 (95.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2838,                   Accuracy: 54956/60000 (91.59%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5808,                   Accuracy: 49684/60000 (82.81%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7756,                   Accuracy: 46231/60000 (77.05%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7776,                   Accuracy: 45660/60000 (76.10%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5359,                   Accuracy: 49778/60000 (82.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2574,                   Accuracy: 55249/60000 (92.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1217,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0784,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1473,                   Accuracy: 57319/60000 (95.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2838,                   Accuracy: 54956/60000 (91.59%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5808,                   Accuracy: 49684/60000 (82.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7756,                   Accuracy: 46231/60000 (77.05%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7776,                   Accuracy: 45660/60000 (76.10%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5359,                   Accuracy: 49778/60000 (82.96%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2574,                   Accuracy: 55249/60000 (92.08%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1217,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0784,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1473,                   Accuracy: 57319/60000 (95.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2838,                   Accuracy: 54956/60000 (91.59%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5808,                   Accuracy: 49684/60000 (82.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7756,                   Accuracy: 46231/60000 (77.05%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7776,                   Accuracy: 45660/60000 (76.10%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5359,                   Accuracy: 49778/60000 (82.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2574,                   Accuracy: 55249/60000 (92.08%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1217,                   Accuracy: 57808/60000 (96.35%)
{0: tensor(97.6867), 10: tensor(95.5317), 20: tensor(91.5933), 30: tensor(82.8067), 40: tensor(77.0517), 50: tensor(76.1000), 60: tensor(82.9633), 70: tensor(92.0817), 80: tensor(96.3467), 90: tensor(97.6867), 100: tensor(95.5317), 110: tensor(91.5933), 120: tensor(82.8067), 130: tensor(77.0517), 140: tensor(76.1000), 150: tensor(82.9633), 160: tensor(92.0817), 170: tensor(96.3467), 180: tensor(97.6867), 190: tensor(95.5317), 200: tensor(91.5933), 210: tensor(82.8067), 220: tensor(77.0517), 230: tensor(76.1000), 240: tensor(82.9633), 250: tensor(92.0817), 260: tensor(96.3467), 270: tensor(97.6867), 280: tensor(95.5317), 290: tensor(91.5933), 300: tensor(82.8067), 310: tensor(77.0517), 320: tensor(76.1000), 330: tensor(82.9633), 340: tensor(92.0817), 350: tensor(96.3467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=39, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0847,                   Accuracy: 274/2000.0 (13.70%)



-= Testing valid =-
Test set: Average loss: 1.7668,                   Accuracy: 785/2000.0 (39.25%)



-= Testing valid =-
Test set: Average loss: 1.0294,                   Accuracy: 1138/2000.0 (56.90%)



-= Testing valid =-
Test set: Average loss: 0.7744,                   Accuracy: 1404/2000.0 (70.20%)



-= Testing valid =-
Test set: Average loss: 0.3725,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.5366,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.3220,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.1939,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2244,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1520,                   Accuracy: 1900/2000.0 (95.00%)



Epoch 10 train accuracy: 95.89%, valid accuracy 95.00%
-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 98.01%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 30 train accuracy: 98.44%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 99.07%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 98.97%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0943,                   Accuracy: 58329/60000 (97.21%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1719,                   Accuracy: 56936/60000 (94.89%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3152,                   Accuracy: 54524/60000 (90.87%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5062,                   Accuracy: 51180/60000 (85.30%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7336,                   Accuracy: 47026/60000 (78.38%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7508,                   Accuracy: 46706/60000 (77.84%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5193,                   Accuracy: 50712/60000 (84.52%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2976,                   Accuracy: 54704/60000 (91.17%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1388,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0943,                   Accuracy: 58329/60000 (97.21%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1719,                   Accuracy: 56936/60000 (94.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3152,                   Accuracy: 54524/60000 (90.87%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5062,                   Accuracy: 51180/60000 (85.30%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7336,                   Accuracy: 47026/60000 (78.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7508,                   Accuracy: 46706/60000 (77.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5193,                   Accuracy: 50712/60000 (84.52%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2976,                   Accuracy: 54704/60000 (91.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1388,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0943,                   Accuracy: 58329/60000 (97.21%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1719,                   Accuracy: 56936/60000 (94.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3152,                   Accuracy: 54524/60000 (90.87%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5062,                   Accuracy: 51180/60000 (85.30%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7336,                   Accuracy: 47026/60000 (78.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7508,                   Accuracy: 46706/60000 (77.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5193,                   Accuracy: 50712/60000 (84.52%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2976,                   Accuracy: 54704/60000 (91.17%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1388,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0943,                   Accuracy: 58329/60000 (97.21%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1719,                   Accuracy: 56936/60000 (94.89%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3152,                   Accuracy: 54524/60000 (90.87%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5062,                   Accuracy: 51180/60000 (85.30%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7336,                   Accuracy: 47026/60000 (78.38%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7508,                   Accuracy: 46706/60000 (77.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5193,                   Accuracy: 50712/60000 (84.52%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2976,                   Accuracy: 54704/60000 (91.17%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1388,                   Accuracy: 57513/60000 (95.86%)
{0: tensor(97.2150), 10: tensor(94.8933), 20: tensor(90.8733), 30: tensor(85.3000), 40: tensor(78.3767), 50: tensor(77.8433), 60: tensor(84.5200), 70: tensor(91.1733), 80: tensor(95.8550), 90: tensor(97.2150), 100: tensor(94.8933), 110: tensor(90.8733), 120: tensor(85.3000), 130: tensor(78.3767), 140: tensor(77.8433), 150: tensor(84.5200), 160: tensor(91.1733), 170: tensor(95.8550), 180: tensor(97.2150), 190: tensor(94.8933), 200: tensor(90.8733), 210: tensor(85.3000), 220: tensor(78.3767), 230: tensor(77.8433), 240: tensor(84.5200), 250: tensor(91.1733), 260: tensor(95.8550), 270: tensor(97.2150), 280: tensor(94.8933), 290: tensor(90.8733), 300: tensor(85.3000), 310: tensor(78.3767), 320: tensor(77.8433), 330: tensor(84.5200), 340: tensor(91.1733), 350: tensor(95.8550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=40, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1294,                   Accuracy: 456/2000.0 (22.80%)



-= Testing valid =-
Test set: Average loss: 1.2661,                   Accuracy: 1157/2000.0 (57.85%)



-= Testing valid =-
Test set: Average loss: 1.3680,                   Accuracy: 945/2000.0 (47.25%)



-= Testing valid =-
Test set: Average loss: 0.3551,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3008,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.1475,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1623,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2702,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.1888,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2069,                   Accuracy: 1863/2000.0 (93.15%)



Epoch 10 train accuracy: 95.89%, valid accuracy 93.15%
-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 97.93%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 30 train accuracy: 98.53%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 40 train accuracy: 98.76%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.07%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0771,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1261,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2572,                   Accuracy: 55402/60000 (92.34%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6157,                   Accuracy: 49415/60000 (82.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0052,                   Accuracy: 42987/60000 (71.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0985,                   Accuracy: 41529/60000 (69.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7121,                   Accuracy: 47259/60000 (78.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3156,                   Accuracy: 54225/60000 (90.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1203,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0771,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1261,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2572,                   Accuracy: 55402/60000 (92.34%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6157,                   Accuracy: 49415/60000 (82.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0052,                   Accuracy: 42987/60000 (71.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0985,                   Accuracy: 41529/60000 (69.21%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7121,                   Accuracy: 47259/60000 (78.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3156,                   Accuracy: 54225/60000 (90.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1203,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0771,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1261,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2572,                   Accuracy: 55402/60000 (92.34%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6157,                   Accuracy: 49415/60000 (82.36%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0052,                   Accuracy: 42987/60000 (71.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0985,                   Accuracy: 41529/60000 (69.21%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7121,                   Accuracy: 47259/60000 (78.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3156,                   Accuracy: 54225/60000 (90.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1203,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0771,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1261,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2572,                   Accuracy: 55402/60000 (92.34%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6157,                   Accuracy: 49415/60000 (82.36%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0052,                   Accuracy: 42987/60000 (71.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0985,                   Accuracy: 41529/60000 (69.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7121,                   Accuracy: 47259/60000 (78.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3156,                   Accuracy: 54225/60000 (90.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1203,                   Accuracy: 57839/60000 (96.40%)
{0: tensor(97.7417), 10: tensor(96.2217), 20: tensor(92.3367), 30: tensor(82.3583), 40: tensor(71.6450), 50: tensor(69.2150), 60: tensor(78.7650), 70: tensor(90.3750), 80: tensor(96.3983), 90: tensor(97.7417), 100: tensor(96.2217), 110: tensor(92.3367), 120: tensor(82.3583), 130: tensor(71.6450), 140: tensor(69.2150), 150: tensor(78.7650), 160: tensor(90.3750), 170: tensor(96.3983), 180: tensor(97.7417), 190: tensor(96.2217), 200: tensor(92.3367), 210: tensor(82.3583), 220: tensor(71.6450), 230: tensor(69.2150), 240: tensor(78.7650), 250: tensor(90.3750), 260: tensor(96.3983), 270: tensor(97.7417), 280: tensor(96.2217), 290: tensor(92.3367), 300: tensor(82.3583), 310: tensor(71.6450), 320: tensor(69.2150), 330: tensor(78.7650), 340: tensor(90.3750), 350: tensor(96.3983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=11, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5774,                   Accuracy: 383/2000.0 (19.15%)



-= Testing valid =-
Test set: Average loss: 2.0161,                   Accuracy: 582/2000.0 (29.10%)



-= Testing valid =-
Test set: Average loss: 1.4826,                   Accuracy: 1188/2000.0 (59.40%)



-= Testing valid =-
Test set: Average loss: 0.4063,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.2263,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1906/2000.0 (95.30%)



Epoch 10 train accuracy: 98.26%, valid accuracy 95.30%
-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 20 train accuracy: 99.05%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.64%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.74%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.75%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0482,                   Accuracy: 59197/60000 (98.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0762,                   Accuracy: 58697/60000 (97.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1498,                   Accuracy: 57456/60000 (95.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3853,                   Accuracy: 53623/60000 (89.37%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7837,                   Accuracy: 47374/60000 (78.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0913,                   Accuracy: 42414/60000 (70.69%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0519,                   Accuracy: 42538/60000 (70.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8055,                   Accuracy: 45439/60000 (75.73%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6376,                   Accuracy: 48099/60000 (80.17%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4858,                   Accuracy: 50806/60000 (84.68%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7641,                   Accuracy: 45691/60000 (76.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1785,                   Accuracy: 40908/60000 (68.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9539,                   Accuracy: 33635/60000 (56.06%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8784,                   Accuracy: 26815/60000 (44.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4977,                   Accuracy: 24488/60000 (40.81%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7641,                   Accuracy: 25066/60000 (41.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7207,                   Accuracy: 27563/60000 (45.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8588,                   Accuracy: 29281/60000 (48.80%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7151,                   Accuracy: 29816/60000 (49.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8068,                   Accuracy: 29028/60000 (48.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8565,                   Accuracy: 27133/60000 (45.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8503,                   Accuracy: 24787/60000 (41.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6024,                   Accuracy: 23905/60000 (39.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9427,                   Accuracy: 26328/60000 (43.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9436,                   Accuracy: 32929/60000 (54.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1915,                   Accuracy: 40500/60000 (67.50%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7163,                   Accuracy: 46492/60000 (77.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4680,                   Accuracy: 50665/60000 (84.44%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5757,                   Accuracy: 48965/60000 (81.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7292,                   Accuracy: 46248/60000 (77.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9526,                   Accuracy: 43307/60000 (72.18%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1427,                   Accuracy: 41391/60000 (68.99%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0480,                   Accuracy: 43736/60000 (72.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6187,                   Accuracy: 49800/60000 (83.00%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2299,                   Accuracy: 55901/60000 (93.17%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0891,                   Accuracy: 58428/60000 (97.38%)
{0: tensor(98.6617), 10: tensor(97.8283), 20: tensor(95.7600), 30: tensor(89.3717), 40: tensor(78.9567), 50: tensor(70.6900), 60: tensor(70.8967), 70: tensor(75.7317), 80: tensor(80.1650), 90: tensor(84.6767), 100: tensor(76.1517), 110: tensor(68.1800), 120: tensor(56.0583), 130: tensor(44.6917), 140: tensor(40.8133), 150: tensor(41.7767), 160: tensor(45.9383), 170: tensor(48.8017), 180: tensor(49.6933), 190: tensor(48.3800), 200: tensor(45.2217), 210: tensor(41.3117), 220: tensor(39.8417), 230: tensor(43.8800), 240: tensor(54.8817), 250: tensor(67.5000), 260: tensor(77.4867), 270: tensor(84.4417), 280: tensor(81.6083), 290: tensor(77.0800), 300: tensor(72.1783), 310: tensor(68.9850), 320: tensor(72.8933), 330: tensor(83.), 340: tensor(93.1683), 350: tensor(97.3800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=12, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0851,                   Accuracy: 469/2000.0 (23.45%)



-= Testing valid =-
Test set: Average loss: 1.0323,                   Accuracy: 1281/2000.0 (64.05%)



-= Testing valid =-
Test set: Average loss: 0.4111,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3517,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.2989,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1421,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1681,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 10 train accuracy: 98.00%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.91%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.53%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.69%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0458,                   Accuracy: 59216/60000 (98.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0661,                   Accuracy: 58875/60000 (98.12%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1499,                   Accuracy: 57421/60000 (95.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4420,                   Accuracy: 52461/60000 (87.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8555,                   Accuracy: 45473/60000 (75.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1498,                   Accuracy: 40686/60000 (67.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1745,                   Accuracy: 39781/60000 (66.30%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8820,                   Accuracy: 44141/60000 (73.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7701,                   Accuracy: 45384/60000 (75.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6708,                   Accuracy: 47455/60000 (79.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9415,                   Accuracy: 43249/60000 (72.08%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5782,                   Accuracy: 36280/60000 (60.47%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4538,                   Accuracy: 29020/60000 (48.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1916,                   Accuracy: 24966/60000 (41.61%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6519,                   Accuracy: 23928/60000 (39.88%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8628,                   Accuracy: 25282/60000 (42.14%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.8263,                   Accuracy: 28608/60000 (47.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.0421,                   Accuracy: 29841/60000 (49.74%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.1658,                   Accuracy: 30928/60000 (51.55%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.1340,                   Accuracy: 30661/60000 (51.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.3532,                   Accuracy: 28767/60000 (47.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.5333,                   Accuracy: 25230/60000 (42.05%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.2173,                   Accuracy: 23233/60000 (38.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4797,                   Accuracy: 24564/60000 (40.94%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3888,                   Accuracy: 29601/60000 (49.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3765,                   Accuracy: 36782/60000 (61.30%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8086,                   Accuracy: 43380/60000 (72.30%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5321,                   Accuracy: 48381/60000 (80.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6677,                   Accuracy: 46024/60000 (76.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8797,                   Accuracy: 41967/60000 (69.94%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1684,                   Accuracy: 38752/60000 (64.59%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2749,                   Accuracy: 37710/60000 (62.85%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1583,                   Accuracy: 40981/60000 (68.30%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6752,                   Accuracy: 48258/60000 (80.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2294,                   Accuracy: 55653/60000 (92.75%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0776,                   Accuracy: 58588/60000 (97.65%)
{0: tensor(98.6933), 10: tensor(98.1250), 20: tensor(95.7017), 30: tensor(87.4350), 40: tensor(75.7883), 50: tensor(67.8100), 60: tensor(66.3017), 70: tensor(73.5683), 80: tensor(75.6400), 90: tensor(79.0917), 100: tensor(72.0817), 110: tensor(60.4667), 120: tensor(48.3667), 130: tensor(41.6100), 140: tensor(39.8800), 150: tensor(42.1367), 160: tensor(47.6800), 170: tensor(49.7350), 180: tensor(51.5467), 190: tensor(51.1017), 200: tensor(47.9450), 210: tensor(42.0500), 220: tensor(38.7217), 230: tensor(40.9400), 240: tensor(49.3350), 250: tensor(61.3033), 260: tensor(72.3000), 270: tensor(80.6350), 280: tensor(76.7067), 290: tensor(69.9450), 300: tensor(64.5867), 310: tensor(62.8500), 320: tensor(68.3017), 330: tensor(80.4300), 340: tensor(92.7550), 350: tensor(97.6467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=13, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 11.3257,                   Accuracy: 248/2000.0 (12.40%)



-= Testing valid =-
Test set: Average loss: 2.6522,                   Accuracy: 338/2000.0 (16.90%)



-= Testing valid =-
Test set: Average loss: 1.3391,                   Accuracy: 951/2000.0 (47.55%)



-= Testing valid =-
Test set: Average loss: 0.2938,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2088,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2505,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.4687,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 10 train accuracy: 97.81%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 98.85%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.50%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.60%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0487,                   Accuracy: 59125/60000 (98.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0784,                   Accuracy: 58634/60000 (97.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1764,                   Accuracy: 56956/60000 (94.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4450,                   Accuracy: 52620/60000 (87.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8415,                   Accuracy: 46437/60000 (77.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1432,                   Accuracy: 41439/60000 (69.07%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1888,                   Accuracy: 40421/60000 (67.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9716,                   Accuracy: 43277/60000 (72.13%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7679,                   Accuracy: 46074/60000 (76.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7425,                   Accuracy: 46322/60000 (77.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0186,                   Accuracy: 41950/60000 (69.92%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6394,                   Accuracy: 34657/60000 (57.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5322,                   Accuracy: 28775/60000 (47.96%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3755,                   Accuracy: 25038/60000 (41.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.1615,                   Accuracy: 23980/60000 (39.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.7639,                   Accuracy: 24706/60000 (41.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.0843,                   Accuracy: 27011/60000 (45.02%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.3450,                   Accuracy: 27557/60000 (45.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.6321,                   Accuracy: 27612/60000 (46.02%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.5984,                   Accuracy: 28120/60000 (46.87%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.6275,                   Accuracy: 26838/60000 (44.73%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.5596,                   Accuracy: 24596/60000 (40.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.9700,                   Accuracy: 23459/60000 (39.10%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.0724,                   Accuracy: 24463/60000 (40.77%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9888,                   Accuracy: 28076/60000 (46.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.0201,                   Accuracy: 33008/60000 (55.01%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2979,                   Accuracy: 38588/60000 (64.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.9729,                   Accuracy: 42170/60000 (70.28%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.0174,                   Accuracy: 41649/60000 (69.42%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1058,                   Accuracy: 41070/60000 (68.45%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3208,                   Accuracy: 40191/60000 (66.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3058,                   Accuracy: 40843/60000 (68.07%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0736,                   Accuracy: 44308/60000 (73.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5913,                   Accuracy: 50573/60000 (84.29%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1942,                   Accuracy: 56507/60000 (94.18%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0754,                   Accuracy: 58618/60000 (97.70%)
{0: tensor(98.5417), 10: tensor(97.7233), 20: tensor(94.9267), 30: tensor(87.7000), 40: tensor(77.3950), 50: tensor(69.0650), 60: tensor(67.3683), 70: tensor(72.1283), 80: tensor(76.7900), 90: tensor(77.2033), 100: tensor(69.9167), 110: tensor(57.7617), 120: tensor(47.9583), 130: tensor(41.7300), 140: tensor(39.9667), 150: tensor(41.1767), 160: tensor(45.0183), 170: tensor(45.9283), 180: tensor(46.0200), 190: tensor(46.8667), 200: tensor(44.7300), 210: tensor(40.9933), 220: tensor(39.0983), 230: tensor(40.7717), 240: tensor(46.7933), 250: tensor(55.0133), 260: tensor(64.3133), 270: tensor(70.2833), 280: tensor(69.4150), 290: tensor(68.4500), 300: tensor(66.9850), 310: tensor(68.0717), 320: tensor(73.8467), 330: tensor(84.2883), 340: tensor(94.1783), 350: tensor(97.6967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=14, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6068,                   Accuracy: 455/2000.0 (22.75%)



-= Testing valid =-
Test set: Average loss: 1.2954,                   Accuracy: 938/2000.0 (46.90%)



-= Testing valid =-
Test set: Average loss: 1.6840,                   Accuracy: 952/2000.0 (47.60%)



-= Testing valid =-
Test set: Average loss: 0.7055,                   Accuracy: 1571/2000.0 (78.55%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1751,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1923,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 10 train accuracy: 98.14%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 20 train accuracy: 98.88%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0522,                   Accuracy: 59122/60000 (98.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0838,                   Accuracy: 58561/60000 (97.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1952,                   Accuracy: 56662/60000 (94.44%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4634,                   Accuracy: 52179/60000 (86.96%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8658,                   Accuracy: 45278/60000 (75.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1172,                   Accuracy: 40970/60000 (68.28%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0185,                   Accuracy: 42219/60000 (70.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7788,                   Accuracy: 46042/60000 (76.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7350,                   Accuracy: 46551/60000 (77.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8945,                   Accuracy: 44734/60000 (74.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.5088,                   Accuracy: 37137/60000 (61.90%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.4053,                   Accuracy: 29174/60000 (48.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.4352,                   Accuracy: 22890/60000 (38.15%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.9628,                   Accuracy: 20611/60000 (34.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.1490,                   Accuracy: 20885/60000 (34.81%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.1745,                   Accuracy: 23093/60000 (38.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0397,                   Accuracy: 27190/60000 (45.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1908,                   Accuracy: 28663/60000 (47.77%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.3084,                   Accuracy: 29108/60000 (48.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.5047,                   Accuracy: 29086/60000 (48.48%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.7415,                   Accuracy: 27495/60000 (45.83%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.7586,                   Accuracy: 25024/60000 (41.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.3002,                   Accuracy: 24534/60000 (40.89%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5938,                   Accuracy: 26201/60000 (43.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5666,                   Accuracy: 30063/60000 (50.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6489,                   Accuracy: 36440/60000 (60.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9759,                   Accuracy: 42070/60000 (70.12%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6805,                   Accuracy: 46026/60000 (76.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7325,                   Accuracy: 45223/60000 (75.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9598,                   Accuracy: 41300/60000 (68.83%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2373,                   Accuracy: 36668/60000 (61.11%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1928,                   Accuracy: 37139/60000 (61.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9660,                   Accuracy: 41854/60000 (69.76%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5532,                   Accuracy: 49635/60000 (82.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2022,                   Accuracy: 56247/60000 (93.75%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0780,                   Accuracy: 58573/60000 (97.62%)
{0: tensor(98.5367), 10: tensor(97.6017), 20: tensor(94.4367), 30: tensor(86.9650), 40: tensor(75.4633), 50: tensor(68.2833), 60: tensor(70.3650), 70: tensor(76.7367), 80: tensor(77.5850), 90: tensor(74.5567), 100: tensor(61.8950), 110: tensor(48.6233), 120: tensor(38.1500), 130: tensor(34.3517), 140: tensor(34.8083), 150: tensor(38.4883), 160: tensor(45.3167), 170: tensor(47.7717), 180: tensor(48.5133), 190: tensor(48.4767), 200: tensor(45.8250), 210: tensor(41.7067), 220: tensor(40.8900), 230: tensor(43.6683), 240: tensor(50.1050), 250: tensor(60.7333), 260: tensor(70.1167), 270: tensor(76.7100), 280: tensor(75.3717), 290: tensor(68.8333), 300: tensor(61.1133), 310: tensor(61.8983), 320: tensor(69.7567), 330: tensor(82.7250), 340: tensor(93.7450), 350: tensor(97.6217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=15, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9844,                   Accuracy: 604/2000.0 (30.20%)



-= Testing valid =-
Test set: Average loss: 0.5845,                   Accuracy: 1605/2000.0 (80.25%)



-= Testing valid =-
Test set: Average loss: 0.2646,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2672,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1460,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1841,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 10 train accuracy: 98.26%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.06%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.43%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.72%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0458,                   Accuracy: 59235/60000 (98.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0714,                   Accuracy: 58779/60000 (97.96%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1576,                   Accuracy: 57363/60000 (95.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3690,                   Accuracy: 53738/60000 (89.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6975,                   Accuracy: 47880/60000 (79.80%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9374,                   Accuracy: 43461/60000 (72.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9068,                   Accuracy: 43730/60000 (72.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6973,                   Accuracy: 46892/60000 (78.15%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5310,                   Accuracy: 49677/60000 (82.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4260,                   Accuracy: 51780/60000 (86.30%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6140,                   Accuracy: 48110/60000 (80.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0528,                   Accuracy: 42145/60000 (70.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.5990,                   Accuracy: 35438/60000 (59.06%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.2653,                   Accuracy: 30347/60000 (50.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.6967,                   Accuracy: 28181/60000 (46.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.9355,                   Accuracy: 28652/60000 (47.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0466,                   Accuracy: 31025/60000 (51.71%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1846,                   Accuracy: 32669/60000 (54.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1661,                   Accuracy: 32559/60000 (54.26%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2795,                   Accuracy: 31502/60000 (52.50%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5418,                   Accuracy: 29666/60000 (49.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.5679,                   Accuracy: 26860/60000 (44.77%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4157,                   Accuracy: 26335/60000 (43.89%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8363,                   Accuracy: 28986/60000 (48.31%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9273,                   Accuracy: 35407/60000 (59.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0622,                   Accuracy: 42937/60000 (71.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5095,                   Accuracy: 50092/60000 (83.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3246,                   Accuracy: 53344/60000 (88.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4298,                   Accuracy: 51838/60000 (86.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6304,                   Accuracy: 48691/60000 (81.15%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8833,                   Accuracy: 44940/60000 (74.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0472,                   Accuracy: 42296/60000 (70.49%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9212,                   Accuracy: 44148/60000 (73.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5166,                   Accuracy: 50828/60000 (84.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1961,                   Accuracy: 56364/60000 (93.94%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0710,                   Accuracy: 58711/60000 (97.85%)
{0: tensor(98.7250), 10: tensor(97.9650), 20: tensor(95.6050), 30: tensor(89.5633), 40: tensor(79.8000), 50: tensor(72.4350), 60: tensor(72.8833), 70: tensor(78.1533), 80: tensor(82.7950), 90: tensor(86.3000), 100: tensor(80.1833), 110: tensor(70.2417), 120: tensor(59.0633), 130: tensor(50.5783), 140: tensor(46.9683), 150: tensor(47.7533), 160: tensor(51.7083), 170: tensor(54.4483), 180: tensor(54.2650), 190: tensor(52.5033), 200: tensor(49.4433), 210: tensor(44.7667), 220: tensor(43.8917), 230: tensor(48.3100), 240: tensor(59.0117), 250: tensor(71.5617), 260: tensor(83.4867), 270: tensor(88.9067), 280: tensor(86.3967), 290: tensor(81.1517), 300: tensor(74.9000), 310: tensor(70.4933), 320: tensor(73.5800), 330: tensor(84.7133), 340: tensor(93.9400), 350: tensor(97.8517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=16, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0751,                   Accuracy: 509/2000.0 (25.45%)



-= Testing valid =-
Test set: Average loss: 1.0658,                   Accuracy: 1343/2000.0 (67.15%)



-= Testing valid =-
Test set: Average loss: 0.7335,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.2601,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1608,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1668,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1853,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 98.49%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 20 train accuracy: 98.99%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.66%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.75%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0514,                   Accuracy: 59136/60000 (98.56%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0733,                   Accuracy: 58727/60000 (97.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1708,                   Accuracy: 57039/60000 (95.07%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4449,                   Accuracy: 52281/60000 (87.14%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8199,                   Accuracy: 45630/60000 (76.05%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0152,                   Accuracy: 42056/60000 (70.09%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9267,                   Accuracy: 43014/60000 (71.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6195,                   Accuracy: 47473/60000 (79.12%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4616,                   Accuracy: 49731/60000 (82.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4450,                   Accuracy: 50028/60000 (83.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6466,                   Accuracy: 47167/60000 (78.61%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2126,                   Accuracy: 41221/60000 (68.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0408,                   Accuracy: 32870/60000 (54.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8759,                   Accuracy: 27007/60000 (45.01%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3813,                   Accuracy: 24412/60000 (40.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5062,                   Accuracy: 24961/60000 (41.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2912,                   Accuracy: 27732/60000 (46.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1211,                   Accuracy: 30039/60000 (50.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0631,                   Accuracy: 30564/60000 (50.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2034,                   Accuracy: 30044/60000 (50.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4370,                   Accuracy: 27541/60000 (45.90%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6704,                   Accuracy: 24047/60000 (40.08%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6055,                   Accuracy: 22270/60000 (37.12%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2173,                   Accuracy: 24169/60000 (40.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.4505,                   Accuracy: 29855/60000 (49.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4116,                   Accuracy: 38832/60000 (64.72%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7435,                   Accuracy: 46801/60000 (78.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4486,                   Accuracy: 51696/60000 (86.16%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4632,                   Accuracy: 51373/60000 (85.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7289,                   Accuracy: 46956/60000 (78.26%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1395,                   Accuracy: 42402/60000 (70.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4299,                   Accuracy: 38746/60000 (64.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3430,                   Accuracy: 40383/60000 (67.31%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8699,                   Accuracy: 46807/60000 (78.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3307,                   Accuracy: 54525/60000 (90.88%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0895,                   Accuracy: 58399/60000 (97.33%)
{0: tensor(98.5600), 10: tensor(97.8783), 20: tensor(95.0650), 30: tensor(87.1350), 40: tensor(76.0500), 50: tensor(70.0933), 60: tensor(71.6900), 70: tensor(79.1217), 80: tensor(82.8850), 90: tensor(83.3800), 100: tensor(78.6117), 110: tensor(68.7017), 120: tensor(54.7833), 130: tensor(45.0117), 140: tensor(40.6867), 150: tensor(41.6017), 160: tensor(46.2200), 170: tensor(50.0650), 180: tensor(50.9400), 190: tensor(50.0733), 200: tensor(45.9017), 210: tensor(40.0783), 220: tensor(37.1167), 230: tensor(40.2817), 240: tensor(49.7583), 250: tensor(64.7200), 260: tensor(78.0017), 270: tensor(86.1600), 280: tensor(85.6217), 290: tensor(78.2600), 300: tensor(70.6700), 310: tensor(64.5767), 320: tensor(67.3050), 330: tensor(78.0117), 340: tensor(90.8750), 350: tensor(97.3317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=17, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.5854,                   Accuracy: 179/2000.0 (8.95%)



-= Testing valid =-
Test set: Average loss: 1.7885,                   Accuracy: 705/2000.0 (35.25%)



-= Testing valid =-
Test set: Average loss: 1.5394,                   Accuracy: 789/2000.0 (39.45%)



-= Testing valid =-
Test set: Average loss: 0.4863,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.1745,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1688,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 98.26%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.12%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.76%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.76%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0509,                   Accuracy: 59145/60000 (98.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0817,                   Accuracy: 58573/60000 (97.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1929,                   Accuracy: 56644/60000 (94.41%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4561,                   Accuracy: 52191/60000 (86.99%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8111,                   Accuracy: 46189/60000 (76.98%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0426,                   Accuracy: 42410/60000 (70.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9664,                   Accuracy: 43387/60000 (72.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7051,                   Accuracy: 47139/60000 (78.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5301,                   Accuracy: 49956/60000 (83.26%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4882,                   Accuracy: 50508/60000 (84.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7445,                   Accuracy: 45018/60000 (75.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2700,                   Accuracy: 36731/60000 (61.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9451,                   Accuracy: 30177/60000 (50.29%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7583,                   Accuracy: 24282/60000 (40.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1694,                   Accuracy: 22681/60000 (37.80%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2063,                   Accuracy: 24375/60000 (40.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1875,                   Accuracy: 26497/60000 (44.16%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1891,                   Accuracy: 27718/60000 (46.20%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2318,                   Accuracy: 28523/60000 (47.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4846,                   Accuracy: 27829/60000 (46.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7533,                   Accuracy: 25664/60000 (42.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8262,                   Accuracy: 23509/60000 (39.18%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5775,                   Accuracy: 22754/60000 (37.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8611,                   Accuracy: 25488/60000 (42.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9643,                   Accuracy: 32337/60000 (53.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1502,                   Accuracy: 41348/60000 (68.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6345,                   Accuracy: 48509/60000 (80.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4015,                   Accuracy: 52402/60000 (87.34%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5061,                   Accuracy: 50807/60000 (84.68%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7437,                   Accuracy: 46205/60000 (77.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9768,                   Accuracy: 42568/60000 (70.95%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0358,                   Accuracy: 41471/60000 (69.12%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8527,                   Accuracy: 44714/60000 (74.52%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4622,                   Accuracy: 51734/60000 (86.22%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1697,                   Accuracy: 56947/60000 (94.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0739,                   Accuracy: 58699/60000 (97.83%)
{0: tensor(98.5750), 10: tensor(97.6217), 20: tensor(94.4067), 30: tensor(86.9850), 40: tensor(76.9817), 50: tensor(70.6833), 60: tensor(72.3117), 70: tensor(78.5650), 80: tensor(83.2600), 90: tensor(84.1800), 100: tensor(75.0300), 110: tensor(61.2183), 120: tensor(50.2950), 130: tensor(40.4700), 140: tensor(37.8017), 150: tensor(40.6250), 160: tensor(44.1617), 170: tensor(46.1967), 180: tensor(47.5383), 190: tensor(46.3817), 200: tensor(42.7733), 210: tensor(39.1817), 220: tensor(37.9233), 230: tensor(42.4800), 240: tensor(53.8950), 250: tensor(68.9133), 260: tensor(80.8483), 270: tensor(87.3367), 280: tensor(84.6783), 290: tensor(77.0083), 300: tensor(70.9467), 310: tensor(69.1183), 320: tensor(74.5233), 330: tensor(86.2233), 340: tensor(94.9117), 350: tensor(97.8317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=18, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4814,                   Accuracy: 423/2000.0 (21.15%)



-= Testing valid =-
Test set: Average loss: 1.7692,                   Accuracy: 642/2000.0 (32.10%)



-= Testing valid =-
Test set: Average loss: 1.7152,                   Accuracy: 921/2000.0 (46.05%)



-= Testing valid =-
Test set: Average loss: 1.5611,                   Accuracy: 1315/2000.0 (65.75%)



-= Testing valid =-
Test set: Average loss: 0.3469,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.1666,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1958,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 10 train accuracy: 97.80%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 20 train accuracy: 98.96%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 30 train accuracy: 99.64%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.72%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0536,                   Accuracy: 59081/60000 (98.47%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0712,                   Accuracy: 58716/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1508,                   Accuracy: 57390/60000 (95.65%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4070,                   Accuracy: 52979/60000 (88.30%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7973,                   Accuracy: 46229/60000 (77.05%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1212,                   Accuracy: 40518/60000 (67.53%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0912,                   Accuracy: 39601/60000 (66.00%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7688,                   Accuracy: 44235/60000 (73.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6595,                   Accuracy: 46092/60000 (76.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7311,                   Accuracy: 45825/60000 (76.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8904,                   Accuracy: 43303/60000 (72.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3830,                   Accuracy: 38265/60000 (63.78%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2586,                   Accuracy: 32349/60000 (53.92%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0572,                   Accuracy: 26903/60000 (44.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6900,                   Accuracy: 24899/60000 (41.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.0013,                   Accuracy: 25255/60000 (42.09%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7768,                   Accuracy: 28067/60000 (46.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8925,                   Accuracy: 29582/60000 (49.30%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7961,                   Accuracy: 30451/60000 (50.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6576,                   Accuracy: 30320/60000 (50.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6357,                   Accuracy: 28890/60000 (48.15%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6847,                   Accuracy: 26699/60000 (44.50%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4978,                   Accuracy: 25318/60000 (42.20%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9847,                   Accuracy: 27082/60000 (45.14%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1470,                   Accuracy: 32491/60000 (54.15%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2849,                   Accuracy: 40949/60000 (68.25%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6377,                   Accuracy: 48465/60000 (80.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4313,                   Accuracy: 51052/60000 (85.09%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4825,                   Accuracy: 50451/60000 (84.08%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6506,                   Accuracy: 47490/60000 (79.15%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0632,                   Accuracy: 40924/60000 (68.21%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2403,                   Accuracy: 37485/60000 (62.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2032,                   Accuracy: 39688/60000 (66.15%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7517,                   Accuracy: 46885/60000 (78.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2587,                   Accuracy: 55251/60000 (92.08%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0914,                   Accuracy: 58346/60000 (97.24%)
{0: tensor(98.4683), 10: tensor(97.8600), 20: tensor(95.6500), 30: tensor(88.2983), 40: tensor(77.0483), 50: tensor(67.5300), 60: tensor(66.0017), 70: tensor(73.7250), 80: tensor(76.8200), 90: tensor(76.3750), 100: tensor(72.1717), 110: tensor(63.7750), 120: tensor(53.9150), 130: tensor(44.8383), 140: tensor(41.4983), 150: tensor(42.0917), 160: tensor(46.7783), 170: tensor(49.3033), 180: tensor(50.7517), 190: tensor(50.5333), 200: tensor(48.1500), 210: tensor(44.4983), 220: tensor(42.1967), 230: tensor(45.1367), 240: tensor(54.1517), 250: tensor(68.2483), 260: tensor(80.7750), 270: tensor(85.0867), 280: tensor(84.0850), 290: tensor(79.1500), 300: tensor(68.2067), 310: tensor(62.4750), 320: tensor(66.1467), 330: tensor(78.1417), 340: tensor(92.0850), 350: tensor(97.2433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=19, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.4502,                   Accuracy: 248/2000.0 (12.40%)



-= Testing valid =-
Test set: Average loss: 2.3437,                   Accuracy: 389/2000.0 (19.45%)



-= Testing valid =-
Test set: Average loss: 1.7553,                   Accuracy: 1053/2000.0 (52.65%)



-= Testing valid =-
Test set: Average loss: 0.3739,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2605,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2358,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.5766,                   Accuracy: 1589/2000.0 (79.45%)



-= Testing valid =-
Test set: Average loss: 0.4201,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.7462,                   Accuracy: 1668/2000.0 (83.40%)



Epoch 10 train accuracy: 97.81%, valid accuracy 83.40%
-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.5982,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.3785,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.8013,                   Accuracy: 1701/2000.0 (85.05%)



-= Testing valid =-
Test set: Average loss: 0.9812,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.6959,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1833,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 20 train accuracy: 98.86%, valid accuracy 93.95%
-= Testing valid =-
Test set: Average loss: 0.1539,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2630,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3976,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.3592,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.1891,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.8808,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.5398,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.28%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.3975,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.2517,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.2645,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.1605,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.2198,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.2856,                   Accuracy: 1822/2000.0 (91.10%)



Epoch 40 train accuracy: 99.57%, valid accuracy 91.10%
-= Testing valid =-
Test set: Average loss: 0.2096,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2017,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.3198,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.1553,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1380,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1756,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1509,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1666,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 50 train accuracy: 99.66%, valid accuracy 95.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0599,                   Accuracy: 58971/60000 (98.29%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0907,                   Accuracy: 58394/60000 (97.32%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1944,                   Accuracy: 56546/60000 (94.24%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5388,                   Accuracy: 51053/60000 (85.09%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9944,                   Accuracy: 44196/60000 (73.66%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3431,                   Accuracy: 38750/60000 (64.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2282,                   Accuracy: 38900/60000 (64.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9811,                   Accuracy: 41204/60000 (68.67%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8677,                   Accuracy: 42953/60000 (71.59%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7566,                   Accuracy: 45322/60000 (75.54%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1203,                   Accuracy: 40433/60000 (67.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7839,                   Accuracy: 33167/60000 (55.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.8624,                   Accuracy: 25943/60000 (43.24%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5801,                   Accuracy: 22242/60000 (37.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8980,                   Accuracy: 21753/60000 (36.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8470,                   Accuracy: 23654/60000 (39.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6608,                   Accuracy: 27026/60000 (45.04%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5629,                   Accuracy: 28093/60000 (46.82%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4977,                   Accuracy: 28828/60000 (48.05%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4925,                   Accuracy: 27927/60000 (46.54%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6954,                   Accuracy: 25979/60000 (43.30%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9033,                   Accuracy: 22698/60000 (37.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9160,                   Accuracy: 21259/60000 (35.43%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4847,                   Accuracy: 22629/60000 (37.72%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5629,                   Accuracy: 27421/60000 (45.70%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6166,                   Accuracy: 35891/60000 (59.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9665,                   Accuracy: 42541/60000 (70.90%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6138,                   Accuracy: 48420/60000 (80.70%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7103,                   Accuracy: 46494/60000 (77.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8621,                   Accuracy: 44252/60000 (73.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3060,                   Accuracy: 39069/60000 (65.11%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4511,                   Accuracy: 37787/60000 (62.98%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2928,                   Accuracy: 40199/60000 (67.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7228,                   Accuracy: 48040/60000 (80.07%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2210,                   Accuracy: 55953/60000 (93.25%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0964,                   Accuracy: 58320/60000 (97.20%)
{0: tensor(98.2850), 10: tensor(97.3233), 20: tensor(94.2433), 30: tensor(85.0883), 40: tensor(73.6600), 50: tensor(64.5833), 60: tensor(64.8333), 70: tensor(68.6733), 80: tensor(71.5883), 90: tensor(75.5367), 100: tensor(67.3883), 110: tensor(55.2783), 120: tensor(43.2383), 130: tensor(37.0700), 140: tensor(36.2550), 150: tensor(39.4233), 160: tensor(45.0433), 170: tensor(46.8217), 180: tensor(48.0467), 190: tensor(46.5450), 200: tensor(43.2983), 210: tensor(37.8300), 220: tensor(35.4317), 230: tensor(37.7150), 240: tensor(45.7017), 250: tensor(59.8183), 260: tensor(70.9017), 270: tensor(80.7000), 280: tensor(77.4900), 290: tensor(73.7533), 300: tensor(65.1150), 310: tensor(62.9783), 320: tensor(66.9983), 330: tensor(80.0667), 340: tensor(93.2550), 350: tensor(97.2000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=20, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3632,                   Accuracy: 409/2000.0 (20.45%)



-= Testing valid =-
Test set: Average loss: 2.2973,                   Accuracy: 463/2000.0 (23.15%)



-= Testing valid =-
Test set: Average loss: 0.5457,                   Accuracy: 1659/2000.0 (82.95%)



-= Testing valid =-
Test set: Average loss: 0.1587,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1706,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1937,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1636,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 10 train accuracy: 97.93%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.16%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.45%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.61%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0427,                   Accuracy: 59249/60000 (98.75%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0697,                   Accuracy: 58788/60000 (97.98%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1416,                   Accuracy: 57562/60000 (95.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2899,                   Accuracy: 54926/60000 (91.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6013,                   Accuracy: 49385/60000 (82.31%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8567,                   Accuracy: 44621/60000 (74.37%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9330,                   Accuracy: 43036/60000 (71.73%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9502,                   Accuracy: 41581/60000 (69.30%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8638,                   Accuracy: 42936/60000 (71.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8539,                   Accuracy: 44152/60000 (73.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3783,                   Accuracy: 36634/60000 (61.06%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.0886,                   Accuracy: 29334/60000 (48.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.0298,                   Accuracy: 23289/60000 (38.81%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.8751,                   Accuracy: 20948/60000 (34.91%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.3395,                   Accuracy: 21291/60000 (35.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.4727,                   Accuracy: 23448/60000 (39.08%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.2747,                   Accuracy: 26071/60000 (43.45%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.2145,                   Accuracy: 27244/60000 (45.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.3235,                   Accuracy: 27654/60000 (46.09%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.0950,                   Accuracy: 28219/60000 (47.03%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.0228,                   Accuracy: 27299/60000 (45.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0170,                   Accuracy: 25483/60000 (42.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6927,                   Accuracy: 25107/60000 (41.85%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0542,                   Accuracy: 27162/60000 (45.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2985,                   Accuracy: 31446/60000 (52.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6541,                   Accuracy: 36042/60000 (60.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9981,                   Accuracy: 42866/60000 (71.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6129,                   Accuracy: 47837/60000 (79.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6734,                   Accuracy: 47044/60000 (78.41%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8750,                   Accuracy: 43629/60000 (72.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1353,                   Accuracy: 40345/60000 (67.24%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1733,                   Accuracy: 39614/60000 (66.02%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0299,                   Accuracy: 41960/60000 (69.93%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6232,                   Accuracy: 48778/60000 (81.30%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2627,                   Accuracy: 55213/60000 (92.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0826,                   Accuracy: 58471/60000 (97.45%)
{0: tensor(98.7483), 10: tensor(97.9800), 20: tensor(95.9367), 30: tensor(91.5433), 40: tensor(82.3083), 50: tensor(74.3683), 60: tensor(71.7267), 70: tensor(69.3017), 80: tensor(71.5600), 90: tensor(73.5867), 100: tensor(61.0567), 110: tensor(48.8900), 120: tensor(38.8150), 130: tensor(34.9133), 140: tensor(35.4850), 150: tensor(39.0800), 160: tensor(43.4517), 170: tensor(45.4067), 180: tensor(46.0900), 190: tensor(47.0317), 200: tensor(45.4983), 210: tensor(42.4717), 220: tensor(41.8450), 230: tensor(45.2700), 240: tensor(52.4100), 250: tensor(60.0700), 260: tensor(71.4433), 270: tensor(79.7283), 280: tensor(78.4067), 290: tensor(72.7150), 300: tensor(67.2417), 310: tensor(66.0233), 320: tensor(69.9333), 330: tensor(81.2967), 340: tensor(92.0217), 350: tensor(97.4517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=21, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0848,                   Accuracy: 486/2000.0 (24.30%)



-= Testing valid =-
Test set: Average loss: 1.0720,                   Accuracy: 1262/2000.0 (63.10%)



-= Testing valid =-
Test set: Average loss: 1.2379,                   Accuracy: 1393/2000.0 (69.65%)



-= Testing valid =-
Test set: Average loss: 1.5663,                   Accuracy: 1197/2000.0 (59.85%)



-= Testing valid =-
Test set: Average loss: 0.2554,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.8781,                   Accuracy: 1486/2000.0 (74.30%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1896,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 10 train accuracy: 97.90%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 1.0741,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 20 train accuracy: 99.12%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.46%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.68%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.61%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0514,                   Accuracy: 59066/60000 (98.44%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0854,                   Accuracy: 58546/60000 (97.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2347,                   Accuracy: 56073/60000 (93.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5943,                   Accuracy: 50711/60000 (84.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0778,                   Accuracy: 43660/60000 (72.77%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.4535,                   Accuracy: 37892/60000 (63.15%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3295,                   Accuracy: 38655/60000 (64.43%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8689,                   Accuracy: 44079/60000 (73.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6985,                   Accuracy: 47125/60000 (78.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7870,                   Accuracy: 45470/60000 (75.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2780,                   Accuracy: 39196/60000 (65.33%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.2995,                   Accuracy: 30465/60000 (50.78%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.3096,                   Accuracy: 23665/60000 (39.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.9207,                   Accuracy: 20529/60000 (34.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.0353,                   Accuracy: 20633/60000 (34.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9335,                   Accuracy: 22667/60000 (37.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5584,                   Accuracy: 27533/60000 (45.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5477,                   Accuracy: 30126/60000 (50.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6630,                   Accuracy: 29876/60000 (49.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5379,                   Accuracy: 30613/60000 (51.02%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6125,                   Accuracy: 28860/60000 (48.10%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7924,                   Accuracy: 25463/60000 (42.44%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6578,                   Accuracy: 23534/60000 (39.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1986,                   Accuracy: 23827/60000 (39.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.4353,                   Accuracy: 27999/60000 (46.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6906,                   Accuracy: 34804/60000 (58.01%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0913,                   Accuracy: 40625/60000 (67.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7442,                   Accuracy: 46293/60000 (77.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8832,                   Accuracy: 43963/60000 (73.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2293,                   Accuracy: 38513/60000 (64.19%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4898,                   Accuracy: 35447/60000 (59.08%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6149,                   Accuracy: 34070/60000 (56.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4094,                   Accuracy: 37614/60000 (62.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7733,                   Accuracy: 47226/60000 (78.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2483,                   Accuracy: 55508/60000 (92.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0854,                   Accuracy: 58493/60000 (97.49%)
{0: tensor(98.4433), 10: tensor(97.5767), 20: tensor(93.4550), 30: tensor(84.5183), 40: tensor(72.7667), 50: tensor(63.1533), 60: tensor(64.4250), 70: tensor(73.4650), 80: tensor(78.5417), 90: tensor(75.7833), 100: tensor(65.3267), 110: tensor(50.7750), 120: tensor(39.4417), 130: tensor(34.2150), 140: tensor(34.3883), 150: tensor(37.7783), 160: tensor(45.8883), 170: tensor(50.2100), 180: tensor(49.7933), 190: tensor(51.0217), 200: tensor(48.1000), 210: tensor(42.4383), 220: tensor(39.2233), 230: tensor(39.7117), 240: tensor(46.6650), 250: tensor(58.0067), 260: tensor(67.7083), 270: tensor(77.1550), 280: tensor(73.2717), 290: tensor(64.1883), 300: tensor(59.0783), 310: tensor(56.7833), 320: tensor(62.6900), 330: tensor(78.7100), 340: tensor(92.5133), 350: tensor(97.4883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=22, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9778,                   Accuracy: 410/2000.0 (20.50%)



-= Testing valid =-
Test set: Average loss: 0.9018,                   Accuracy: 1330/2000.0 (66.50%)



-= Testing valid =-
Test set: Average loss: 0.9768,                   Accuracy: 1317/2000.0 (65.85%)



-= Testing valid =-
Test set: Average loss: 0.1709,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 10 train accuracy: 98.20%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 20 train accuracy: 99.34%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 99.54%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 99.68%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 50 train accuracy: 99.78%, valid accuracy 98.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0596,                   Accuracy: 58925/60000 (98.21%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0894,                   Accuracy: 58469/60000 (97.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1909,                   Accuracy: 56683/60000 (94.47%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4740,                   Accuracy: 51760/60000 (86.27%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8582,                   Accuracy: 44971/60000 (74.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1129,                   Accuracy: 40439/60000 (67.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0472,                   Accuracy: 41305/60000 (68.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7702,                   Accuracy: 45720/60000 (76.20%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5957,                   Accuracy: 48228/60000 (80.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5726,                   Accuracy: 48209/60000 (80.35%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7244,                   Accuracy: 45449/60000 (75.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1878,                   Accuracy: 37778/60000 (62.96%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0231,                   Accuracy: 28102/60000 (46.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7576,                   Accuracy: 23146/60000 (38.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1461,                   Accuracy: 22373/60000 (37.29%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2565,                   Accuracy: 23988/60000 (39.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0731,                   Accuracy: 28660/60000 (47.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0039,                   Accuracy: 31733/60000 (52.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1342,                   Accuracy: 32740/60000 (54.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2558,                   Accuracy: 32359/60000 (53.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4563,                   Accuracy: 30069/60000 (50.12%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6000,                   Accuracy: 26332/60000 (43.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3431,                   Accuracy: 25137/60000 (41.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8026,                   Accuracy: 27132/60000 (45.22%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9917,                   Accuracy: 33265/60000 (55.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1732,                   Accuracy: 42016/60000 (70.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6065,                   Accuracy: 49391/60000 (82.32%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3810,                   Accuracy: 52926/60000 (88.21%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4513,                   Accuracy: 51398/60000 (85.66%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6706,                   Accuracy: 46911/60000 (78.18%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0553,                   Accuracy: 40683/60000 (67.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1945,                   Accuracy: 37872/60000 (63.12%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1016,                   Accuracy: 39415/60000 (65.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6796,                   Accuracy: 46479/60000 (77.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2576,                   Accuracy: 54743/60000 (91.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0882,                   Accuracy: 58330/60000 (97.22%)
{0: tensor(98.2083), 10: tensor(97.4483), 20: tensor(94.4717), 30: tensor(86.2667), 40: tensor(74.9517), 50: tensor(67.3983), 60: tensor(68.8417), 70: tensor(76.2000), 80: tensor(80.3800), 90: tensor(80.3483), 100: tensor(75.7483), 110: tensor(62.9633), 120: tensor(46.8367), 130: tensor(38.5767), 140: tensor(37.2883), 150: tensor(39.9800), 160: tensor(47.7667), 170: tensor(52.8883), 180: tensor(54.5667), 190: tensor(53.9317), 200: tensor(50.1150), 210: tensor(43.8867), 220: tensor(41.8950), 230: tensor(45.2200), 240: tensor(55.4417), 250: tensor(70.0267), 260: tensor(82.3183), 270: tensor(88.2100), 280: tensor(85.6633), 290: tensor(78.1850), 300: tensor(67.8050), 310: tensor(63.1200), 320: tensor(65.6917), 330: tensor(77.4650), 340: tensor(91.2383), 350: tensor(97.2167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=23, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.1439,                   Accuracy: 219/2000.0 (10.95%)



-= Testing valid =-
Test set: Average loss: 1.3114,                   Accuracy: 1078/2000.0 (53.90%)



-= Testing valid =-
Test set: Average loss: 1.3771,                   Accuracy: 1170/2000.0 (58.50%)



-= Testing valid =-
Test set: Average loss: 1.2056,                   Accuracy: 1238/2000.0 (61.90%)



-= Testing valid =-
Test set: Average loss: 0.5006,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 10 train accuracy: 98.06%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 99.25%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.47%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.59%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0504,                   Accuracy: 59128/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0766,                   Accuracy: 58669/60000 (97.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2017,                   Accuracy: 56429/60000 (94.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4848,                   Accuracy: 51443/60000 (85.74%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9061,                   Accuracy: 44078/60000 (73.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2315,                   Accuracy: 38265/60000 (63.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2258,                   Accuracy: 37411/60000 (62.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0721,                   Accuracy: 38076/60000 (63.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9382,                   Accuracy: 40450/60000 (67.42%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.0845,                   Accuracy: 37909/60000 (63.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3903,                   Accuracy: 33828/60000 (56.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9709,                   Accuracy: 29431/60000 (49.05%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5949,                   Accuracy: 25301/60000 (42.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2110,                   Accuracy: 23119/60000 (38.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5383,                   Accuracy: 23439/60000 (39.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5968,                   Accuracy: 25031/60000 (41.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6533,                   Accuracy: 27158/60000 (45.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7238,                   Accuracy: 28759/60000 (47.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.0368,                   Accuracy: 29313/60000 (48.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.9014,                   Accuracy: 29531/60000 (49.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9937,                   Accuracy: 27362/60000 (45.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.1807,                   Accuracy: 24851/60000 (41.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9764,                   Accuracy: 23566/60000 (39.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5032,                   Accuracy: 25004/60000 (41.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7885,                   Accuracy: 28563/60000 (47.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.8693,                   Accuracy: 33294/60000 (55.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.1102,                   Accuracy: 39989/60000 (66.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7254,                   Accuracy: 46105/60000 (76.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8495,                   Accuracy: 44086/60000 (73.48%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1868,                   Accuracy: 38888/60000 (64.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3428,                   Accuracy: 36369/60000 (60.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3895,                   Accuracy: 35833/60000 (59.72%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1670,                   Accuracy: 39525/60000 (65.88%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6156,                   Accuracy: 48008/60000 (80.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2485,                   Accuracy: 55058/60000 (91.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0824,                   Accuracy: 58477/60000 (97.46%)
{0: tensor(98.5467), 10: tensor(97.7817), 20: tensor(94.0483), 30: tensor(85.7383), 40: tensor(73.4633), 50: tensor(63.7750), 60: tensor(62.3517), 70: tensor(63.4600), 80: tensor(67.4167), 90: tensor(63.1817), 100: tensor(56.3800), 110: tensor(49.0517), 120: tensor(42.1683), 130: tensor(38.5317), 140: tensor(39.0650), 150: tensor(41.7183), 160: tensor(45.2633), 170: tensor(47.9317), 180: tensor(48.8550), 190: tensor(49.2183), 200: tensor(45.6033), 210: tensor(41.4183), 220: tensor(39.2767), 230: tensor(41.6733), 240: tensor(47.6050), 250: tensor(55.4900), 260: tensor(66.6483), 270: tensor(76.8417), 280: tensor(73.4767), 290: tensor(64.8133), 300: tensor(60.6150), 310: tensor(59.7217), 320: tensor(65.8750), 330: tensor(80.0133), 340: tensor(91.7633), 350: tensor(97.4617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=24, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7353,                   Accuracy: 861/2000.0 (43.05%)



-= Testing valid =-
Test set: Average loss: 3.5899,                   Accuracy: 398/2000.0 (19.90%)



-= Testing valid =-
Test set: Average loss: 0.3410,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2843,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.5749,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.5255,                   Accuracy: 1673/2000.0 (83.65%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.5702,                   Accuracy: 1633/2000.0 (81.65%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 97.97%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.16%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.43%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.68%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0498,                   Accuracy: 59147/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0802,                   Accuracy: 58638/60000 (97.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1785,                   Accuracy: 57035/60000 (95.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4163,                   Accuracy: 53016/60000 (88.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7175,                   Accuracy: 47660/60000 (79.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8684,                   Accuracy: 44444/60000 (74.07%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7748,                   Accuracy: 45623/60000 (76.04%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5406,                   Accuracy: 49765/60000 (82.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3878,                   Accuracy: 52783/60000 (87.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3726,                   Accuracy: 53384/60000 (88.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6937,                   Accuracy: 47914/60000 (79.86%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4620,                   Accuracy: 39072/60000 (65.12%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5456,                   Accuracy: 29245/60000 (48.74%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4393,                   Accuracy: 22996/60000 (38.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7640,                   Accuracy: 21209/60000 (35.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7336,                   Accuracy: 23358/60000 (38.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5612,                   Accuracy: 26961/60000 (44.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3325,                   Accuracy: 30969/60000 (51.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1521,                   Accuracy: 33525/60000 (55.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3707,                   Accuracy: 30654/60000 (51.09%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5440,                   Accuracy: 27940/60000 (46.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6359,                   Accuracy: 24034/60000 (40.06%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5067,                   Accuracy: 22460/60000 (37.43%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9535,                   Accuracy: 24859/60000 (41.43%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1148,                   Accuracy: 30582/60000 (50.97%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2647,                   Accuracy: 38222/60000 (63.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6935,                   Accuracy: 45741/60000 (76.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4313,                   Accuracy: 50629/60000 (84.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5557,                   Accuracy: 48498/60000 (80.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8378,                   Accuracy: 44778/60000 (74.63%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3313,                   Accuracy: 38023/60000 (63.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6202,                   Accuracy: 35125/60000 (58.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4705,                   Accuracy: 38096/60000 (63.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8635,                   Accuracy: 46614/60000 (77.69%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3094,                   Accuracy: 54879/60000 (91.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0866,                   Accuracy: 58465/60000 (97.44%)
{0: tensor(98.5783), 10: tensor(97.7300), 20: tensor(95.0583), 30: tensor(88.3600), 40: tensor(79.4333), 50: tensor(74.0733), 60: tensor(76.0383), 70: tensor(82.9417), 80: tensor(87.9717), 90: tensor(88.9733), 100: tensor(79.8567), 110: tensor(65.1200), 120: tensor(48.7417), 130: tensor(38.3267), 140: tensor(35.3483), 150: tensor(38.9300), 160: tensor(44.9350), 170: tensor(51.6150), 180: tensor(55.8750), 190: tensor(51.0900), 200: tensor(46.5667), 210: tensor(40.0567), 220: tensor(37.4333), 230: tensor(41.4317), 240: tensor(50.9700), 250: tensor(63.7033), 260: tensor(76.2350), 270: tensor(84.3817), 280: tensor(80.8300), 290: tensor(74.6300), 300: tensor(63.3717), 310: tensor(58.5417), 320: tensor(63.4933), 330: tensor(77.6900), 340: tensor(91.4650), 350: tensor(97.4417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=25, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6361,                   Accuracy: 771/2000.0 (38.55%)



-= Testing valid =-
Test set: Average loss: 1.0510,                   Accuracy: 1288/2000.0 (64.40%)



-= Testing valid =-
Test set: Average loss: 0.4335,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.1658,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1480,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 10 train accuracy: 98.22%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.10%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.51%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.55%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.51%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0587,                   Accuracy: 59007/60000 (98.35%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0930,                   Accuracy: 58471/60000 (97.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2318,                   Accuracy: 56242/60000 (93.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6558,                   Accuracy: 49907/60000 (83.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1817,                   Accuracy: 42630/60000 (71.05%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.4987,                   Accuracy: 37429/60000 (62.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.4819,                   Accuracy: 36460/60000 (60.77%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.2671,                   Accuracy: 37951/60000 (63.25%)
-= Testing Rotation 80 =-
Test set: Average loss: 1.0839,                   Accuracy: 39730/60000 (66.22%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9791,                   Accuracy: 40982/60000 (68.30%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.4891,                   Accuracy: 34914/60000 (58.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.0992,                   Accuracy: 29844/60000 (49.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7967,                   Accuracy: 24445/60000 (40.74%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3505,                   Accuracy: 21579/60000 (35.97%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6759,                   Accuracy: 20949/60000 (34.92%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9372,                   Accuracy: 22207/60000 (37.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0409,                   Accuracy: 24837/60000 (41.40%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.3394,                   Accuracy: 26558/60000 (44.26%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.2673,                   Accuracy: 27271/60000 (45.45%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.6022,                   Accuracy: 26855/60000 (44.76%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.8419,                   Accuracy: 24781/60000 (41.30%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.9254,                   Accuracy: 22696/60000 (37.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.4454,                   Accuracy: 22694/60000 (37.82%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5475,                   Accuracy: 25074/60000 (41.79%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.4063,                   Accuracy: 30904/60000 (51.51%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4338,                   Accuracy: 37676/60000 (62.79%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8969,                   Accuracy: 43396/60000 (72.33%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6678,                   Accuracy: 46546/60000 (77.58%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8870,                   Accuracy: 42868/60000 (71.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0806,                   Accuracy: 40972/60000 (68.29%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3424,                   Accuracy: 38202/60000 (63.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2998,                   Accuracy: 38749/60000 (64.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0387,                   Accuracy: 43365/60000 (72.28%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5656,                   Accuracy: 50644/60000 (84.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1949,                   Accuracy: 56561/60000 (94.27%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0790,                   Accuracy: 58567/60000 (97.61%)
{0: tensor(98.3450), 10: tensor(97.4517), 20: tensor(93.7367), 30: tensor(83.1783), 40: tensor(71.0500), 50: tensor(62.3817), 60: tensor(60.7667), 70: tensor(63.2517), 80: tensor(66.2167), 90: tensor(68.3033), 100: tensor(58.1900), 110: tensor(49.7400), 120: tensor(40.7417), 130: tensor(35.9650), 140: tensor(34.9150), 150: tensor(37.0117), 160: tensor(41.3950), 170: tensor(44.2633), 180: tensor(45.4517), 190: tensor(44.7583), 200: tensor(41.3017), 210: tensor(37.8267), 220: tensor(37.8233), 230: tensor(41.7900), 240: tensor(51.5067), 250: tensor(62.7933), 260: tensor(72.3267), 270: tensor(77.5767), 280: tensor(71.4467), 290: tensor(68.2867), 300: tensor(63.6700), 310: tensor(64.5817), 320: tensor(72.2750), 330: tensor(84.4067), 340: tensor(94.2683), 350: tensor(97.6117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=26, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2989,                   Accuracy: 378/2000.0 (18.90%)



-= Testing valid =-
Test set: Average loss: 1.9425,                   Accuracy: 547/2000.0 (27.35%)



-= Testing valid =-
Test set: Average loss: 1.0144,                   Accuracy: 1290/2000.0 (64.50%)



-= Testing valid =-
Test set: Average loss: 0.9297,                   Accuracy: 1366/2000.0 (68.30%)



-= Testing valid =-
Test set: Average loss: 2.6949,                   Accuracy: 692/2000.0 (34.60%)



-= Testing valid =-
Test set: Average loss: 0.3663,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.2684,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.1682,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.3532,                   Accuracy: 1805/2000.0 (90.25%)



Epoch 10 train accuracy: 97.41%, valid accuracy 90.25%
-= Testing valid =-
Test set: Average loss: 0.1703,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.3394,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1387,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 20 train accuracy: 98.89%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 99.12%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 99.50%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.56%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0624,                   Accuracy: 58893/60000 (98.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0913,                   Accuracy: 58402/60000 (97.34%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1793,                   Accuracy: 56977/60000 (94.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4569,                   Accuracy: 52381/60000 (87.30%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8343,                   Accuracy: 46333/60000 (77.22%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2046,                   Accuracy: 40350/60000 (67.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3586,                   Accuracy: 37045/60000 (61.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.1326,                   Accuracy: 39710/60000 (66.18%)
-= Testing Rotation 80 =-
Test set: Average loss: 1.1647,                   Accuracy: 39206/60000 (65.34%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.1164,                   Accuracy: 39967/60000 (66.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.4206,                   Accuracy: 36297/60000 (60.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9144,                   Accuracy: 31881/60000 (53.13%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.8228,                   Accuracy: 24653/60000 (41.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5890,                   Accuracy: 21961/60000 (36.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.1528,                   Accuracy: 21358/60000 (35.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.5285,                   Accuracy: 23105/60000 (38.51%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.6103,                   Accuracy: 26744/60000 (44.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.7812,                   Accuracy: 28017/60000 (46.69%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.6240,                   Accuracy: 29028/60000 (48.38%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.9538,                   Accuracy: 28157/60000 (46.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.8943,                   Accuracy: 26479/60000 (44.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.7445,                   Accuracy: 23728/60000 (39.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.3101,                   Accuracy: 22646/60000 (37.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5529,                   Accuracy: 24424/60000 (40.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5022,                   Accuracy: 29453/60000 (49.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6033,                   Accuracy: 36831/60000 (61.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9423,                   Accuracy: 43541/60000 (72.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5947,                   Accuracy: 48575/60000 (80.96%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6662,                   Accuracy: 47465/60000 (79.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7379,                   Accuracy: 46178/60000 (76.96%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9420,                   Accuracy: 44264/60000 (73.77%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9621,                   Accuracy: 43604/60000 (72.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8290,                   Accuracy: 45611/60000 (76.02%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4830,                   Accuracy: 51215/60000 (85.36%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1893,                   Accuracy: 56526/60000 (94.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0868,                   Accuracy: 58447/60000 (97.41%)
{0: tensor(98.1550), 10: tensor(97.3367), 20: tensor(94.9617), 30: tensor(87.3017), 40: tensor(77.2217), 50: tensor(67.2500), 60: tensor(61.7417), 70: tensor(66.1833), 80: tensor(65.3433), 90: tensor(66.6117), 100: tensor(60.4950), 110: tensor(53.1350), 120: tensor(41.0883), 130: tensor(36.6017), 140: tensor(35.5967), 150: tensor(38.5083), 160: tensor(44.5733), 170: tensor(46.6950), 180: tensor(48.3800), 190: tensor(46.9283), 200: tensor(44.1317), 210: tensor(39.5467), 220: tensor(37.7433), 230: tensor(40.7067), 240: tensor(49.0883), 250: tensor(61.3850), 260: tensor(72.5683), 270: tensor(80.9583), 280: tensor(79.1083), 290: tensor(76.9633), 300: tensor(73.7733), 310: tensor(72.6733), 320: tensor(76.0183), 330: tensor(85.3583), 340: tensor(94.2100), 350: tensor(97.4117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=27, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.3172,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 1.0374,                   Accuracy: 1253/2000.0 (62.65%)



-= Testing valid =-
Test set: Average loss: 0.7390,                   Accuracy: 1512/2000.0 (75.60%)



-= Testing valid =-
Test set: Average loss: 0.3269,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.1593,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1628,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1808,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2864,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.4361,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.1795,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 10 train accuracy: 97.97%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 99.21%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 30 train accuracy: 99.62%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.61%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0533,                   Accuracy: 59107/60000 (98.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0877,                   Accuracy: 58502/60000 (97.50%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2228,                   Accuracy: 56030/60000 (93.38%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5296,                   Accuracy: 50618/60000 (84.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9094,                   Accuracy: 43654/60000 (72.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1261,                   Accuracy: 39924/60000 (66.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9963,                   Accuracy: 42049/60000 (70.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6136,                   Accuracy: 48590/60000 (80.98%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3899,                   Accuracy: 52512/60000 (87.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3617,                   Accuracy: 53257/60000 (88.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5534,                   Accuracy: 50302/60000 (83.84%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1075,                   Accuracy: 42366/60000 (70.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9988,                   Accuracy: 31811/60000 (53.02%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7083,                   Accuracy: 25037/60000 (41.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1407,                   Accuracy: 22441/60000 (37.40%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0933,                   Accuracy: 24029/60000 (40.05%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.7471,                   Accuracy: 28040/60000 (46.73%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.5430,                   Accuracy: 31602/60000 (52.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.3223,                   Accuracy: 33222/60000 (55.37%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.3564,                   Accuracy: 31873/60000 (53.12%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.5017,                   Accuracy: 28894/60000 (48.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.7202,                   Accuracy: 25947/60000 (43.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.8093,                   Accuracy: 23714/60000 (39.52%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6160,                   Accuracy: 24664/60000 (41.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1032,                   Accuracy: 29278/60000 (48.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3866,                   Accuracy: 36307/60000 (60.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9285,                   Accuracy: 42720/60000 (71.20%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5606,                   Accuracy: 48747/60000 (81.25%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5358,                   Accuracy: 48313/60000 (80.52%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7313,                   Accuracy: 44587/60000 (74.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9109,                   Accuracy: 41538/60000 (69.23%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0165,                   Accuracy: 39960/60000 (66.60%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8888,                   Accuracy: 42607/60000 (71.01%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5200,                   Accuracy: 49790/60000 (82.98%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1978,                   Accuracy: 56295/60000 (93.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0763,                   Accuracy: 58642/60000 (97.74%)
{0: tensor(98.5117), 10: tensor(97.5033), 20: tensor(93.3833), 30: tensor(84.3633), 40: tensor(72.7567), 50: tensor(66.5400), 60: tensor(70.0817), 70: tensor(80.9833), 80: tensor(87.5200), 90: tensor(88.7617), 100: tensor(83.8367), 110: tensor(70.6100), 120: tensor(53.0183), 130: tensor(41.7283), 140: tensor(37.4017), 150: tensor(40.0483), 160: tensor(46.7333), 170: tensor(52.6700), 180: tensor(55.3700), 190: tensor(53.1217), 200: tensor(48.1567), 210: tensor(43.2450), 220: tensor(39.5233), 230: tensor(41.1067), 240: tensor(48.7967), 250: tensor(60.5117), 260: tensor(71.2000), 270: tensor(81.2450), 280: tensor(80.5217), 290: tensor(74.3117), 300: tensor(69.2300), 310: tensor(66.6000), 320: tensor(71.0117), 330: tensor(82.9833), 340: tensor(93.8250), 350: tensor(97.7367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=28, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7902,                   Accuracy: 455/2000.0 (22.75%)



-= Testing valid =-
Test set: Average loss: 0.8279,                   Accuracy: 1516/2000.0 (75.80%)



-= Testing valid =-
Test set: Average loss: 0.3527,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1701,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1722,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1542,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 10 train accuracy: 98.19%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 99.14%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.55%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.69%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.75%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0498,                   Accuracy: 59196/60000 (98.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0833,                   Accuracy: 58588/60000 (97.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1761,                   Accuracy: 56954/60000 (94.92%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4057,                   Accuracy: 52966/60000 (88.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6386,                   Accuracy: 48686/60000 (81.14%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8114,                   Accuracy: 45499/60000 (75.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7477,                   Accuracy: 45924/60000 (76.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5600,                   Accuracy: 49268/60000 (82.11%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5369,                   Accuracy: 49426/60000 (82.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6410,                   Accuracy: 47084/60000 (78.47%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0007,                   Accuracy: 42046/60000 (70.08%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6455,                   Accuracy: 34654/60000 (57.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3857,                   Accuracy: 28099/60000 (46.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9116,                   Accuracy: 26598/60000 (44.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2237,                   Accuracy: 26766/60000 (44.61%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2731,                   Accuracy: 28299/60000 (47.17%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1467,                   Accuracy: 31292/60000 (52.15%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0696,                   Accuracy: 31871/60000 (53.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0931,                   Accuracy: 32080/60000 (53.47%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2032,                   Accuracy: 30900/60000 (51.50%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5373,                   Accuracy: 28431/60000 (47.38%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6694,                   Accuracy: 25847/60000 (43.08%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4109,                   Accuracy: 25238/60000 (42.06%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7673,                   Accuracy: 27512/60000 (45.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8948,                   Accuracy: 33492/60000 (55.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0016,                   Accuracy: 42893/60000 (71.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5157,                   Accuracy: 49810/60000 (83.02%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3348,                   Accuracy: 53400/60000 (89.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4464,                   Accuracy: 51333/60000 (85.56%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6668,                   Accuracy: 47331/60000 (78.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9630,                   Accuracy: 42337/60000 (70.56%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0755,                   Accuracy: 41224/60000 (68.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0133,                   Accuracy: 42801/60000 (71.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5969,                   Accuracy: 49316/60000 (82.19%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2176,                   Accuracy: 55986/60000 (93.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0828,                   Accuracy: 58562/60000 (97.60%)
{0: tensor(98.6600), 10: tensor(97.6467), 20: tensor(94.9233), 30: tensor(88.2767), 40: tensor(81.1433), 50: tensor(75.8317), 60: tensor(76.5400), 70: tensor(82.1133), 80: tensor(82.3767), 90: tensor(78.4733), 100: tensor(70.0767), 110: tensor(57.7567), 120: tensor(46.8317), 130: tensor(44.3300), 140: tensor(44.6100), 150: tensor(47.1650), 160: tensor(52.1533), 170: tensor(53.1183), 180: tensor(53.4667), 190: tensor(51.5000), 200: tensor(47.3850), 210: tensor(43.0783), 220: tensor(42.0633), 230: tensor(45.8533), 240: tensor(55.8200), 250: tensor(71.4883), 260: tensor(83.0167), 270: tensor(89.), 280: tensor(85.5550), 290: tensor(78.8850), 300: tensor(70.5617), 310: tensor(68.7067), 320: tensor(71.3350), 330: tensor(82.1933), 340: tensor(93.3100), 350: tensor(97.6033)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=29, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9405,                   Accuracy: 547/2000.0 (27.35%)



-= Testing valid =-
Test set: Average loss: 1.7758,                   Accuracy: 1178/2000.0 (58.90%)



-= Testing valid =-
Test set: Average loss: 1.1605,                   Accuracy: 1506/2000.0 (75.30%)



-= Testing valid =-
Test set: Average loss: 0.7782,                   Accuracy: 1497/2000.0 (74.85%)



-= Testing valid =-
Test set: Average loss: 0.1367,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.8569,                   Accuracy: 1467/2000.0 (73.35%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.5346,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.2857,                   Accuracy: 1833/2000.0 (91.65%)



Epoch 10 train accuracy: 98.04%, valid accuracy 91.65%
-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.21%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.38%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.46%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0538,                   Accuracy: 59083/60000 (98.47%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0984,                   Accuracy: 58353/60000 (97.25%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2351,                   Accuracy: 56285/60000 (93.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5852,                   Accuracy: 50946/60000 (84.91%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0707,                   Accuracy: 43290/60000 (72.15%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2755,                   Accuracy: 39382/60000 (65.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0674,                   Accuracy: 41074/60000 (68.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7669,                   Accuracy: 44939/60000 (74.90%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6442,                   Accuracy: 46185/60000 (76.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5028,                   Accuracy: 49076/60000 (81.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8015,                   Accuracy: 43938/60000 (73.23%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4159,                   Accuracy: 35212/60000 (58.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2338,                   Accuracy: 27867/60000 (46.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0295,                   Accuracy: 22935/60000 (38.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4621,                   Accuracy: 21873/60000 (36.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4926,                   Accuracy: 23509/60000 (39.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2726,                   Accuracy: 26164/60000 (43.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2245,                   Accuracy: 28391/60000 (47.32%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1887,                   Accuracy: 30079/60000 (50.13%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4867,                   Accuracy: 28729/60000 (47.88%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6353,                   Accuracy: 26752/60000 (44.59%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7427,                   Accuracy: 24597/60000 (40.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5219,                   Accuracy: 24040/60000 (40.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9582,                   Accuracy: 26614/60000 (44.36%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0268,                   Accuracy: 33405/60000 (55.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1573,                   Accuracy: 42618/60000 (71.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6370,                   Accuracy: 49028/60000 (81.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3558,                   Accuracy: 53614/60000 (89.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5620,                   Accuracy: 49576/60000 (82.63%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8042,                   Accuracy: 44984/60000 (74.97%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2352,                   Accuracy: 39957/60000 (66.60%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4724,                   Accuracy: 36481/60000 (60.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3683,                   Accuracy: 39360/60000 (65.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7696,                   Accuracy: 47960/60000 (79.93%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2681,                   Accuracy: 55433/60000 (92.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1063,                   Accuracy: 58105/60000 (96.84%)
{0: tensor(98.4717), 10: tensor(97.2550), 20: tensor(93.8083), 30: tensor(84.9100), 40: tensor(72.1500), 50: tensor(65.6367), 60: tensor(68.4567), 70: tensor(74.8983), 80: tensor(76.9750), 90: tensor(81.7933), 100: tensor(73.2300), 110: tensor(58.6867), 120: tensor(46.4450), 130: tensor(38.2250), 140: tensor(36.4550), 150: tensor(39.1817), 160: tensor(43.6067), 170: tensor(47.3183), 180: tensor(50.1317), 190: tensor(47.8817), 200: tensor(44.5867), 210: tensor(40.9950), 220: tensor(40.0667), 230: tensor(44.3567), 240: tensor(55.6750), 250: tensor(71.0300), 260: tensor(81.7133), 270: tensor(89.3567), 280: tensor(82.6267), 290: tensor(74.9733), 300: tensor(66.5950), 310: tensor(60.8017), 320: tensor(65.6000), 330: tensor(79.9333), 340: tensor(92.3883), 350: tensor(96.8417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=30, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.1283,                   Accuracy: 235/2000.0 (11.75%)



-= Testing valid =-
Test set: Average loss: 1.6470,                   Accuracy: 793/2000.0 (39.65%)



-= Testing valid =-
Test set: Average loss: 0.7486,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.3253,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3577,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.6164,                   Accuracy: 1628/2000.0 (81.40%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 10 train accuracy: 97.80%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 98.93%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.39%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.65%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.64%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0471,                   Accuracy: 59161/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0795,                   Accuracy: 58617/60000 (97.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1654,                   Accuracy: 57221/60000 (95.37%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3263,                   Accuracy: 54328/60000 (90.55%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6213,                   Accuracy: 49176/60000 (81.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8246,                   Accuracy: 44964/60000 (74.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8283,                   Accuracy: 44183/60000 (73.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7939,                   Accuracy: 44636/60000 (74.39%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6697,                   Accuracy: 46093/60000 (76.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6578,                   Accuracy: 46862/60000 (78.10%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9156,                   Accuracy: 42956/60000 (71.59%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3110,                   Accuracy: 38774/60000 (64.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0696,                   Accuracy: 31262/60000 (52.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7560,                   Accuracy: 26888/60000 (44.81%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2884,                   Accuracy: 25249/60000 (42.08%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5536,                   Accuracy: 26763/60000 (44.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4838,                   Accuracy: 29858/60000 (49.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5776,                   Accuracy: 32069/60000 (53.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7801,                   Accuracy: 32549/60000 (54.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4721,                   Accuracy: 32261/60000 (53.77%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4205,                   Accuracy: 30702/60000 (51.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4737,                   Accuracy: 27935/60000 (46.56%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.0826,                   Accuracy: 26552/60000 (44.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5842,                   Accuracy: 27652/60000 (46.09%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9288,                   Accuracy: 31677/60000 (52.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4177,                   Accuracy: 36493/60000 (60.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9716,                   Accuracy: 41541/60000 (69.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7349,                   Accuracy: 44848/60000 (74.75%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7497,                   Accuracy: 44498/60000 (74.16%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8646,                   Accuracy: 42775/60000 (71.29%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0030,                   Accuracy: 40046/60000 (66.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0118,                   Accuracy: 40198/60000 (67.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8946,                   Accuracy: 42464/60000 (70.77%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4980,                   Accuracy: 49995/60000 (83.32%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2210,                   Accuracy: 55814/60000 (93.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0827,                   Accuracy: 58436/60000 (97.39%)
{0: tensor(98.6017), 10: tensor(97.6950), 20: tensor(95.3683), 30: tensor(90.5467), 40: tensor(81.9600), 50: tensor(74.9400), 60: tensor(73.6383), 70: tensor(74.3933), 80: tensor(76.8217), 90: tensor(78.1033), 100: tensor(71.5933), 110: tensor(64.6233), 120: tensor(52.1033), 130: tensor(44.8133), 140: tensor(42.0817), 150: tensor(44.6050), 160: tensor(49.7633), 170: tensor(53.4483), 180: tensor(54.2483), 190: tensor(53.7683), 200: tensor(51.1700), 210: tensor(46.5583), 220: tensor(44.2533), 230: tensor(46.0867), 240: tensor(52.7950), 250: tensor(60.8217), 260: tensor(69.2350), 270: tensor(74.7467), 280: tensor(74.1633), 290: tensor(71.2917), 300: tensor(66.7433), 310: tensor(66.9967), 320: tensor(70.7733), 330: tensor(83.3250), 340: tensor(93.0233), 350: tensor(97.3933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=31, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0308,                   Accuracy: 547/2000.0 (27.35%)



-= Testing valid =-
Test set: Average loss: 1.1531,                   Accuracy: 1161/2000.0 (58.05%)



-= Testing valid =-
Test set: Average loss: 1.2909,                   Accuracy: 1222/2000.0 (61.10%)



-= Testing valid =-
Test set: Average loss: 0.1670,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1484,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1700,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1746,                   Accuracy: 1898/2000.0 (94.90%)



Epoch 10 train accuracy: 98.29%, valid accuracy 94.90%
-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.09%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.49%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.71%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0494,                   Accuracy: 59166/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0746,                   Accuracy: 58729/60000 (97.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1739,                   Accuracy: 56961/60000 (94.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4619,                   Accuracy: 51961/60000 (86.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8955,                   Accuracy: 44201/60000 (73.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1987,                   Accuracy: 38265/60000 (63.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1853,                   Accuracy: 37667/60000 (62.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9787,                   Accuracy: 40195/60000 (66.99%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8502,                   Accuracy: 42785/60000 (71.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7739,                   Accuracy: 44555/60000 (74.26%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1844,                   Accuracy: 39411/60000 (65.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8001,                   Accuracy: 32478/60000 (54.13%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.9614,                   Accuracy: 25407/60000 (42.35%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.9628,                   Accuracy: 21287/60000 (35.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.4821,                   Accuracy: 21138/60000 (35.23%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.5198,                   Accuracy: 23224/60000 (38.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0812,                   Accuracy: 26473/60000 (44.12%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1198,                   Accuracy: 27356/60000 (45.59%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.2711,                   Accuracy: 27339/60000 (45.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7967,                   Accuracy: 28013/60000 (46.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9434,                   Accuracy: 26197/60000 (43.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3128,                   Accuracy: 23474/60000 (39.12%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.2176,                   Accuracy: 21375/60000 (35.62%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.6493,                   Accuracy: 22728/60000 (37.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6960,                   Accuracy: 27623/60000 (46.04%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7377,                   Accuracy: 34794/60000 (57.99%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0735,                   Accuracy: 42287/60000 (70.48%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7129,                   Accuracy: 46700/60000 (77.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7965,                   Accuracy: 45238/60000 (75.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9742,                   Accuracy: 41792/60000 (69.65%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3020,                   Accuracy: 38199/60000 (63.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5138,                   Accuracy: 35707/60000 (59.51%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3549,                   Accuracy: 38667/60000 (64.44%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7702,                   Accuracy: 46912/60000 (78.19%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2765,                   Accuracy: 55088/60000 (91.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0880,                   Accuracy: 58464/60000 (97.44%)
{0: tensor(98.6100), 10: tensor(97.8817), 20: tensor(94.9350), 30: tensor(86.6017), 40: tensor(73.6683), 50: tensor(63.7750), 60: tensor(62.7783), 70: tensor(66.9917), 80: tensor(71.3083), 90: tensor(74.2583), 100: tensor(65.6850), 110: tensor(54.1300), 120: tensor(42.3450), 130: tensor(35.4783), 140: tensor(35.2300), 150: tensor(38.7067), 160: tensor(44.1217), 170: tensor(45.5933), 180: tensor(45.5650), 190: tensor(46.6883), 200: tensor(43.6617), 210: tensor(39.1233), 220: tensor(35.6250), 230: tensor(37.8800), 240: tensor(46.0383), 250: tensor(57.9900), 260: tensor(70.4783), 270: tensor(77.8333), 280: tensor(75.3967), 290: tensor(69.6533), 300: tensor(63.6650), 310: tensor(59.5117), 320: tensor(64.4450), 330: tensor(78.1867), 340: tensor(91.8133), 350: tensor(97.4400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=32, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3351,                   Accuracy: 255/2000.0 (12.75%)



-= Testing valid =-
Test set: Average loss: 1.0245,                   Accuracy: 1361/2000.0 (68.05%)



-= Testing valid =-
Test set: Average loss: 0.3029,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1861,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 98.18%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 20 train accuracy: 98.95%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.51%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.68%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0565,                   Accuracy: 59040/60000 (98.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1130,                   Accuracy: 58082/60000 (96.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2731,                   Accuracy: 55376/60000 (92.29%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7057,                   Accuracy: 48382/60000 (80.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1764,                   Accuracy: 40674/60000 (67.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2974,                   Accuracy: 38159/60000 (63.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1083,                   Accuracy: 39871/60000 (66.45%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8290,                   Accuracy: 43247/60000 (72.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7428,                   Accuracy: 44457/60000 (74.10%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6842,                   Accuracy: 46443/60000 (77.40%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1878,                   Accuracy: 39156/60000 (65.26%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.1220,                   Accuracy: 30779/60000 (51.30%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.2221,                   Accuracy: 24556/60000 (40.93%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.7964,                   Accuracy: 22072/60000 (36.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8713,                   Accuracy: 22602/60000 (37.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6961,                   Accuracy: 24365/60000 (40.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4534,                   Accuracy: 26700/60000 (44.50%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3990,                   Accuracy: 28455/60000 (47.42%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2137,                   Accuracy: 30248/60000 (50.41%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3437,                   Accuracy: 29708/60000 (49.51%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4514,                   Accuracy: 27133/60000 (45.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6440,                   Accuracy: 23291/60000 (38.82%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5367,                   Accuracy: 22037/60000 (36.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9655,                   Accuracy: 25186/60000 (41.98%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0291,                   Accuracy: 32544/60000 (54.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1091,                   Accuracy: 42321/60000 (70.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5946,                   Accuracy: 49131/60000 (81.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3643,                   Accuracy: 53410/60000 (89.02%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6071,                   Accuracy: 49538/60000 (82.56%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9597,                   Accuracy: 44646/60000 (74.41%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4497,                   Accuracy: 38989/60000 (64.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6489,                   Accuracy: 36064/60000 (60.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4134,                   Accuracy: 40056/60000 (66.76%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8281,                   Accuracy: 47542/60000 (79.24%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2799,                   Accuracy: 55192/60000 (91.99%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1077,                   Accuracy: 58093/60000 (96.82%)
{0: tensor(98.4000), 10: tensor(96.8033), 20: tensor(92.2933), 30: tensor(80.6367), 40: tensor(67.7900), 50: tensor(63.5983), 60: tensor(66.4517), 70: tensor(72.0783), 80: tensor(74.0950), 90: tensor(77.4050), 100: tensor(65.2600), 110: tensor(51.2983), 120: tensor(40.9267), 130: tensor(36.7867), 140: tensor(37.6700), 150: tensor(40.6083), 160: tensor(44.5000), 170: tensor(47.4250), 180: tensor(50.4133), 190: tensor(49.5133), 200: tensor(45.2217), 210: tensor(38.8183), 220: tensor(36.7283), 230: tensor(41.9767), 240: tensor(54.2400), 250: tensor(70.5350), 260: tensor(81.8850), 270: tensor(89.0167), 280: tensor(82.5633), 290: tensor(74.4100), 300: tensor(64.9817), 310: tensor(60.1067), 320: tensor(66.7600), 330: tensor(79.2367), 340: tensor(91.9867), 350: tensor(96.8217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=33, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3198,                   Accuracy: 470/2000.0 (23.50%)



-= Testing valid =-
Test set: Average loss: 1.6859,                   Accuracy: 836/2000.0 (41.80%)



-= Testing valid =-
Test set: Average loss: 1.1702,                   Accuracy: 1298/2000.0 (64.90%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.3133,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2106,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.2227,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1247,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 10 train accuracy: 98.04%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 20 train accuracy: 99.01%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 30 train accuracy: 99.35%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0181,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.64%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0192,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0473,                   Accuracy: 59180/60000 (98.63%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0795,                   Accuracy: 58616/60000 (97.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1737,                   Accuracy: 56977/60000 (94.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4666,                   Accuracy: 51924/60000 (86.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8588,                   Accuracy: 45171/60000 (75.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1770,                   Accuracy: 39292/60000 (65.49%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0796,                   Accuracy: 39898/60000 (66.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8780,                   Accuracy: 42484/60000 (70.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8038,                   Accuracy: 44206/60000 (73.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8873,                   Accuracy: 43457/60000 (72.43%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2529,                   Accuracy: 36584/60000 (60.97%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7972,                   Accuracy: 31094/60000 (51.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6421,                   Accuracy: 24166/60000 (40.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3487,                   Accuracy: 22037/60000 (36.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8504,                   Accuracy: 22300/60000 (37.17%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9700,                   Accuracy: 24502/60000 (40.84%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7520,                   Accuracy: 26648/60000 (44.41%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7446,                   Accuracy: 27751/60000 (46.25%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5970,                   Accuracy: 27926/60000 (46.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6858,                   Accuracy: 26379/60000 (43.97%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7139,                   Accuracy: 24865/60000 (41.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7939,                   Accuracy: 23641/60000 (39.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5110,                   Accuracy: 24135/60000 (40.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7774,                   Accuracy: 27308/60000 (45.51%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8290,                   Accuracy: 33787/60000 (56.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0792,                   Accuracy: 41440/60000 (69.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6926,                   Accuracy: 46857/60000 (78.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4987,                   Accuracy: 50410/60000 (84.02%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5962,                   Accuracy: 48780/60000 (81.30%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7491,                   Accuracy: 45924/60000 (76.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0659,                   Accuracy: 41265/60000 (68.78%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1152,                   Accuracy: 40797/60000 (68.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0339,                   Accuracy: 42738/60000 (71.23%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5597,                   Accuracy: 50035/60000 (83.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1829,                   Accuracy: 56504/60000 (94.17%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0769,                   Accuracy: 58573/60000 (97.62%)
{0: tensor(98.6333), 10: tensor(97.6933), 20: tensor(94.9617), 30: tensor(86.5400), 40: tensor(75.2850), 50: tensor(65.4867), 60: tensor(66.4967), 70: tensor(70.8067), 80: tensor(73.6767), 90: tensor(72.4283), 100: tensor(60.9733), 110: tensor(51.8233), 120: tensor(40.2767), 130: tensor(36.7283), 140: tensor(37.1667), 150: tensor(40.8367), 160: tensor(44.4133), 170: tensor(46.2517), 180: tensor(46.5433), 190: tensor(43.9650), 200: tensor(41.4417), 210: tensor(39.4017), 220: tensor(40.2250), 230: tensor(45.5133), 240: tensor(56.3117), 250: tensor(69.0667), 260: tensor(78.0950), 270: tensor(84.0167), 280: tensor(81.3000), 290: tensor(76.5400), 300: tensor(68.7750), 310: tensor(67.9950), 320: tensor(71.2300), 330: tensor(83.3917), 340: tensor(94.1733), 350: tensor(97.6217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=34, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3014,                   Accuracy: 512/2000.0 (25.60%)



-= Testing valid =-
Test set: Average loss: 1.1756,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 1.6807,                   Accuracy: 864/2000.0 (43.20%)



-= Testing valid =-
Test set: Average loss: 0.3182,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.3790,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 10 train accuracy: 98.12%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 99.26%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.60%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.65%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.78%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0444,                   Accuracy: 59209/60000 (98.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0740,                   Accuracy: 58705/60000 (97.84%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1623,                   Accuracy: 57170/60000 (95.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3968,                   Accuracy: 53003/60000 (88.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8368,                   Accuracy: 45265/60000 (75.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1950,                   Accuracy: 38910/60000 (64.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2565,                   Accuracy: 37210/60000 (62.02%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0218,                   Accuracy: 40594/60000 (67.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7761,                   Accuracy: 44669/60000 (74.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6694,                   Accuracy: 47115/60000 (78.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0329,                   Accuracy: 42602/60000 (71.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6847,                   Accuracy: 35863/60000 (59.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7544,                   Accuracy: 28599/60000 (47.67%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.7491,                   Accuracy: 24589/60000 (40.98%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.3134,                   Accuracy: 23641/60000 (39.40%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.4751,                   Accuracy: 24321/60000 (40.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.4202,                   Accuracy: 26625/60000 (44.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.2775,                   Accuracy: 28126/60000 (46.88%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.9325,                   Accuracy: 29496/60000 (49.16%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8693,                   Accuracy: 29664/60000 (49.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8893,                   Accuracy: 28288/60000 (47.15%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9855,                   Accuracy: 25417/60000 (42.36%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8938,                   Accuracy: 23367/60000 (38.94%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.3088,                   Accuracy: 24630/60000 (41.05%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3563,                   Accuracy: 29817/60000 (49.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3704,                   Accuracy: 38983/60000 (64.97%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7039,                   Accuracy: 47076/60000 (78.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3687,                   Accuracy: 52978/60000 (88.30%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5318,                   Accuracy: 50045/60000 (83.41%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7913,                   Accuracy: 45905/60000 (76.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1191,                   Accuracy: 41556/60000 (69.26%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3456,                   Accuracy: 38557/60000 (64.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1728,                   Accuracy: 40919/60000 (68.20%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6227,                   Accuracy: 48865/60000 (81.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2162,                   Accuracy: 55929/60000 (93.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0755,                   Accuracy: 58600/60000 (97.67%)
{0: tensor(98.6817), 10: tensor(97.8417), 20: tensor(95.2833), 30: tensor(88.3383), 40: tensor(75.4417), 50: tensor(64.8500), 60: tensor(62.0167), 70: tensor(67.6567), 80: tensor(74.4483), 90: tensor(78.5250), 100: tensor(71.0033), 110: tensor(59.7717), 120: tensor(47.6650), 130: tensor(40.9817), 140: tensor(39.4017), 150: tensor(40.5350), 160: tensor(44.3750), 170: tensor(46.8767), 180: tensor(49.1600), 190: tensor(49.4400), 200: tensor(47.1467), 210: tensor(42.3617), 220: tensor(38.9450), 230: tensor(41.0500), 240: tensor(49.6950), 250: tensor(64.9717), 260: tensor(78.4600), 270: tensor(88.2967), 280: tensor(83.4083), 290: tensor(76.5083), 300: tensor(69.2600), 310: tensor(64.2617), 320: tensor(68.1983), 330: tensor(81.4417), 340: tensor(93.2150), 350: tensor(97.6667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=35, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9656,                   Accuracy: 600/2000.0 (30.00%)



-= Testing valid =-
Test set: Average loss: 1.2390,                   Accuracy: 1255/2000.0 (62.75%)



-= Testing valid =-
Test set: Average loss: 0.5487,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.2859,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.9620,                   Accuracy: 1385/2000.0 (69.25%)



-= Testing valid =-
Test set: Average loss: 0.1770,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.3994,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.2925,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 10 train accuracy: 98.18%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1548,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 20 train accuracy: 98.86%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 30 train accuracy: 99.55%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 50 train accuracy: 99.62%, valid accuracy 98.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0695,                   Accuracy: 58806/60000 (98.01%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1221,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2801,                   Accuracy: 55066/60000 (91.78%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6091,                   Accuracy: 49152/60000 (81.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0447,                   Accuracy: 41421/60000 (69.04%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2055,                   Accuracy: 38013/60000 (63.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0464,                   Accuracy: 39914/60000 (66.52%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7713,                   Accuracy: 44871/60000 (74.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6985,                   Accuracy: 45540/60000 (75.90%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7179,                   Accuracy: 45297/60000 (75.50%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1284,                   Accuracy: 38548/60000 (64.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8047,                   Accuracy: 30094/60000 (50.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7001,                   Accuracy: 23073/60000 (38.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3015,                   Accuracy: 20851/60000 (34.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5919,                   Accuracy: 21467/60000 (35.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7052,                   Accuracy: 23266/60000 (38.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5242,                   Accuracy: 26066/60000 (43.44%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5637,                   Accuracy: 27520/60000 (45.87%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6878,                   Accuracy: 27513/60000 (45.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6256,                   Accuracy: 26928/60000 (44.88%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8711,                   Accuracy: 24996/60000 (41.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.1736,                   Accuracy: 22594/60000 (37.66%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9839,                   Accuracy: 22142/60000 (36.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4934,                   Accuracy: 23974/60000 (39.96%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7503,                   Accuracy: 27572/60000 (45.95%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.0113,                   Accuracy: 32647/60000 (54.41%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.4176,                   Accuracy: 37248/60000 (62.08%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.0132,                   Accuracy: 41425/60000 (69.04%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.1898,                   Accuracy: 39486/60000 (65.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.3979,                   Accuracy: 36123/60000 (60.21%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5216,                   Accuracy: 34210/60000 (57.02%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3890,                   Accuracy: 35618/60000 (59.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0200,                   Accuracy: 41801/60000 (69.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5045,                   Accuracy: 50764/60000 (84.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1880,                   Accuracy: 56573/60000 (94.29%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0902,                   Accuracy: 58390/60000 (97.32%)
{0: tensor(98.0100), 10: tensor(96.5150), 20: tensor(91.7767), 30: tensor(81.9200), 40: tensor(69.0350), 50: tensor(63.3550), 60: tensor(66.5233), 70: tensor(74.7850), 80: tensor(75.9000), 90: tensor(75.4950), 100: tensor(64.2467), 110: tensor(50.1567), 120: tensor(38.4550), 130: tensor(34.7517), 140: tensor(35.7783), 150: tensor(38.7767), 160: tensor(43.4433), 170: tensor(45.8667), 180: tensor(45.8550), 190: tensor(44.8800), 200: tensor(41.6600), 210: tensor(37.6567), 220: tensor(36.9033), 230: tensor(39.9567), 240: tensor(45.9533), 250: tensor(54.4117), 260: tensor(62.0800), 270: tensor(69.0417), 280: tensor(65.8100), 290: tensor(60.2050), 300: tensor(57.0167), 310: tensor(59.3633), 320: tensor(69.6683), 330: tensor(84.6067), 340: tensor(94.2883), 350: tensor(97.3167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=36, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8154,                   Accuracy: 645/2000.0 (32.25%)



-= Testing valid =-
Test set: Average loss: 1.5565,                   Accuracy: 928/2000.0 (46.40%)



-= Testing valid =-
Test set: Average loss: 1.4631,                   Accuracy: 1065/2000.0 (53.25%)



-= Testing valid =-
Test set: Average loss: 0.9999,                   Accuracy: 1302/2000.0 (65.10%)



-= Testing valid =-
Test set: Average loss: 0.3095,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.4166,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.1698,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1749,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.2187,                   Accuracy: 1850/2000.0 (92.50%)



Epoch 10 train accuracy: 98.14%, valid accuracy 92.50%
-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.1539,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 98.96%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.47%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.68%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.64%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0599,                   Accuracy: 58957/60000 (98.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0946,                   Accuracy: 58341/60000 (97.24%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2441,                   Accuracy: 55705/60000 (92.84%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7315,                   Accuracy: 47839/60000 (79.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3426,                   Accuracy: 38284/60000 (63.81%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.6957,                   Accuracy: 32370/60000 (53.95%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.7103,                   Accuracy: 30821/60000 (51.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.3448,                   Accuracy: 35121/60000 (58.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 1.1787,                   Accuracy: 36899/60000 (61.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.2902,                   Accuracy: 35571/60000 (59.28%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.6664,                   Accuracy: 31336/60000 (52.23%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.5715,                   Accuracy: 25368/60000 (42.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.9894,                   Accuracy: 20144/60000 (33.57%)
-= Testing Rotation 130 =-
Test set: Average loss: 4.6993,                   Accuracy: 19109/60000 (31.85%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.9381,                   Accuracy: 20063/60000 (33.44%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.8801,                   Accuracy: 22071/60000 (36.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.5571,                   Accuracy: 25072/60000 (41.79%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.5159,                   Accuracy: 26600/60000 (44.33%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.4986,                   Accuracy: 27059/60000 (45.10%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.6014,                   Accuracy: 26868/60000 (44.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.8903,                   Accuracy: 23934/60000 (39.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.9373,                   Accuracy: 21087/60000 (35.15%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.6787,                   Accuracy: 19619/60000 (32.70%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.9644,                   Accuracy: 21408/60000 (35.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8791,                   Accuracy: 25920/60000 (43.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.9019,                   Accuracy: 32281/60000 (53.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2069,                   Accuracy: 39402/60000 (65.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.9807,                   Accuracy: 42825/60000 (71.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.2446,                   Accuracy: 40125/60000 (66.88%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.5886,                   Accuracy: 36657/60000 (61.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 2.1496,                   Accuracy: 32573/60000 (54.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 2.2328,                   Accuracy: 32308/60000 (53.85%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9056,                   Accuracy: 36287/60000 (60.48%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.1426,                   Accuracy: 44830/60000 (74.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3986,                   Accuracy: 53778/60000 (89.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1115,                   Accuracy: 58057/60000 (96.76%)
{0: tensor(98.2617), 10: tensor(97.2350), 20: tensor(92.8417), 30: tensor(79.7317), 40: tensor(63.8067), 50: tensor(53.9500), 60: tensor(51.3683), 70: tensor(58.5350), 80: tensor(61.4983), 90: tensor(59.2850), 100: tensor(52.2267), 110: tensor(42.2800), 120: tensor(33.5733), 130: tensor(31.8483), 140: tensor(33.4383), 150: tensor(36.7850), 160: tensor(41.7867), 170: tensor(44.3333), 180: tensor(45.0983), 190: tensor(44.7800), 200: tensor(39.8900), 210: tensor(35.1450), 220: tensor(32.6983), 230: tensor(35.6800), 240: tensor(43.2000), 250: tensor(53.8017), 260: tensor(65.6700), 270: tensor(71.3750), 280: tensor(66.8750), 290: tensor(61.0950), 300: tensor(54.2883), 310: tensor(53.8467), 320: tensor(60.4783), 330: tensor(74.7167), 340: tensor(89.6300), 350: tensor(96.7617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=37, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6108,                   Accuracy: 1010/2000.0 (50.50%)



-= Testing valid =-
Test set: Average loss: 1.5777,                   Accuracy: 883/2000.0 (44.15%)



-= Testing valid =-
Test set: Average loss: 0.3892,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.3753,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.1639,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.3886,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 98.10%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.91%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.46%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.68%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0494,                   Accuracy: 59149/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0748,                   Accuracy: 58686/60000 (97.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1439,                   Accuracy: 57545/60000 (95.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3150,                   Accuracy: 54280/60000 (90.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.5883,                   Accuracy: 48972/60000 (81.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7828,                   Accuracy: 45015/60000 (75.03%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7987,                   Accuracy: 44389/60000 (73.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7514,                   Accuracy: 45295/60000 (75.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6785,                   Accuracy: 46958/60000 (78.26%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6916,                   Accuracy: 47545/60000 (79.24%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9936,                   Accuracy: 43587/60000 (72.64%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5252,                   Accuracy: 38078/60000 (63.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3995,                   Accuracy: 31305/60000 (52.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1387,                   Accuracy: 26759/60000 (44.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7274,                   Accuracy: 25175/60000 (41.96%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.0387,                   Accuracy: 25629/60000 (42.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.2783,                   Accuracy: 27936/60000 (46.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.5089,                   Accuracy: 29567/60000 (49.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.5429,                   Accuracy: 29640/60000 (49.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.5597,                   Accuracy: 30009/60000 (50.01%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.5208,                   Accuracy: 27955/60000 (46.59%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.4445,                   Accuracy: 25360/60000 (42.27%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.2101,                   Accuracy: 24276/60000 (40.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.7117,                   Accuracy: 24892/60000 (41.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8286,                   Accuracy: 28424/60000 (47.37%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.0052,                   Accuracy: 32937/60000 (54.90%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.3438,                   Accuracy: 38431/60000 (64.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.8997,                   Accuracy: 44452/60000 (74.09%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9804,                   Accuracy: 42481/60000 (70.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1068,                   Accuracy: 40388/60000 (67.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3188,                   Accuracy: 37560/60000 (62.60%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3848,                   Accuracy: 36467/60000 (60.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1710,                   Accuracy: 40094/60000 (66.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6644,                   Accuracy: 48257/60000 (80.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2367,                   Accuracy: 55526/60000 (92.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0860,                   Accuracy: 58440/60000 (97.40%)
{0: tensor(98.5817), 10: tensor(97.8100), 20: tensor(95.9083), 30: tensor(90.4667), 40: tensor(81.6200), 50: tensor(75.0250), 60: tensor(73.9817), 70: tensor(75.4917), 80: tensor(78.2633), 90: tensor(79.2417), 100: tensor(72.6450), 110: tensor(63.4633), 120: tensor(52.1750), 130: tensor(44.5983), 140: tensor(41.9583), 150: tensor(42.7150), 160: tensor(46.5600), 170: tensor(49.2783), 180: tensor(49.4000), 190: tensor(50.0150), 200: tensor(46.5917), 210: tensor(42.2667), 220: tensor(40.4600), 230: tensor(41.4867), 240: tensor(47.3733), 250: tensor(54.8950), 260: tensor(64.0517), 270: tensor(74.0867), 280: tensor(70.8017), 290: tensor(67.3133), 300: tensor(62.6000), 310: tensor(60.7783), 320: tensor(66.8233), 330: tensor(80.4283), 340: tensor(92.5433), 350: tensor(97.4000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=38, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8841,                   Accuracy: 603/2000.0 (30.15%)



-= Testing valid =-
Test set: Average loss: 0.9796,                   Accuracy: 1283/2000.0 (64.15%)



-= Testing valid =-
Test set: Average loss: 0.3160,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2186,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2298,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.4106,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.2491,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.2067,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.3599,                   Accuracy: 1773/2000.0 (88.65%)



Epoch 10 train accuracy: 98.05%, valid accuracy 88.65%
-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 20 train accuracy: 99.09%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 30 train accuracy: 99.41%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0641,                   Accuracy: 58888/60000 (98.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0921,                   Accuracy: 58421/60000 (97.37%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2050,                   Accuracy: 56693/60000 (94.49%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5869,                   Accuracy: 51403/60000 (85.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1448,                   Accuracy: 44205/60000 (73.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.5749,                   Accuracy: 38723/60000 (64.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.4526,                   Accuracy: 39139/60000 (65.23%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9965,                   Accuracy: 43968/60000 (73.28%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7101,                   Accuracy: 47203/60000 (78.67%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5259,                   Accuracy: 49534/60000 (82.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6748,                   Accuracy: 46818/60000 (78.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1824,                   Accuracy: 39616/60000 (66.03%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0144,                   Accuracy: 30653/60000 (51.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7751,                   Accuracy: 24824/60000 (41.37%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2476,                   Accuracy: 22660/60000 (37.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3492,                   Accuracy: 23824/60000 (39.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2693,                   Accuracy: 26575/60000 (44.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2681,                   Accuracy: 28175/60000 (46.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1150,                   Accuracy: 29439/60000 (49.06%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3790,                   Accuracy: 29089/60000 (48.48%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6831,                   Accuracy: 27451/60000 (45.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9968,                   Accuracy: 24777/60000 (41.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9951,                   Accuracy: 23444/60000 (39.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5639,                   Accuracy: 25097/60000 (41.83%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5544,                   Accuracy: 30540/60000 (50.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5003,                   Accuracy: 38755/60000 (64.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8537,                   Accuracy: 45049/60000 (75.08%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5231,                   Accuracy: 50037/60000 (83.39%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6058,                   Accuracy: 48056/60000 (80.09%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8283,                   Accuracy: 44580/60000 (74.30%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2213,                   Accuracy: 39170/60000 (65.28%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4744,                   Accuracy: 36043/60000 (60.07%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3575,                   Accuracy: 39003/60000 (65.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8183,                   Accuracy: 46894/60000 (78.16%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3072,                   Accuracy: 54570/60000 (90.95%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1282,                   Accuracy: 57655/60000 (96.09%)
{0: tensor(98.1467), 10: tensor(97.3683), 20: tensor(94.4883), 30: tensor(85.6717), 40: tensor(73.6750), 50: tensor(64.5383), 60: tensor(65.2317), 70: tensor(73.2800), 80: tensor(78.6717), 90: tensor(82.5567), 100: tensor(78.0300), 110: tensor(66.0267), 120: tensor(51.0883), 130: tensor(41.3733), 140: tensor(37.7667), 150: tensor(39.7067), 160: tensor(44.2917), 170: tensor(46.9583), 180: tensor(49.0650), 190: tensor(48.4817), 200: tensor(45.7517), 210: tensor(41.2950), 220: tensor(39.0733), 230: tensor(41.8283), 240: tensor(50.9000), 250: tensor(64.5917), 260: tensor(75.0817), 270: tensor(83.3950), 280: tensor(80.0933), 290: tensor(74.3000), 300: tensor(65.2833), 310: tensor(60.0717), 320: tensor(65.0050), 330: tensor(78.1567), 340: tensor(90.9500), 350: tensor(96.0917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=39, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3397,                   Accuracy: 253/2000.0 (12.65%)



-= Testing valid =-
Test set: Average loss: 0.8913,                   Accuracy: 1445/2000.0 (72.25%)



-= Testing valid =-
Test set: Average loss: 0.3062,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2509,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2571,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.1860,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 10 train accuracy: 98.29%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.21%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.57%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.76%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0592,                   Accuracy: 58979/60000 (98.30%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1050,                   Accuracy: 58241/60000 (97.07%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2150,                   Accuracy: 56569/60000 (94.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4912,                   Accuracy: 52113/60000 (86.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9085,                   Accuracy: 45369/60000 (75.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2258,                   Accuracy: 39422/60000 (65.70%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2442,                   Accuracy: 37957/60000 (63.26%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0101,                   Accuracy: 41229/60000 (68.71%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8457,                   Accuracy: 43678/60000 (72.80%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7459,                   Accuracy: 45488/60000 (75.81%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9151,                   Accuracy: 43445/60000 (72.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3545,                   Accuracy: 38297/60000 (63.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1965,                   Accuracy: 29547/60000 (49.24%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0106,                   Accuracy: 24604/60000 (41.01%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8280,                   Accuracy: 21952/60000 (36.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.3857,                   Accuracy: 22310/60000 (37.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.5801,                   Accuracy: 24441/60000 (40.74%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.6592,                   Accuracy: 25676/60000 (42.79%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.8445,                   Accuracy: 26210/60000 (43.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.8157,                   Accuracy: 25670/60000 (42.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.9577,                   Accuracy: 24043/60000 (40.07%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.1454,                   Accuracy: 21944/60000 (36.57%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.7935,                   Accuracy: 21719/60000 (36.20%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.9426,                   Accuracy: 23222/60000 (38.70%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8369,                   Accuracy: 27336/60000 (45.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.8565,                   Accuracy: 33733/60000 (56.22%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2580,                   Accuracy: 39279/60000 (65.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.8215,                   Accuracy: 45174/60000 (75.29%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9916,                   Accuracy: 40877/60000 (68.13%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0579,                   Accuracy: 39991/60000 (66.65%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3068,                   Accuracy: 37188/60000 (61.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3765,                   Accuracy: 37725/60000 (62.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1960,                   Accuracy: 41850/60000 (69.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7178,                   Accuracy: 48991/60000 (81.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2572,                   Accuracy: 55601/60000 (92.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0998,                   Accuracy: 58201/60000 (97.00%)
{0: tensor(98.2983), 10: tensor(97.0683), 20: tensor(94.2817), 30: tensor(86.8550), 40: tensor(75.6150), 50: tensor(65.7033), 60: tensor(63.2617), 70: tensor(68.7150), 80: tensor(72.7967), 90: tensor(75.8133), 100: tensor(72.4083), 110: tensor(63.8283), 120: tensor(49.2450), 130: tensor(41.0067), 140: tensor(36.5867), 150: tensor(37.1833), 160: tensor(40.7350), 170: tensor(42.7933), 180: tensor(43.6833), 190: tensor(42.7833), 200: tensor(40.0717), 210: tensor(36.5733), 220: tensor(36.1983), 230: tensor(38.7033), 240: tensor(45.5600), 250: tensor(56.2217), 260: tensor(65.4650), 270: tensor(75.2900), 280: tensor(68.1283), 290: tensor(66.6517), 300: tensor(61.9800), 310: tensor(62.8750), 320: tensor(69.7500), 330: tensor(81.6517), 340: tensor(92.6683), 350: tensor(97.0017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=40, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3438,                   Accuracy: 396/2000.0 (19.80%)



-= Testing valid =-
Test set: Average loss: 1.7317,                   Accuracy: 715/2000.0 (35.75%)



-= Testing valid =-
Test set: Average loss: 0.6857,                   Accuracy: 1595/2000.0 (79.75%)



-= Testing valid =-
Test set: Average loss: 1.0877,                   Accuracy: 1166/2000.0 (58.30%)



-= Testing valid =-
Test set: Average loss: 0.2357,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1777,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.3026,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.1703,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.5879,                   Accuracy: 1526/2000.0 (76.30%)



Epoch 10 train accuracy: 97.66%, valid accuracy 76.30%
-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1585,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 98.88%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 99.28%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.69%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.60%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0524,                   Accuracy: 59081/60000 (98.47%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0855,                   Accuracy: 58564/60000 (97.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2030,                   Accuracy: 56623/60000 (94.37%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4952,                   Accuracy: 51833/60000 (86.39%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9335,                   Accuracy: 44999/60000 (75.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1942,                   Accuracy: 40402/60000 (67.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1715,                   Accuracy: 39964/60000 (66.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9007,                   Accuracy: 43120/60000 (71.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7365,                   Accuracy: 45428/60000 (75.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6470,                   Accuracy: 46753/60000 (77.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9389,                   Accuracy: 42609/60000 (71.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4641,                   Accuracy: 36125/60000 (60.21%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2163,                   Accuracy: 28823/60000 (48.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8983,                   Accuracy: 24569/60000 (40.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4138,                   Accuracy: 23690/60000 (39.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7452,                   Accuracy: 24836/60000 (41.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.9448,                   Accuracy: 27249/60000 (45.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1868,                   Accuracy: 29015/60000 (48.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.3888,                   Accuracy: 29359/60000 (48.93%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.2609,                   Accuracy: 29395/60000 (48.99%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.3722,                   Accuracy: 27078/60000 (45.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.2370,                   Accuracy: 24757/60000 (41.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9685,                   Accuracy: 23863/60000 (39.77%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5847,                   Accuracy: 25086/60000 (41.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9729,                   Accuracy: 28797/60000 (47.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.3240,                   Accuracy: 33482/60000 (55.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.6888,                   Accuracy: 37723/60000 (62.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.0822,                   Accuracy: 41953/60000 (69.92%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.0988,                   Accuracy: 40192/60000 (66.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1627,                   Accuracy: 38779/60000 (64.63%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3494,                   Accuracy: 36540/60000 (60.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4539,                   Accuracy: 36367/60000 (60.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2647,                   Accuracy: 40104/60000 (66.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7542,                   Accuracy: 47696/60000 (79.49%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2771,                   Accuracy: 55205/60000 (92.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0916,                   Accuracy: 58327/60000 (97.21%)
{0: tensor(98.4683), 10: tensor(97.6067), 20: tensor(94.3717), 30: tensor(86.3883), 40: tensor(74.9983), 50: tensor(67.3367), 60: tensor(66.6067), 70: tensor(71.8667), 80: tensor(75.7133), 90: tensor(77.9217), 100: tensor(71.0150), 110: tensor(60.2083), 120: tensor(48.0383), 130: tensor(40.9483), 140: tensor(39.4833), 150: tensor(41.3933), 160: tensor(45.4150), 170: tensor(48.3583), 180: tensor(48.9317), 190: tensor(48.9917), 200: tensor(45.1300), 210: tensor(41.2617), 220: tensor(39.7717), 230: tensor(41.8100), 240: tensor(47.9950), 250: tensor(55.8033), 260: tensor(62.8717), 270: tensor(69.9217), 280: tensor(66.9867), 290: tensor(64.6317), 300: tensor(60.9000), 310: tensor(60.6117), 320: tensor(66.8400), 330: tensor(79.4933), 340: tensor(92.0083), 350: tensor(97.2117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=11, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2726,                   Accuracy: 429/2000.0 (21.45%)



-= Testing valid =-
Test set: Average loss: 1.9865,                   Accuracy: 576/2000.0 (28.80%)



-= Testing valid =-
Test set: Average loss: 1.3023,                   Accuracy: 1161/2000.0 (58.05%)



-= Testing valid =-
Test set: Average loss: 0.4369,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.6988,                   Accuracy: 1524/2000.0 (76.20%)



-= Testing valid =-
Test set: Average loss: 0.1796,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.2767,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.1850,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 10 train accuracy: 98.14%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 20 train accuracy: 99.20%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 30 train accuracy: 99.49%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.76%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.76%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0540,                   Accuracy: 59037/60000 (98.39%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0847,                   Accuracy: 58557/60000 (97.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2084,                   Accuracy: 56398/60000 (94.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5026,                   Accuracy: 51179/60000 (85.30%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8522,                   Accuracy: 45444/60000 (75.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0470,                   Accuracy: 42078/60000 (70.13%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9439,                   Accuracy: 43185/60000 (71.97%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6742,                   Accuracy: 47484/60000 (79.14%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4585,                   Accuracy: 51056/60000 (85.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4776,                   Accuracy: 50525/60000 (84.21%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6565,                   Accuracy: 47391/60000 (78.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1560,                   Accuracy: 39774/60000 (66.29%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9030,                   Accuracy: 31480/60000 (52.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.5695,                   Accuracy: 26572/60000 (44.29%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.9517,                   Accuracy: 25129/60000 (41.88%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1108,                   Accuracy: 26097/60000 (43.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1375,                   Accuracy: 28828/60000 (48.05%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0475,                   Accuracy: 30710/60000 (51.18%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0947,                   Accuracy: 30784/60000 (51.31%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1383,                   Accuracy: 30269/60000 (50.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2877,                   Accuracy: 28562/60000 (47.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3577,                   Accuracy: 25598/60000 (42.66%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.1356,                   Accuracy: 25128/60000 (41.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5307,                   Accuracy: 27861/60000 (46.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.7317,                   Accuracy: 34194/60000 (56.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0625,                   Accuracy: 42108/60000 (70.18%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6593,                   Accuracy: 47546/60000 (79.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5172,                   Accuracy: 49726/60000 (82.88%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5380,                   Accuracy: 49424/60000 (82.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7763,                   Accuracy: 44918/60000 (74.86%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0460,                   Accuracy: 40585/60000 (67.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1613,                   Accuracy: 39231/60000 (65.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0104,                   Accuracy: 42424/60000 (70.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5563,                   Accuracy: 50089/60000 (83.48%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1821,                   Accuracy: 56692/60000 (94.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0706,                   Accuracy: 58721/60000 (97.87%)
{0: tensor(98.3950), 10: tensor(97.5950), 20: tensor(93.9967), 30: tensor(85.2983), 40: tensor(75.7400), 50: tensor(70.1300), 60: tensor(71.9750), 70: tensor(79.1400), 80: tensor(85.0933), 90: tensor(84.2083), 100: tensor(78.9850), 110: tensor(66.2900), 120: tensor(52.4667), 130: tensor(44.2867), 140: tensor(41.8817), 150: tensor(43.4950), 160: tensor(48.0467), 170: tensor(51.1833), 180: tensor(51.3067), 190: tensor(50.4483), 200: tensor(47.6033), 210: tensor(42.6633), 220: tensor(41.8800), 230: tensor(46.4350), 240: tensor(56.9900), 250: tensor(70.1800), 260: tensor(79.2433), 270: tensor(82.8767), 280: tensor(82.3733), 290: tensor(74.8633), 300: tensor(67.6417), 310: tensor(65.3850), 320: tensor(70.7067), 330: tensor(83.4817), 340: tensor(94.4867), 350: tensor(97.8683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=12, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.1244,                   Accuracy: 435/2000.0 (21.75%)



-= Testing valid =-
Test set: Average loss: 1.4801,                   Accuracy: 904/2000.0 (45.20%)



-= Testing valid =-
Test set: Average loss: 1.2006,                   Accuracy: 1212/2000.0 (60.60%)



-= Testing valid =-
Test set: Average loss: 0.2614,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.7235,                   Accuracy: 1580/2000.0 (79.00%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.6846,                   Accuracy: 1526/2000.0 (76.30%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 10 train accuracy: 97.93%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 20 train accuracy: 99.05%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.50%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.76%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0502,                   Accuracy: 59127/60000 (98.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0864,                   Accuracy: 58532/60000 (97.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2072,                   Accuracy: 56499/60000 (94.17%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5036,                   Accuracy: 51505/60000 (85.84%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0294,                   Accuracy: 43261/60000 (72.10%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3404,                   Accuracy: 38482/60000 (64.14%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2163,                   Accuracy: 39157/60000 (65.26%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9036,                   Accuracy: 43317/60000 (72.19%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7396,                   Accuracy: 45882/60000 (76.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7071,                   Accuracy: 46717/60000 (77.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0577,                   Accuracy: 41553/60000 (69.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7409,                   Accuracy: 34509/60000 (57.51%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6993,                   Accuracy: 27349/60000 (45.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5969,                   Accuracy: 22704/60000 (37.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9853,                   Accuracy: 22163/60000 (36.94%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9774,                   Accuracy: 23987/60000 (39.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.9609,                   Accuracy: 26450/60000 (44.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8841,                   Accuracy: 28363/60000 (47.27%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.8637,                   Accuracy: 28952/60000 (48.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.9360,                   Accuracy: 28109/60000 (46.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.0867,                   Accuracy: 26006/60000 (43.34%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3954,                   Accuracy: 23268/60000 (38.78%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.5261,                   Accuracy: 21747/60000 (36.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.0651,                   Accuracy: 23647/60000 (39.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.1602,                   Accuracy: 28263/60000 (47.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.1178,                   Accuracy: 34548/60000 (57.58%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.1733,                   Accuracy: 41897/60000 (69.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7310,                   Accuracy: 47121/60000 (78.54%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7171,                   Accuracy: 46935/60000 (78.22%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9119,                   Accuracy: 43347/60000 (72.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1485,                   Accuracy: 39140/60000 (65.23%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1782,                   Accuracy: 38279/60000 (63.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9189,                   Accuracy: 42873/60000 (71.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4941,                   Accuracy: 50451/60000 (84.08%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1870,                   Accuracy: 56484/60000 (94.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0738,                   Accuracy: 58653/60000 (97.75%)
{0: tensor(98.5450), 10: tensor(97.5533), 20: tensor(94.1650), 30: tensor(85.8417), 40: tensor(72.1017), 50: tensor(64.1367), 60: tensor(65.2617), 70: tensor(72.1950), 80: tensor(76.4700), 90: tensor(77.8617), 100: tensor(69.2550), 110: tensor(57.5150), 120: tensor(45.5817), 130: tensor(37.8400), 140: tensor(36.9383), 150: tensor(39.9783), 160: tensor(44.0833), 170: tensor(47.2717), 180: tensor(48.2533), 190: tensor(46.8483), 200: tensor(43.3433), 210: tensor(38.7800), 220: tensor(36.2450), 230: tensor(39.4117), 240: tensor(47.1050), 250: tensor(57.5800), 260: tensor(69.8283), 270: tensor(78.5350), 280: tensor(78.2250), 290: tensor(72.2450), 300: tensor(65.2333), 310: tensor(63.7983), 320: tensor(71.4550), 330: tensor(84.0850), 340: tensor(94.1400), 350: tensor(97.7550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=13, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.7468,                   Accuracy: 256/2000.0 (12.80%)



-= Testing valid =-
Test set: Average loss: 1.8619,                   Accuracy: 637/2000.0 (31.85%)



-= Testing valid =-
Test set: Average loss: 0.7259,                   Accuracy: 1489/2000.0 (74.45%)



-= Testing valid =-
Test set: Average loss: 0.2155,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2211,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1811,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 10 train accuracy: 97.95%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.47%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.59%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0537,                   Accuracy: 59033/60000 (98.39%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1073,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2742,                   Accuracy: 55365/60000 (92.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5315,                   Accuracy: 51394/60000 (85.66%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9497,                   Accuracy: 45211/60000 (75.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2643,                   Accuracy: 40680/60000 (67.80%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2256,                   Accuracy: 39996/60000 (66.66%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.1308,                   Accuracy: 40137/60000 (66.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8945,                   Accuracy: 42236/60000 (70.39%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8150,                   Accuracy: 43278/60000 (72.13%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2948,                   Accuracy: 35897/60000 (59.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9770,                   Accuracy: 30556/60000 (50.93%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7265,                   Accuracy: 26000/60000 (43.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5972,                   Accuracy: 23295/60000 (38.83%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.2598,                   Accuracy: 22197/60000 (36.99%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.6436,                   Accuracy: 24039/60000 (40.06%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.8486,                   Accuracy: 25728/60000 (42.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.0302,                   Accuracy: 27645/60000 (46.08%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.1770,                   Accuracy: 28661/60000 (47.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.2492,                   Accuracy: 26854/60000 (44.76%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.3370,                   Accuracy: 24633/60000 (41.06%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.0021,                   Accuracy: 23399/60000 (39.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.5188,                   Accuracy: 22396/60000 (37.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.7782,                   Accuracy: 23911/60000 (39.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7733,                   Accuracy: 28556/60000 (47.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.8379,                   Accuracy: 33965/60000 (56.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2278,                   Accuracy: 38484/60000 (64.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.8068,                   Accuracy: 43324/60000 (72.21%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8104,                   Accuracy: 43583/60000 (72.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0652,                   Accuracy: 40084/60000 (66.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2712,                   Accuracy: 38554/60000 (64.26%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3437,                   Accuracy: 38690/60000 (64.48%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1522,                   Accuracy: 42296/60000 (70.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6478,                   Accuracy: 49586/60000 (82.64%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2793,                   Accuracy: 55281/60000 (92.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0963,                   Accuracy: 58333/60000 (97.22%)
{0: tensor(98.3883), 10: tensor(96.8500), 20: tensor(92.2750), 30: tensor(85.6567), 40: tensor(75.3517), 50: tensor(67.8000), 60: tensor(66.6600), 70: tensor(66.8950), 80: tensor(70.3933), 90: tensor(72.1300), 100: tensor(59.8283), 110: tensor(50.9267), 120: tensor(43.3333), 130: tensor(38.8250), 140: tensor(36.9950), 150: tensor(40.0650), 160: tensor(42.8800), 170: tensor(46.0750), 180: tensor(47.7683), 190: tensor(44.7567), 200: tensor(41.0550), 210: tensor(38.9983), 220: tensor(37.3267), 230: tensor(39.8517), 240: tensor(47.5933), 250: tensor(56.6083), 260: tensor(64.1400), 270: tensor(72.2067), 280: tensor(72.6383), 290: tensor(66.8067), 300: tensor(64.2567), 310: tensor(64.4833), 320: tensor(70.4933), 330: tensor(82.6433), 340: tensor(92.1350), 350: tensor(97.2217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=14, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8357,                   Accuracy: 427/2000.0 (21.35%)



-= Testing valid =-
Test set: Average loss: 1.5715,                   Accuracy: 770/2000.0 (38.50%)



-= Testing valid =-
Test set: Average loss: 1.0378,                   Accuracy: 1288/2000.0 (64.40%)



-= Testing valid =-
Test set: Average loss: 0.5325,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.1423,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.2165,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.4070,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.1835,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 98.06%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.04%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.46%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.65%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0478,                   Accuracy: 59162/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0835,                   Accuracy: 58485/60000 (97.47%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2009,                   Accuracy: 56521/60000 (94.20%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4960,                   Accuracy: 51552/60000 (85.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8931,                   Accuracy: 44822/60000 (74.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0496,                   Accuracy: 41987/60000 (69.98%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8967,                   Accuracy: 44025/60000 (73.38%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6182,                   Accuracy: 48282/60000 (80.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5297,                   Accuracy: 49766/60000 (82.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5061,                   Accuracy: 49921/60000 (83.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9171,                   Accuracy: 42820/60000 (71.37%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6222,                   Accuracy: 34256/60000 (57.09%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5190,                   Accuracy: 26875/60000 (44.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3963,                   Accuracy: 23577/60000 (39.29%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6760,                   Accuracy: 24323/60000 (40.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5828,                   Accuracy: 27409/60000 (45.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4124,                   Accuracy: 30650/60000 (51.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4309,                   Accuracy: 32005/60000 (53.34%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4131,                   Accuracy: 32273/60000 (53.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6158,                   Accuracy: 31000/60000 (51.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7449,                   Accuracy: 29016/60000 (48.36%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9808,                   Accuracy: 26336/60000 (43.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8095,                   Accuracy: 25546/60000 (42.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1450,                   Accuracy: 28025/60000 (46.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1019,                   Accuracy: 34802/60000 (58.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1917,                   Accuracy: 42643/60000 (71.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6682,                   Accuracy: 48484/60000 (80.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3575,                   Accuracy: 52983/60000 (88.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5029,                   Accuracy: 49715/60000 (82.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7650,                   Accuracy: 44614/60000 (74.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0292,                   Accuracy: 39955/60000 (66.59%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2382,                   Accuracy: 36831/60000 (61.38%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0726,                   Accuracy: 39805/60000 (66.34%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5737,                   Accuracy: 48919/60000 (81.53%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2070,                   Accuracy: 55908/60000 (93.18%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0752,                   Accuracy: 58611/60000 (97.68%)
{0: tensor(98.6033), 10: tensor(97.4750), 20: tensor(94.2017), 30: tensor(85.9200), 40: tensor(74.7033), 50: tensor(69.9783), 60: tensor(73.3750), 70: tensor(80.4700), 80: tensor(82.9433), 90: tensor(83.2017), 100: tensor(71.3667), 110: tensor(57.0933), 120: tensor(44.7917), 130: tensor(39.2950), 140: tensor(40.5383), 150: tensor(45.6817), 160: tensor(51.0833), 170: tensor(53.3417), 180: tensor(53.7883), 190: tensor(51.6667), 200: tensor(48.3600), 210: tensor(43.8933), 220: tensor(42.5767), 230: tensor(46.7083), 240: tensor(58.0033), 250: tensor(71.0717), 260: tensor(80.8067), 270: tensor(88.3050), 280: tensor(82.8583), 290: tensor(74.3567), 300: tensor(66.5917), 310: tensor(61.3850), 320: tensor(66.3417), 330: tensor(81.5317), 340: tensor(93.1800), 350: tensor(97.6850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=15, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3766,                   Accuracy: 323/2000.0 (16.15%)



-= Testing valid =-
Test set: Average loss: 1.1235,                   Accuracy: 1232/2000.0 (61.60%)



-= Testing valid =-
Test set: Average loss: 0.7640,                   Accuracy: 1537/2000.0 (76.85%)



-= Testing valid =-
Test set: Average loss: 0.1896,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2644,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1601,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1821,                   Accuracy: 1891/2000.0 (94.55%)



Epoch 10 train accuracy: 98.20%, valid accuracy 94.55%
-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.29%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.70%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0488,                   Accuracy: 59166/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0790,                   Accuracy: 58671/60000 (97.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1628,                   Accuracy: 57324/60000 (95.54%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3782,                   Accuracy: 53594/60000 (89.32%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7085,                   Accuracy: 48045/60000 (80.07%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8976,                   Accuracy: 44521/60000 (74.20%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8993,                   Accuracy: 43802/60000 (73.00%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7266,                   Accuracy: 46511/60000 (77.52%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5653,                   Accuracy: 49307/60000 (82.18%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6343,                   Accuracy: 48157/60000 (80.26%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9841,                   Accuracy: 43296/60000 (72.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6104,                   Accuracy: 36930/60000 (61.55%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6855,                   Accuracy: 28782/60000 (47.97%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5442,                   Accuracy: 25283/60000 (42.14%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.0939,                   Accuracy: 24453/60000 (40.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.4126,                   Accuracy: 25553/60000 (42.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.5000,                   Accuracy: 27746/60000 (46.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.6139,                   Accuracy: 29455/60000 (49.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.8265,                   Accuracy: 29227/60000 (48.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.7965,                   Accuracy: 28862/60000 (48.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.8901,                   Accuracy: 27142/60000 (45.24%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.9161,                   Accuracy: 24747/60000 (41.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.6294,                   Accuracy: 23722/60000 (39.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.0059,                   Accuracy: 24897/60000 (41.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.0844,                   Accuracy: 27608/60000 (46.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.2062,                   Accuracy: 32430/60000 (54.05%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.4390,                   Accuracy: 38307/60000 (63.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.0273,                   Accuracy: 42877/60000 (71.46%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.0736,                   Accuracy: 41792/60000 (69.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1326,                   Accuracy: 40737/60000 (67.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2442,                   Accuracy: 38086/60000 (63.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1597,                   Accuracy: 39145/60000 (65.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8674,                   Accuracy: 43799/60000 (73.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4551,                   Accuracy: 51369/60000 (85.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1721,                   Accuracy: 56798/60000 (94.66%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0716,                   Accuracy: 58684/60000 (97.81%)
{0: tensor(98.6100), 10: tensor(97.7850), 20: tensor(95.5400), 30: tensor(89.3233), 40: tensor(80.0750), 50: tensor(74.2017), 60: tensor(73.0033), 70: tensor(77.5183), 80: tensor(82.1783), 90: tensor(80.2617), 100: tensor(72.1600), 110: tensor(61.5500), 120: tensor(47.9700), 130: tensor(42.1383), 140: tensor(40.7550), 150: tensor(42.5883), 160: tensor(46.2433), 170: tensor(49.0917), 180: tensor(48.7117), 190: tensor(48.1033), 200: tensor(45.2367), 210: tensor(41.2450), 220: tensor(39.5367), 230: tensor(41.4950), 240: tensor(46.0133), 250: tensor(54.0500), 260: tensor(63.8450), 270: tensor(71.4617), 280: tensor(69.6533), 290: tensor(67.8950), 300: tensor(63.4767), 310: tensor(65.2417), 320: tensor(72.9983), 330: tensor(85.6150), 340: tensor(94.6633), 350: tensor(97.8067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=16, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3825,                   Accuracy: 444/2000.0 (22.20%)



-= Testing valid =-
Test set: Average loss: 1.0760,                   Accuracy: 1209/2000.0 (60.45%)



-= Testing valid =-
Test set: Average loss: 0.5328,                   Accuracy: 1686/2000.0 (84.30%)



-= Testing valid =-
Test set: Average loss: 0.2974,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.5180,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1355,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 10 train accuracy: 98.25%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 20 train accuracy: 98.89%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.72%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0555,                   Accuracy: 59046/60000 (98.41%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0795,                   Accuracy: 58656/60000 (97.76%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1818,                   Accuracy: 56893/60000 (94.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4564,                   Accuracy: 52087/60000 (86.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8793,                   Accuracy: 45019/60000 (75.03%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0848,                   Accuracy: 41549/60000 (69.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9368,                   Accuracy: 43377/60000 (72.29%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6308,                   Accuracy: 48146/60000 (80.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4760,                   Accuracy: 50573/60000 (84.29%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4793,                   Accuracy: 50370/60000 (83.95%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8030,                   Accuracy: 44687/60000 (74.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3535,                   Accuracy: 37573/60000 (62.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2554,                   Accuracy: 29616/60000 (49.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0860,                   Accuracy: 25498/60000 (42.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4814,                   Accuracy: 24879/60000 (41.47%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5318,                   Accuracy: 26584/60000 (44.31%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4746,                   Accuracy: 29550/60000 (49.25%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3110,                   Accuracy: 31090/60000 (51.82%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1781,                   Accuracy: 30755/60000 (51.26%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2636,                   Accuracy: 30191/60000 (50.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3043,                   Accuracy: 28105/60000 (46.84%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4797,                   Accuracy: 25045/60000 (41.74%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4104,                   Accuracy: 24102/60000 (40.17%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9884,                   Accuracy: 25961/60000 (43.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1923,                   Accuracy: 30918/60000 (51.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3083,                   Accuracy: 38925/60000 (64.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7265,                   Accuracy: 46046/60000 (76.74%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4285,                   Accuracy: 51268/60000 (85.45%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4825,                   Accuracy: 50953/60000 (84.92%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7921,                   Accuracy: 45586/60000 (75.98%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2037,                   Accuracy: 39869/60000 (66.45%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4618,                   Accuracy: 36586/60000 (60.98%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3018,                   Accuracy: 39477/60000 (65.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7226,                   Accuracy: 47623/60000 (79.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2575,                   Accuracy: 55419/60000 (92.36%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0899,                   Accuracy: 58439/60000 (97.40%)
{0: tensor(98.4100), 10: tensor(97.7600), 20: tensor(94.8217), 30: tensor(86.8117), 40: tensor(75.0317), 50: tensor(69.2483), 60: tensor(72.2950), 70: tensor(80.2433), 80: tensor(84.2883), 90: tensor(83.9500), 100: tensor(74.4783), 110: tensor(62.6217), 120: tensor(49.3600), 130: tensor(42.4967), 140: tensor(41.4650), 150: tensor(44.3067), 160: tensor(49.2500), 170: tensor(51.8167), 180: tensor(51.2583), 190: tensor(50.3183), 200: tensor(46.8417), 210: tensor(41.7417), 220: tensor(40.1700), 230: tensor(43.2683), 240: tensor(51.5300), 250: tensor(64.8750), 260: tensor(76.7433), 270: tensor(85.4467), 280: tensor(84.9217), 290: tensor(75.9767), 300: tensor(66.4483), 310: tensor(60.9767), 320: tensor(65.7950), 330: tensor(79.3717), 340: tensor(92.3650), 350: tensor(97.3983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=17, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4277,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 7.4377,                   Accuracy: 218/2000.0 (10.90%)



-= Testing valid =-
Test set: Average loss: 1.1715,                   Accuracy: 996/2000.0 (49.80%)



-= Testing valid =-
Test set: Average loss: 1.0405,                   Accuracy: 1372/2000.0 (68.60%)



-= Testing valid =-
Test set: Average loss: 0.6880,                   Accuracy: 1564/2000.0 (78.20%)



-= Testing valid =-
Test set: Average loss: 0.1946,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.2184,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1603,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 10 train accuracy: 98.26%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.54%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0505,                   Accuracy: 59143/60000 (98.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0722,                   Accuracy: 58752/60000 (97.92%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1651,                   Accuracy: 57140/60000 (95.23%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4678,                   Accuracy: 51777/60000 (86.29%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9028,                   Accuracy: 44037/60000 (73.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2007,                   Accuracy: 39091/60000 (65.15%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1491,                   Accuracy: 39543/60000 (65.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7924,                   Accuracy: 44871/60000 (74.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5575,                   Accuracy: 48979/60000 (81.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5150,                   Accuracy: 49726/60000 (82.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7298,                   Accuracy: 45859/60000 (76.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2881,                   Accuracy: 37945/60000 (63.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1772,                   Accuracy: 27950/60000 (46.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8967,                   Accuracy: 23458/60000 (39.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3440,                   Accuracy: 22314/60000 (37.19%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3774,                   Accuracy: 23838/60000 (39.73%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1573,                   Accuracy: 27741/60000 (46.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0178,                   Accuracy: 30457/60000 (50.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0029,                   Accuracy: 31542/60000 (52.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.9339,                   Accuracy: 31359/60000 (52.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2309,                   Accuracy: 28554/60000 (47.59%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6231,                   Accuracy: 23978/60000 (39.96%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5302,                   Accuracy: 21920/60000 (36.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0133,                   Accuracy: 24142/60000 (40.24%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0596,                   Accuracy: 30841/60000 (51.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1703,                   Accuracy: 40190/60000 (66.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6999,                   Accuracy: 46300/60000 (77.17%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5064,                   Accuracy: 49761/60000 (82.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6273,                   Accuracy: 48177/60000 (80.29%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9101,                   Accuracy: 43625/60000 (72.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3774,                   Accuracy: 37039/60000 (61.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5084,                   Accuracy: 35819/60000 (59.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3592,                   Accuracy: 39379/60000 (65.63%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8477,                   Accuracy: 47343/60000 (78.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2792,                   Accuracy: 55281/60000 (92.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0792,                   Accuracy: 58578/60000 (97.63%)
{0: tensor(98.5717), 10: tensor(97.9200), 20: tensor(95.2333), 30: tensor(86.2950), 40: tensor(73.3950), 50: tensor(65.1517), 60: tensor(65.9050), 70: tensor(74.7850), 80: tensor(81.6317), 90: tensor(82.8767), 100: tensor(76.4317), 110: tensor(63.2417), 120: tensor(46.5833), 130: tensor(39.0967), 140: tensor(37.1900), 150: tensor(39.7300), 160: tensor(46.2350), 170: tensor(50.7617), 180: tensor(52.5700), 190: tensor(52.2650), 200: tensor(47.5900), 210: tensor(39.9633), 220: tensor(36.5333), 230: tensor(40.2367), 240: tensor(51.4017), 250: tensor(66.9833), 260: tensor(77.1667), 270: tensor(82.9350), 280: tensor(80.2950), 290: tensor(72.7083), 300: tensor(61.7317), 310: tensor(59.6983), 320: tensor(65.6317), 330: tensor(78.9050), 340: tensor(92.1350), 350: tensor(97.6300)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=18, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7748,                   Accuracy: 219/2000.0 (10.95%)



-= Testing valid =-
Test set: Average loss: 1.8704,                   Accuracy: 743/2000.0 (37.15%)



-= Testing valid =-
Test set: Average loss: 1.0656,                   Accuracy: 1140/2000.0 (57.00%)



-= Testing valid =-
Test set: Average loss: 0.3033,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1840,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.2211,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 10 train accuracy: 98.40%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 99.15%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 30 train accuracy: 99.47%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.72%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0520,                   Accuracy: 59110/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0798,                   Accuracy: 58619/60000 (97.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1816,                   Accuracy: 56892/60000 (94.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5129,                   Accuracy: 51536/60000 (85.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9245,                   Accuracy: 44688/60000 (74.48%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2287,                   Accuracy: 39461/60000 (65.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1453,                   Accuracy: 39927/60000 (66.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7674,                   Accuracy: 45560/60000 (75.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4942,                   Accuracy: 50702/60000 (84.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4871,                   Accuracy: 51354/60000 (85.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8129,                   Accuracy: 46121/60000 (76.87%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3826,                   Accuracy: 39690/60000 (66.15%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4440,                   Accuracy: 30519/60000 (50.87%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4265,                   Accuracy: 25557/60000 (42.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.0661,                   Accuracy: 24512/60000 (40.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.3411,                   Accuracy: 25704/60000 (42.84%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1425,                   Accuracy: 28245/60000 (47.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.2531,                   Accuracy: 29174/60000 (48.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.2745,                   Accuracy: 29442/60000 (49.07%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.2095,                   Accuracy: 29015/60000 (48.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1644,                   Accuracy: 27278/60000 (45.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3599,                   Accuracy: 23917/60000 (39.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0806,                   Accuracy: 22783/60000 (37.97%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4764,                   Accuracy: 24206/60000 (40.34%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6454,                   Accuracy: 28002/60000 (46.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6580,                   Accuracy: 34780/60000 (57.97%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0808,                   Accuracy: 39734/60000 (66.22%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.9239,                   Accuracy: 42751/60000 (71.25%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8618,                   Accuracy: 43041/60000 (71.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0730,                   Accuracy: 40494/60000 (67.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5752,                   Accuracy: 35880/60000 (59.80%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6367,                   Accuracy: 36463/60000 (60.77%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3984,                   Accuracy: 40799/60000 (68.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7743,                   Accuracy: 48397/60000 (80.66%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2457,                   Accuracy: 55791/60000 (92.99%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0785,                   Accuracy: 58587/60000 (97.64%)
{0: tensor(98.5167), 10: tensor(97.6983), 20: tensor(94.8200), 30: tensor(85.8933), 40: tensor(74.4800), 50: tensor(65.7683), 60: tensor(66.5450), 70: tensor(75.9333), 80: tensor(84.5033), 90: tensor(85.5900), 100: tensor(76.8683), 110: tensor(66.1500), 120: tensor(50.8650), 130: tensor(42.5950), 140: tensor(40.8533), 150: tensor(42.8400), 160: tensor(47.0750), 170: tensor(48.6233), 180: tensor(49.0700), 190: tensor(48.3583), 200: tensor(45.4633), 210: tensor(39.8617), 220: tensor(37.9717), 230: tensor(40.3433), 240: tensor(46.6700), 250: tensor(57.9667), 260: tensor(66.2233), 270: tensor(71.2517), 280: tensor(71.7350), 290: tensor(67.4900), 300: tensor(59.8000), 310: tensor(60.7717), 320: tensor(67.9983), 330: tensor(80.6617), 340: tensor(92.9850), 350: tensor(97.6450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=19, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6368,                   Accuracy: 299/2000.0 (14.95%)



-= Testing valid =-
Test set: Average loss: 2.0401,                   Accuracy: 415/2000.0 (20.75%)



-= Testing valid =-
Test set: Average loss: 2.0081,                   Accuracy: 779/2000.0 (38.95%)



-= Testing valid =-
Test set: Average loss: 0.5595,                   Accuracy: 1701/2000.0 (85.05%)



-= Testing valid =-
Test set: Average loss: 0.2177,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1599,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 98.22%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 99.31%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.85%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0470,                   Accuracy: 59190/60000 (98.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0787,                   Accuracy: 58649/60000 (97.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1840,                   Accuracy: 56713/60000 (94.52%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5131,                   Accuracy: 51092/60000 (85.15%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9480,                   Accuracy: 43974/60000 (73.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2535,                   Accuracy: 38863/60000 (64.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1539,                   Accuracy: 39229/60000 (65.38%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9270,                   Accuracy: 42532/60000 (70.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8146,                   Accuracy: 45238/60000 (75.40%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8287,                   Accuracy: 45718/60000 (76.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3128,                   Accuracy: 40279/60000 (67.13%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9174,                   Accuracy: 33995/60000 (56.66%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7655,                   Accuracy: 25844/60000 (43.07%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6092,                   Accuracy: 22001/60000 (36.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.0413,                   Accuracy: 21474/60000 (35.79%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.0692,                   Accuracy: 24560/60000 (40.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1047,                   Accuracy: 27997/60000 (46.66%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1382,                   Accuracy: 29438/60000 (49.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.1103,                   Accuracy: 30319/60000 (50.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.3140,                   Accuracy: 29747/60000 (49.58%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.3958,                   Accuracy: 28304/60000 (47.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3403,                   Accuracy: 25483/60000 (42.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.1060,                   Accuracy: 24285/60000 (40.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4249,                   Accuracy: 26093/60000 (43.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5517,                   Accuracy: 30256/60000 (50.43%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7144,                   Accuracy: 35821/60000 (59.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.1604,                   Accuracy: 40920/60000 (68.20%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7711,                   Accuracy: 45583/60000 (75.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8532,                   Accuracy: 43077/60000 (71.79%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0560,                   Accuracy: 39303/60000 (65.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4125,                   Accuracy: 33619/60000 (56.03%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4740,                   Accuracy: 33122/60000 (55.20%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2335,                   Accuracy: 37983/60000 (63.31%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6286,                   Accuracy: 48219/60000 (80.36%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1861,                   Accuracy: 56457/60000 (94.10%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0712,                   Accuracy: 58718/60000 (97.86%)
{0: tensor(98.6500), 10: tensor(97.7483), 20: tensor(94.5217), 30: tensor(85.1533), 40: tensor(73.2900), 50: tensor(64.7717), 60: tensor(65.3817), 70: tensor(70.8867), 80: tensor(75.3967), 90: tensor(76.1967), 100: tensor(67.1317), 110: tensor(56.6583), 120: tensor(43.0733), 130: tensor(36.6683), 140: tensor(35.7900), 150: tensor(40.9333), 160: tensor(46.6617), 170: tensor(49.0633), 180: tensor(50.5317), 190: tensor(49.5783), 200: tensor(47.1733), 210: tensor(42.4717), 220: tensor(40.4750), 230: tensor(43.4883), 240: tensor(50.4267), 250: tensor(59.7017), 260: tensor(68.2000), 270: tensor(75.9717), 280: tensor(71.7950), 290: tensor(65.5050), 300: tensor(56.0317), 310: tensor(55.2033), 320: tensor(63.3050), 330: tensor(80.3650), 340: tensor(94.0950), 350: tensor(97.8633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=20, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.8642,                   Accuracy: 234/2000.0 (11.70%)



-= Testing valid =-
Test set: Average loss: 2.0626,                   Accuracy: 693/2000.0 (34.65%)



-= Testing valid =-
Test set: Average loss: 1.4551,                   Accuracy: 911/2000.0 (45.55%)



-= Testing valid =-
Test set: Average loss: 0.3093,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 10 train accuracy: 98.24%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.97%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 99.51%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.59%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.76%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0563,                   Accuracy: 59025/60000 (98.38%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0913,                   Accuracy: 58425/60000 (97.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2152,                   Accuracy: 56385/60000 (93.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5325,                   Accuracy: 51015/60000 (85.03%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9757,                   Accuracy: 43931/60000 (73.22%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1942,                   Accuracy: 40624/60000 (67.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0195,                   Accuracy: 43080/60000 (71.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7248,                   Accuracy: 47351/60000 (78.92%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5163,                   Accuracy: 50290/60000 (83.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4699,                   Accuracy: 50920/60000 (84.87%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7282,                   Accuracy: 45568/60000 (75.95%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2329,                   Accuracy: 37814/60000 (63.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9712,                   Accuracy: 29967/60000 (49.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7496,                   Accuracy: 24726/60000 (41.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1929,                   Accuracy: 23246/60000 (38.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3186,                   Accuracy: 23824/60000 (39.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2844,                   Accuracy: 25894/60000 (43.16%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3293,                   Accuracy: 27705/60000 (46.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4534,                   Accuracy: 28655/60000 (47.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4681,                   Accuracy: 29215/60000 (48.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5700,                   Accuracy: 28203/60000 (47.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7232,                   Accuracy: 26334/60000 (43.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4652,                   Accuracy: 25460/60000 (42.43%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7838,                   Accuracy: 28083/60000 (46.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8744,                   Accuracy: 33981/60000 (56.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0998,                   Accuracy: 41854/60000 (69.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6109,                   Accuracy: 48430/60000 (80.72%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4140,                   Accuracy: 51769/60000 (86.28%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4881,                   Accuracy: 50458/60000 (84.10%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7137,                   Accuracy: 46478/60000 (77.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0056,                   Accuracy: 41639/60000 (69.40%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1184,                   Accuracy: 39650/60000 (66.08%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9359,                   Accuracy: 42734/60000 (71.22%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5274,                   Accuracy: 49775/60000 (82.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2092,                   Accuracy: 55914/60000 (93.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0788,                   Accuracy: 58570/60000 (97.62%)
{0: tensor(98.3750), 10: tensor(97.3750), 20: tensor(93.9750), 30: tensor(85.0250), 40: tensor(73.2183), 50: tensor(67.7067), 60: tensor(71.8000), 70: tensor(78.9183), 80: tensor(83.8167), 90: tensor(84.8667), 100: tensor(75.9467), 110: tensor(63.0233), 120: tensor(49.9450), 130: tensor(41.2100), 140: tensor(38.7433), 150: tensor(39.7067), 160: tensor(43.1567), 170: tensor(46.1750), 180: tensor(47.7583), 190: tensor(48.6917), 200: tensor(47.0050), 210: tensor(43.8900), 220: tensor(42.4333), 230: tensor(46.8050), 240: tensor(56.6350), 250: tensor(69.7567), 260: tensor(80.7167), 270: tensor(86.2817), 280: tensor(84.0967), 290: tensor(77.4633), 300: tensor(69.3983), 310: tensor(66.0833), 320: tensor(71.2233), 330: tensor(82.9583), 340: tensor(93.1900), 350: tensor(97.6167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=21, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2047,                   Accuracy: 400/2000.0 (20.00%)



-= Testing valid =-
Test set: Average loss: 1.3952,                   Accuracy: 1039/2000.0 (51.95%)



-= Testing valid =-
Test set: Average loss: 1.9111,                   Accuracy: 869/2000.0 (43.45%)



-= Testing valid =-
Test set: Average loss: 0.4023,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.3413,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.1359,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 97.75%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.44%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.68%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0474,                   Accuracy: 59190/60000 (98.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0756,                   Accuracy: 58723/60000 (97.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1824,                   Accuracy: 56885/60000 (94.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4767,                   Accuracy: 51870/60000 (86.45%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8939,                   Accuracy: 44667/60000 (74.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1903,                   Accuracy: 39741/60000 (66.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0445,                   Accuracy: 41747/60000 (69.58%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7560,                   Accuracy: 46122/60000 (76.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5703,                   Accuracy: 48899/60000 (81.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5502,                   Accuracy: 48817/60000 (81.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8809,                   Accuracy: 43071/60000 (71.79%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4917,                   Accuracy: 36143/60000 (60.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3282,                   Accuracy: 28220/60000 (47.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0460,                   Accuracy: 24357/60000 (40.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4134,                   Accuracy: 23725/60000 (39.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4974,                   Accuracy: 25536/60000 (42.56%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4798,                   Accuracy: 28523/60000 (47.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5495,                   Accuracy: 30136/60000 (50.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.8972,                   Accuracy: 29365/60000 (48.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7829,                   Accuracy: 28990/60000 (48.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9400,                   Accuracy: 27156/60000 (45.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0496,                   Accuracy: 23706/60000 (39.51%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6434,                   Accuracy: 22558/60000 (37.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8627,                   Accuracy: 25266/60000 (42.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9012,                   Accuracy: 31956/60000 (53.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1669,                   Accuracy: 39355/60000 (65.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7947,                   Accuracy: 44337/60000 (73.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5865,                   Accuracy: 47467/60000 (79.11%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7156,                   Accuracy: 45833/60000 (76.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0200,                   Accuracy: 42031/60000 (70.05%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3929,                   Accuracy: 37241/60000 (62.07%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5149,                   Accuracy: 35223/60000 (58.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2826,                   Accuracy: 39892/60000 (66.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6655,                   Accuracy: 49104/60000 (81.84%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2106,                   Accuracy: 56167/60000 (93.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0763,                   Accuracy: 58645/60000 (97.74%)
{0: tensor(98.6500), 10: tensor(97.8717), 20: tensor(94.8083), 30: tensor(86.4500), 40: tensor(74.4450), 50: tensor(66.2350), 60: tensor(69.5783), 70: tensor(76.8700), 80: tensor(81.4983), 90: tensor(81.3617), 100: tensor(71.7850), 110: tensor(60.2383), 120: tensor(47.0333), 130: tensor(40.5950), 140: tensor(39.5417), 150: tensor(42.5600), 160: tensor(47.5383), 170: tensor(50.2267), 180: tensor(48.9417), 190: tensor(48.3167), 200: tensor(45.2600), 210: tensor(39.5100), 220: tensor(37.5967), 230: tensor(42.1100), 240: tensor(53.2600), 250: tensor(65.5917), 260: tensor(73.8950), 270: tensor(79.1117), 280: tensor(76.3883), 290: tensor(70.0517), 300: tensor(62.0683), 310: tensor(58.7050), 320: tensor(66.4867), 330: tensor(81.8400), 340: tensor(93.6117), 350: tensor(97.7417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=22, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2911,                   Accuracy: 405/2000.0 (20.25%)



-= Testing valid =-
Test set: Average loss: 1.1786,                   Accuracy: 1301/2000.0 (65.05%)



-= Testing valid =-
Test set: Average loss: 0.6527,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.3883,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.5729,                   Accuracy: 1662/2000.0 (83.10%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 10 train accuracy: 97.68%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.18%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.28%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0508,                   Accuracy: 59108/60000 (98.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0791,                   Accuracy: 58597/60000 (97.66%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1668,                   Accuracy: 57082/60000 (95.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3664,                   Accuracy: 53672/60000 (89.45%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6067,                   Accuracy: 49308/60000 (82.18%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7023,                   Accuracy: 47364/60000 (78.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6374,                   Accuracy: 48283/60000 (80.47%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5034,                   Accuracy: 50554/60000 (84.26%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4391,                   Accuracy: 51007/60000 (85.01%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4687,                   Accuracy: 50327/60000 (83.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7214,                   Accuracy: 46384/60000 (77.31%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1821,                   Accuracy: 39680/60000 (66.13%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9684,                   Accuracy: 31109/60000 (51.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7185,                   Accuracy: 26541/60000 (44.24%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1538,                   Accuracy: 25932/60000 (43.22%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2861,                   Accuracy: 27506/60000 (45.84%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2484,                   Accuracy: 30485/60000 (50.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2348,                   Accuracy: 32668/60000 (54.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4237,                   Accuracy: 32883/60000 (54.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4305,                   Accuracy: 32285/60000 (53.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6263,                   Accuracy: 30301/60000 (50.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8884,                   Accuracy: 27261/60000 (45.44%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5166,                   Accuracy: 26628/60000 (44.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7932,                   Accuracy: 30100/60000 (50.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8525,                   Accuracy: 36620/60000 (61.03%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.9752,                   Accuracy: 45346/60000 (75.58%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4950,                   Accuracy: 51654/60000 (86.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3418,                   Accuracy: 53895/60000 (89.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3791,                   Accuracy: 53173/60000 (88.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5170,                   Accuracy: 50353/60000 (83.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7160,                   Accuracy: 46929/60000 (78.21%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7025,                   Accuracy: 46959/60000 (78.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.5901,                   Accuracy: 49097/60000 (81.83%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3381,                   Accuracy: 53731/60000 (89.55%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1499,                   Accuracy: 57299/60000 (95.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0743,                   Accuracy: 58667/60000 (97.78%)
{0: tensor(98.5133), 10: tensor(97.6617), 20: tensor(95.1367), 30: tensor(89.4533), 40: tensor(82.1800), 50: tensor(78.9400), 60: tensor(80.4717), 70: tensor(84.2567), 80: tensor(85.0117), 90: tensor(83.8783), 100: tensor(77.3067), 110: tensor(66.1333), 120: tensor(51.8483), 130: tensor(44.2350), 140: tensor(43.2200), 150: tensor(45.8433), 160: tensor(50.8083), 170: tensor(54.4467), 180: tensor(54.8050), 190: tensor(53.8083), 200: tensor(50.5017), 210: tensor(45.4350), 220: tensor(44.3800), 230: tensor(50.1667), 240: tensor(61.0333), 250: tensor(75.5767), 260: tensor(86.0900), 270: tensor(89.8250), 280: tensor(88.6217), 290: tensor(83.9217), 300: tensor(78.2150), 310: tensor(78.2650), 320: tensor(81.8283), 330: tensor(89.5517), 340: tensor(95.4983), 350: tensor(97.7783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=23, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0151,                   Accuracy: 232/2000.0 (11.60%)



-= Testing valid =-
Test set: Average loss: 2.6295,                   Accuracy: 397/2000.0 (19.85%)



-= Testing valid =-
Test set: Average loss: 1.3717,                   Accuracy: 1024/2000.0 (51.20%)



-= Testing valid =-
Test set: Average loss: 0.8113,                   Accuracy: 1500/2000.0 (75.00%)



-= Testing valid =-
Test set: Average loss: 0.3401,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3718,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.6611,                   Accuracy: 1617/2000.0 (80.85%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1886/2000.0 (94.30%)



Epoch 10 train accuracy: 98.07%, valid accuracy 94.30%
-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 99.12%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.59%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 40 train accuracy: 99.61%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 50 train accuracy: 99.61%, valid accuracy 98.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0720,                   Accuracy: 58742/60000 (97.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0989,                   Accuracy: 58252/60000 (97.09%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2131,                   Accuracy: 56215/60000 (93.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4783,                   Accuracy: 51080/60000 (85.13%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8220,                   Accuracy: 44303/60000 (73.84%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1197,                   Accuracy: 38340/60000 (63.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1532,                   Accuracy: 36154/60000 (60.26%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0151,                   Accuracy: 37159/60000 (61.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8976,                   Accuracy: 38336/60000 (63.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9680,                   Accuracy: 36584/60000 (60.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1126,                   Accuracy: 35094/60000 (58.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5706,                   Accuracy: 29743/60000 (49.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2051,                   Accuracy: 24662/60000 (41.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8922,                   Accuracy: 21612/60000 (36.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2886,                   Accuracy: 21864/60000 (36.44%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4983,                   Accuracy: 23086/60000 (38.48%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5652,                   Accuracy: 25784/60000 (42.97%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5709,                   Accuracy: 26633/60000 (44.39%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5864,                   Accuracy: 26721/60000 (44.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5351,                   Accuracy: 27190/60000 (45.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6647,                   Accuracy: 25067/60000 (41.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6639,                   Accuracy: 23044/60000 (38.41%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4343,                   Accuracy: 22551/60000 (37.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9678,                   Accuracy: 24920/60000 (41.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3355,                   Accuracy: 29715/60000 (49.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6257,                   Accuracy: 35930/60000 (59.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0844,                   Accuracy: 42011/60000 (70.02%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7882,                   Accuracy: 45446/60000 (75.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8321,                   Accuracy: 44728/60000 (74.55%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0828,                   Accuracy: 41056/60000 (68.43%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2626,                   Accuracy: 37647/60000 (62.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2139,                   Accuracy: 37848/60000 (63.08%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9647,                   Accuracy: 42294/60000 (70.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5549,                   Accuracy: 49684/60000 (82.81%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2284,                   Accuracy: 55792/60000 (92.99%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0959,                   Accuracy: 58255/60000 (97.09%)
{0: tensor(97.9033), 10: tensor(97.0867), 20: tensor(93.6917), 30: tensor(85.1333), 40: tensor(73.8383), 50: tensor(63.9000), 60: tensor(60.2567), 70: tensor(61.9317), 80: tensor(63.8933), 90: tensor(60.9733), 100: tensor(58.4900), 110: tensor(49.5717), 120: tensor(41.1033), 130: tensor(36.0200), 140: tensor(36.4400), 150: tensor(38.4767), 160: tensor(42.9733), 170: tensor(44.3883), 180: tensor(44.5350), 190: tensor(45.3167), 200: tensor(41.7783), 210: tensor(38.4067), 220: tensor(37.5850), 230: tensor(41.5333), 240: tensor(49.5250), 250: tensor(59.8833), 260: tensor(70.0183), 270: tensor(75.7433), 280: tensor(74.5467), 290: tensor(68.4267), 300: tensor(62.7450), 310: tensor(63.0800), 320: tensor(70.4900), 330: tensor(82.8067), 340: tensor(92.9867), 350: tensor(97.0917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=24, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 21.5251,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 2.3287,                   Accuracy: 431/2000.0 (21.55%)



-= Testing valid =-
Test set: Average loss: 0.8377,                   Accuracy: 1466/2000.0 (73.30%)



-= Testing valid =-
Test set: Average loss: 0.8523,                   Accuracy: 1400/2000.0 (70.00%)



-= Testing valid =-
Test set: Average loss: 0.3082,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.1741,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.2835,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 10 train accuracy: 97.90%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.1480,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 98.94%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.28%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.56%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.55%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0485,                   Accuracy: 59178/60000 (98.63%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0770,                   Accuracy: 58678/60000 (97.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1692,                   Accuracy: 57106/60000 (95.18%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4388,                   Accuracy: 52573/60000 (87.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8968,                   Accuracy: 44931/60000 (74.89%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1870,                   Accuracy: 39875/60000 (66.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0539,                   Accuracy: 41112/60000 (68.52%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6727,                   Accuracy: 47277/60000 (78.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4665,                   Accuracy: 50568/60000 (84.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4038,                   Accuracy: 51750/60000 (86.25%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6441,                   Accuracy: 47389/60000 (78.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2162,                   Accuracy: 40225/60000 (67.04%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0344,                   Accuracy: 32668/60000 (54.45%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8465,                   Accuracy: 26816/60000 (44.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2889,                   Accuracy: 24054/60000 (40.09%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3834,                   Accuracy: 24806/60000 (41.34%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1948,                   Accuracy: 27719/60000 (46.20%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0218,                   Accuracy: 30949/60000 (51.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9609,                   Accuracy: 33001/60000 (55.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0183,                   Accuracy: 31529/60000 (52.55%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1759,                   Accuracy: 29553/60000 (49.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3510,                   Accuracy: 26565/60000 (44.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.1234,                   Accuracy: 25797/60000 (42.99%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6984,                   Accuracy: 27677/60000 (46.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9254,                   Accuracy: 33465/60000 (55.78%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1090,                   Accuracy: 42296/60000 (70.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5944,                   Accuracy: 49175/60000 (81.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3898,                   Accuracy: 52162/60000 (86.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4717,                   Accuracy: 50272/60000 (83.79%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7226,                   Accuracy: 45830/60000 (76.38%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1085,                   Accuracy: 40586/60000 (67.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3170,                   Accuracy: 37553/60000 (62.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2742,                   Accuracy: 38681/60000 (64.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7507,                   Accuracy: 46665/60000 (77.78%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2495,                   Accuracy: 55270/60000 (92.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0789,                   Accuracy: 58536/60000 (97.56%)
{0: tensor(98.6300), 10: tensor(97.7967), 20: tensor(95.1767), 30: tensor(87.6217), 40: tensor(74.8850), 50: tensor(66.4583), 60: tensor(68.5200), 70: tensor(78.7950), 80: tensor(84.2800), 90: tensor(86.2500), 100: tensor(78.9817), 110: tensor(67.0417), 120: tensor(54.4467), 130: tensor(44.6933), 140: tensor(40.0900), 150: tensor(41.3433), 160: tensor(46.1983), 170: tensor(51.5817), 180: tensor(55.0017), 190: tensor(52.5483), 200: tensor(49.2550), 210: tensor(44.2750), 220: tensor(42.9950), 230: tensor(46.1283), 240: tensor(55.7750), 250: tensor(70.4933), 260: tensor(81.9583), 270: tensor(86.9367), 280: tensor(83.7867), 290: tensor(76.3833), 300: tensor(67.6433), 310: tensor(62.5883), 320: tensor(64.4683), 330: tensor(77.7750), 340: tensor(92.1167), 350: tensor(97.5600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=25, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7809,                   Accuracy: 698/2000.0 (34.90%)



-= Testing valid =-
Test set: Average loss: 1.4682,                   Accuracy: 922/2000.0 (46.10%)



-= Testing valid =-
Test set: Average loss: 1.2004,                   Accuracy: 1111/2000.0 (55.55%)



-= Testing valid =-
Test set: Average loss: 0.2579,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.3232,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2501,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1599,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.4614,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 10 train accuracy: 97.85%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 99.05%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.20%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.61%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0554,                   Accuracy: 59041/60000 (98.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0948,                   Accuracy: 58371/60000 (97.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2461,                   Accuracy: 55926/60000 (93.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6608,                   Accuracy: 49975/60000 (83.29%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2292,                   Accuracy: 41385/60000 (68.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.6482,                   Accuracy: 34310/60000 (57.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.6564,                   Accuracy: 31834/60000 (53.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.3457,                   Accuracy: 33387/60000 (55.65%)
-= Testing Rotation 80 =-
Test set: Average loss: 1.0818,                   Accuracy: 37219/60000 (62.03%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9698,                   Accuracy: 39995/60000 (66.66%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.4189,                   Accuracy: 33476/60000 (55.79%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9502,                   Accuracy: 30049/60000 (50.08%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7839,                   Accuracy: 24334/60000 (40.56%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6799,                   Accuracy: 19649/60000 (32.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.2664,                   Accuracy: 19019/60000 (31.70%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.4015,                   Accuracy: 21349/60000 (35.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.3134,                   Accuracy: 25023/60000 (41.71%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.2277,                   Accuracy: 28178/60000 (46.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.2793,                   Accuracy: 28532/60000 (47.55%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.1772,                   Accuracy: 27789/60000 (46.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.0429,                   Accuracy: 25506/60000 (42.51%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0659,                   Accuracy: 22421/60000 (37.37%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7429,                   Accuracy: 21037/60000 (35.06%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1467,                   Accuracy: 22871/60000 (38.12%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2400,                   Accuracy: 28687/60000 (47.81%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4092,                   Accuracy: 36510/60000 (60.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8907,                   Accuracy: 43067/60000 (71.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6263,                   Accuracy: 47514/60000 (79.19%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8945,                   Accuracy: 42452/60000 (70.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.3610,                   Accuracy: 35661/60000 (59.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.7862,                   Accuracy: 31509/60000 (52.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.8584,                   Accuracy: 31018/60000 (51.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5456,                   Accuracy: 36408/60000 (60.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8694,                   Accuracy: 46154/60000 (76.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2909,                   Accuracy: 54909/60000 (91.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0939,                   Accuracy: 58329/60000 (97.21%)
{0: tensor(98.4017), 10: tensor(97.2850), 20: tensor(93.2100), 30: tensor(83.2917), 40: tensor(68.9750), 50: tensor(57.1833), 60: tensor(53.0567), 70: tensor(55.6450), 80: tensor(62.0317), 90: tensor(66.6583), 100: tensor(55.7933), 110: tensor(50.0817), 120: tensor(40.5567), 130: tensor(32.7483), 140: tensor(31.6983), 150: tensor(35.5817), 160: tensor(41.7050), 170: tensor(46.9633), 180: tensor(47.5533), 190: tensor(46.3150), 200: tensor(42.5100), 210: tensor(37.3683), 220: tensor(35.0617), 230: tensor(38.1183), 240: tensor(47.8117), 250: tensor(60.8500), 260: tensor(71.7783), 270: tensor(79.1900), 280: tensor(70.7533), 290: tensor(59.4350), 300: tensor(52.5150), 310: tensor(51.6967), 320: tensor(60.6800), 330: tensor(76.9233), 340: tensor(91.5150), 350: tensor(97.2150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=26, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1496,                   Accuracy: 329/2000.0 (16.45%)



-= Testing valid =-
Test set: Average loss: 2.9543,                   Accuracy: 290/2000.0 (14.50%)



-= Testing valid =-
Test set: Average loss: 1.0749,                   Accuracy: 1200/2000.0 (60.00%)



-= Testing valid =-
Test set: Average loss: 0.8636,                   Accuracy: 1507/2000.0 (75.35%)



-= Testing valid =-
Test set: Average loss: 0.4510,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3950,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.1987,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1812,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.4259,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 10 train accuracy: 98.14%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 99.19%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 30 train accuracy: 99.49%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 99.55%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 99.68%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0594,                   Accuracy: 58954/60000 (98.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0857,                   Accuracy: 58562/60000 (97.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1790,                   Accuracy: 56870/60000 (94.78%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4423,                   Accuracy: 52138/60000 (86.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8336,                   Accuracy: 45120/60000 (75.20%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0508,                   Accuracy: 41204/60000 (68.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9722,                   Accuracy: 42211/60000 (70.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8044,                   Accuracy: 44521/60000 (74.20%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7338,                   Accuracy: 45928/60000 (76.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8115,                   Accuracy: 46378/60000 (77.30%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1833,                   Accuracy: 42283/60000 (70.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5571,                   Accuracy: 38297/60000 (63.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2204,                   Accuracy: 31066/60000 (51.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8690,                   Accuracy: 26279/60000 (43.80%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2599,                   Accuracy: 24680/60000 (41.13%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3297,                   Accuracy: 25819/60000 (43.03%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3636,                   Accuracy: 28377/60000 (47.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2880,                   Accuracy: 29771/60000 (49.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1864,                   Accuracy: 30590/60000 (50.98%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5484,                   Accuracy: 29691/60000 (49.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6522,                   Accuracy: 28535/60000 (47.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7792,                   Accuracy: 26033/60000 (43.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6200,                   Accuracy: 25084/60000 (41.81%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0511,                   Accuracy: 26946/60000 (44.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2333,                   Accuracy: 32511/60000 (54.19%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3439,                   Accuracy: 40416/60000 (67.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6972,                   Accuracy: 47719/60000 (79.53%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4582,                   Accuracy: 51131/60000 (85.22%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5265,                   Accuracy: 50294/60000 (83.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7159,                   Accuracy: 46705/60000 (77.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9842,                   Accuracy: 43207/60000 (72.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0413,                   Accuracy: 42393/60000 (70.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8763,                   Accuracy: 45394/60000 (75.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5260,                   Accuracy: 50985/60000 (84.97%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2161,                   Accuracy: 56047/60000 (93.41%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0865,                   Accuracy: 58446/60000 (97.41%)
{0: tensor(98.2567), 10: tensor(97.6033), 20: tensor(94.7833), 30: tensor(86.8967), 40: tensor(75.2000), 50: tensor(68.6733), 60: tensor(70.3517), 70: tensor(74.2017), 80: tensor(76.5467), 90: tensor(77.2967), 100: tensor(70.4717), 110: tensor(63.8283), 120: tensor(51.7767), 130: tensor(43.7983), 140: tensor(41.1333), 150: tensor(43.0317), 160: tensor(47.2950), 170: tensor(49.6183), 180: tensor(50.9833), 190: tensor(49.4850), 200: tensor(47.5583), 210: tensor(43.3883), 220: tensor(41.8067), 230: tensor(44.9100), 240: tensor(54.1850), 250: tensor(67.3600), 260: tensor(79.5317), 270: tensor(85.2183), 280: tensor(83.8233), 290: tensor(77.8417), 300: tensor(72.0117), 310: tensor(70.6550), 320: tensor(75.6567), 330: tensor(84.9750), 340: tensor(93.4117), 350: tensor(97.4100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=27, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2465,                   Accuracy: 282/2000.0 (14.10%)



-= Testing valid =-
Test set: Average loss: 1.7958,                   Accuracy: 716/2000.0 (35.80%)



-= Testing valid =-
Test set: Average loss: 1.3402,                   Accuracy: 979/2000.0 (48.95%)



-= Testing valid =-
Test set: Average loss: 1.6463,                   Accuracy: 1016/2000.0 (50.80%)



-= Testing valid =-
Test set: Average loss: 1.1434,                   Accuracy: 1275/2000.0 (63.75%)



-= Testing valid =-
Test set: Average loss: 0.2992,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.9351,                   Accuracy: 1415/2000.0 (70.75%)



-= Testing valid =-
Test set: Average loss: 0.2495,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 1.3704,                   Accuracy: 1172/2000.0 (58.60%)



-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 10 train accuracy: 98.19%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.2759,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.2143,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.3277,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 20 train accuracy: 99.00%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 99.41%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 99.66%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0794,                   Accuracy: 58599/60000 (97.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1249,                   Accuracy: 57760/60000 (96.27%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2685,                   Accuracy: 55244/60000 (92.07%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7448,                   Accuracy: 46927/60000 (78.21%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2568,                   Accuracy: 37996/60000 (63.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.5171,                   Accuracy: 32969/60000 (54.95%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3637,                   Accuracy: 33924/60000 (56.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9429,                   Accuracy: 41417/60000 (69.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6383,                   Accuracy: 47010/60000 (78.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4987,                   Accuracy: 50011/60000 (83.35%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7251,                   Accuracy: 45123/60000 (75.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1621,                   Accuracy: 38705/60000 (64.51%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0464,                   Accuracy: 29216/60000 (48.69%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8607,                   Accuracy: 23191/60000 (38.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3286,                   Accuracy: 21338/60000 (35.56%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4213,                   Accuracy: 23279/60000 (38.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2203,                   Accuracy: 27702/60000 (46.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0341,                   Accuracy: 30865/60000 (51.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9158,                   Accuracy: 32052/60000 (53.42%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0617,                   Accuracy: 31934/60000 (53.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.0532,                   Accuracy: 31246/60000 (52.08%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.1345,                   Accuracy: 27139/60000 (45.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.1184,                   Accuracy: 23734/60000 (39.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7769,                   Accuracy: 22769/60000 (37.95%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1377,                   Accuracy: 25901/60000 (43.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5453,                   Accuracy: 31410/60000 (52.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0540,                   Accuracy: 36389/60000 (60.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7209,                   Accuracy: 42772/60000 (71.29%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7258,                   Accuracy: 42821/60000 (71.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8953,                   Accuracy: 40509/60000 (67.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1709,                   Accuracy: 36612/60000 (61.02%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2779,                   Accuracy: 35240/60000 (58.73%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0898,                   Accuracy: 39027/60000 (65.04%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6436,                   Accuracy: 47218/60000 (78.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2846,                   Accuracy: 54490/60000 (90.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1219,                   Accuracy: 57790/60000 (96.32%)
{0: tensor(97.6650), 10: tensor(96.2667), 20: tensor(92.0733), 30: tensor(78.2117), 40: tensor(63.3267), 50: tensor(54.9483), 60: tensor(56.5400), 70: tensor(69.0283), 80: tensor(78.3500), 90: tensor(83.3517), 100: tensor(75.2050), 110: tensor(64.5083), 120: tensor(48.6933), 130: tensor(38.6517), 140: tensor(35.5633), 150: tensor(38.7983), 160: tensor(46.1700), 170: tensor(51.4417), 180: tensor(53.4200), 190: tensor(53.2233), 200: tensor(52.0767), 210: tensor(45.2317), 220: tensor(39.5567), 230: tensor(37.9483), 240: tensor(43.1683), 250: tensor(52.3500), 260: tensor(60.6483), 270: tensor(71.2867), 280: tensor(71.3683), 290: tensor(67.5150), 300: tensor(61.0200), 310: tensor(58.7333), 320: tensor(65.0450), 330: tensor(78.6967), 340: tensor(90.8167), 350: tensor(96.3167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=28, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8587,                   Accuracy: 271/2000.0 (13.55%)



-= Testing valid =-
Test set: Average loss: 1.4971,                   Accuracy: 878/2000.0 (43.90%)



-= Testing valid =-
Test set: Average loss: 0.7121,                   Accuracy: 1533/2000.0 (76.65%)



-= Testing valid =-
Test set: Average loss: 0.3255,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.7142,                   Accuracy: 1527/2000.0 (76.35%)



-= Testing valid =-
Test set: Average loss: 0.1327,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 10 train accuracy: 97.95%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.54%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0533,                   Accuracy: 59085/60000 (98.47%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0782,                   Accuracy: 58667/60000 (97.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1500,                   Accuracy: 57437/60000 (95.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3477,                   Accuracy: 54082/60000 (90.14%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6504,                   Accuracy: 48783/60000 (81.31%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8072,                   Accuracy: 45860/60000 (76.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7107,                   Accuracy: 47345/60000 (78.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5215,                   Accuracy: 50305/60000 (83.84%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3807,                   Accuracy: 52838/60000 (88.06%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3236,                   Accuracy: 53834/60000 (89.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4881,                   Accuracy: 50519/60000 (84.20%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.8096,                   Accuracy: 44654/60000 (74.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.3308,                   Accuracy: 37136/60000 (61.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.9867,                   Accuracy: 29175/60000 (48.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.3954,                   Accuracy: 25949/60000 (43.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.4808,                   Accuracy: 27854/60000 (46.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.4772,                   Accuracy: 31199/60000 (52.00%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.4971,                   Accuracy: 33492/60000 (55.82%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.7294,                   Accuracy: 33218/60000 (55.36%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.9127,                   Accuracy: 31862/60000 (53.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.0957,                   Accuracy: 29755/60000 (49.59%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.2517,                   Accuracy: 26308/60000 (43.85%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.0997,                   Accuracy: 25150/60000 (41.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.4705,                   Accuracy: 28511/60000 (47.52%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6199,                   Accuracy: 36130/60000 (60.22%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.9217,                   Accuracy: 44219/60000 (73.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5025,                   Accuracy: 50498/60000 (84.16%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3353,                   Accuracy: 53742/60000 (89.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4023,                   Accuracy: 52262/60000 (87.10%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5396,                   Accuracy: 49238/60000 (82.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6902,                   Accuracy: 46104/60000 (76.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8124,                   Accuracy: 44204/60000 (73.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7287,                   Accuracy: 45622/60000 (76.04%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4498,                   Accuracy: 51261/60000 (85.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2072,                   Accuracy: 56097/60000 (93.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0802,                   Accuracy: 58552/60000 (97.59%)
{0: tensor(98.4750), 10: tensor(97.7783), 20: tensor(95.7283), 30: tensor(90.1367), 40: tensor(81.3050), 50: tensor(76.4333), 60: tensor(78.9083), 70: tensor(83.8417), 80: tensor(88.0633), 90: tensor(89.7233), 100: tensor(84.1983), 110: tensor(74.4233), 120: tensor(61.8933), 130: tensor(48.6250), 140: tensor(43.2483), 150: tensor(46.4233), 160: tensor(51.9983), 170: tensor(55.8200), 180: tensor(55.3633), 190: tensor(53.1033), 200: tensor(49.5917), 210: tensor(43.8467), 220: tensor(41.9167), 230: tensor(47.5183), 240: tensor(60.2167), 250: tensor(73.6983), 260: tensor(84.1633), 270: tensor(89.5700), 280: tensor(87.1033), 290: tensor(82.0633), 300: tensor(76.8400), 310: tensor(73.6733), 320: tensor(76.0367), 330: tensor(85.4350), 340: tensor(93.4950), 350: tensor(97.5867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=29, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9381,                   Accuracy: 315/2000.0 (15.75%)



-= Testing valid =-
Test set: Average loss: 1.6742,                   Accuracy: 836/2000.0 (41.80%)



-= Testing valid =-
Test set: Average loss: 0.9493,                   Accuracy: 1331/2000.0 (66.55%)



-= Testing valid =-
Test set: Average loss: 0.3922,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 1.7306,                   Accuracy: 1215/2000.0 (60.75%)



-= Testing valid =-
Test set: Average loss: 1.3728,                   Accuracy: 1465/2000.0 (73.25%)



-= Testing valid =-
Test set: Average loss: 0.2942,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 1.2961,                   Accuracy: 1533/2000.0 (76.65%)



Epoch 10 train accuracy: 98.14%, valid accuracy 76.65%
-= Testing valid =-
Test set: Average loss: 0.4410,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.6514,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.4872,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.4193,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.2500,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 98.96%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.31%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.1816,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.53%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 99.49%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0674,                   Accuracy: 58820/60000 (98.03%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1016,                   Accuracy: 58283/60000 (97.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2039,                   Accuracy: 56590/60000 (94.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4546,                   Accuracy: 52325/60000 (87.21%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8634,                   Accuracy: 45232/60000 (75.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1378,                   Accuracy: 40277/60000 (67.13%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0833,                   Accuracy: 40162/60000 (66.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8586,                   Accuracy: 42937/60000 (71.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6740,                   Accuracy: 46041/60000 (76.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5805,                   Accuracy: 47999/60000 (80.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8318,                   Accuracy: 43135/60000 (71.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2166,                   Accuracy: 36850/60000 (61.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.7736,                   Accuracy: 29687/60000 (49.48%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.4064,                   Accuracy: 24715/60000 (41.19%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.7667,                   Accuracy: 23677/60000 (39.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.8101,                   Accuracy: 25524/60000 (42.54%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.8001,                   Accuracy: 28732/60000 (47.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.8259,                   Accuracy: 31027/60000 (51.71%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.8118,                   Accuracy: 31847/60000 (53.08%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.9326,                   Accuracy: 30783/60000 (51.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.0605,                   Accuracy: 28617/60000 (47.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.1268,                   Accuracy: 26033/60000 (43.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.1322,                   Accuracy: 24885/60000 (41.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8149,                   Accuracy: 26746/60000 (44.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0715,                   Accuracy: 32382/60000 (53.97%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2538,                   Accuracy: 40474/60000 (67.46%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7167,                   Accuracy: 47274/60000 (78.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4283,                   Accuracy: 52014/60000 (86.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4694,                   Accuracy: 51108/60000 (85.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6464,                   Accuracy: 47992/60000 (79.99%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9277,                   Accuracy: 43107/60000 (71.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1584,                   Accuracy: 39109/60000 (65.18%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0575,                   Accuracy: 40656/60000 (67.76%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6102,                   Accuracy: 48358/60000 (80.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2367,                   Accuracy: 55477/60000 (92.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1091,                   Accuracy: 58029/60000 (96.71%)
{0: tensor(98.0333), 10: tensor(97.1383), 20: tensor(94.3167), 30: tensor(87.2083), 40: tensor(75.3867), 50: tensor(67.1283), 60: tensor(66.9367), 70: tensor(71.5617), 80: tensor(76.7350), 90: tensor(79.9983), 100: tensor(71.8917), 110: tensor(61.4167), 120: tensor(49.4783), 130: tensor(41.1917), 140: tensor(39.4617), 150: tensor(42.5400), 160: tensor(47.8867), 170: tensor(51.7117), 180: tensor(53.0783), 190: tensor(51.3050), 200: tensor(47.6950), 210: tensor(43.3883), 220: tensor(41.4750), 230: tensor(44.5767), 240: tensor(53.9700), 250: tensor(67.4567), 260: tensor(78.7900), 270: tensor(86.6900), 280: tensor(85.1800), 290: tensor(79.9867), 300: tensor(71.8450), 310: tensor(65.1817), 320: tensor(67.7600), 330: tensor(80.5967), 340: tensor(92.4617), 350: tensor(96.7150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=30, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3246,                   Accuracy: 347/2000.0 (17.35%)



-= Testing valid =-
Test set: Average loss: 2.3282,                   Accuracy: 373/2000.0 (18.65%)



-= Testing valid =-
Test set: Average loss: 1.0642,                   Accuracy: 1309/2000.0 (65.45%)



-= Testing valid =-
Test set: Average loss: 0.9845,                   Accuracy: 1388/2000.0 (69.40%)



-= Testing valid =-
Test set: Average loss: 0.1452,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 10 train accuracy: 98.12%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 20 train accuracy: 99.14%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.54%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.61%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0550,                   Accuracy: 59075/60000 (98.46%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0804,                   Accuracy: 58604/60000 (97.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1838,                   Accuracy: 56757/60000 (94.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4602,                   Accuracy: 51627/60000 (86.04%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9025,                   Accuracy: 43008/60000 (71.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2264,                   Accuracy: 36178/60000 (60.30%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2087,                   Accuracy: 35312/60000 (58.85%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9480,                   Accuracy: 39858/60000 (66.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8073,                   Accuracy: 42075/60000 (70.12%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8084,                   Accuracy: 41296/60000 (68.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1753,                   Accuracy: 36404/60000 (60.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5223,                   Accuracy: 33956/60000 (56.59%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1055,                   Accuracy: 28697/60000 (47.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8706,                   Accuracy: 25253/60000 (42.09%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3827,                   Accuracy: 23885/60000 (39.81%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6111,                   Accuracy: 24399/60000 (40.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7440,                   Accuracy: 26067/60000 (43.44%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7308,                   Accuracy: 27732/60000 (46.22%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6504,                   Accuracy: 28651/60000 (47.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6991,                   Accuracy: 28869/60000 (48.12%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5185,                   Accuracy: 27672/60000 (46.12%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3702,                   Accuracy: 25051/60000 (41.75%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.0660,                   Accuracy: 23703/60000 (39.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5654,                   Accuracy: 25432/60000 (42.39%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8895,                   Accuracy: 30588/60000 (50.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2116,                   Accuracy: 38602/60000 (64.34%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8268,                   Accuracy: 43175/60000 (71.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6139,                   Accuracy: 46467/60000 (77.44%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6861,                   Accuracy: 46000/60000 (76.67%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8725,                   Accuracy: 43514/60000 (72.52%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0907,                   Accuracy: 40514/60000 (67.52%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2504,                   Accuracy: 38279/60000 (63.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0826,                   Accuracy: 41034/60000 (68.39%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5791,                   Accuracy: 49541/60000 (82.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2088,                   Accuracy: 56168/60000 (93.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0779,                   Accuracy: 58614/60000 (97.69%)
{0: tensor(98.4583), 10: tensor(97.6733), 20: tensor(94.5950), 30: tensor(86.0450), 40: tensor(71.6800), 50: tensor(60.2967), 60: tensor(58.8533), 70: tensor(66.4300), 80: tensor(70.1250), 90: tensor(68.8267), 100: tensor(60.6733), 110: tensor(56.5933), 120: tensor(47.8283), 130: tensor(42.0883), 140: tensor(39.8083), 150: tensor(40.6650), 160: tensor(43.4450), 170: tensor(46.2200), 180: tensor(47.7517), 190: tensor(48.1150), 200: tensor(46.1200), 210: tensor(41.7517), 220: tensor(39.5050), 230: tensor(42.3867), 240: tensor(50.9800), 250: tensor(64.3367), 260: tensor(71.9583), 270: tensor(77.4450), 280: tensor(76.6667), 290: tensor(72.5233), 300: tensor(67.5233), 310: tensor(63.7983), 320: tensor(68.3900), 330: tensor(82.5683), 340: tensor(93.6133), 350: tensor(97.6900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=31, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.1111,                   Accuracy: 242/2000.0 (12.10%)



-= Testing valid =-
Test set: Average loss: 7.3176,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 1.0770,                   Accuracy: 1137/2000.0 (56.85%)



-= Testing valid =-
Test set: Average loss: 1.2025,                   Accuracy: 1317/2000.0 (65.85%)



-= Testing valid =-
Test set: Average loss: 0.2896,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.4012,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.2793,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2743,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 10 train accuracy: 98.06%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.03%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.51%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.71%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0516,                   Accuracy: 59107/60000 (98.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0787,                   Accuracy: 58633/60000 (97.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1706,                   Accuracy: 57130/60000 (95.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3957,                   Accuracy: 53378/60000 (88.96%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7271,                   Accuracy: 47628/60000 (79.38%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0144,                   Accuracy: 42410/60000 (70.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0902,                   Accuracy: 40099/60000 (66.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9079,                   Accuracy: 42504/60000 (70.84%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8338,                   Accuracy: 43131/60000 (71.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9804,                   Accuracy: 40535/60000 (67.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3645,                   Accuracy: 36402/60000 (60.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8906,                   Accuracy: 31967/60000 (53.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7955,                   Accuracy: 26403/60000 (44.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6384,                   Accuracy: 24214/60000 (40.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.1802,                   Accuracy: 23854/60000 (39.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.4578,                   Accuracy: 24878/60000 (41.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.3844,                   Accuracy: 27125/60000 (45.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.3580,                   Accuracy: 28217/60000 (47.03%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.5145,                   Accuracy: 28450/60000 (47.42%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.3059,                   Accuracy: 28809/60000 (48.01%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.3857,                   Accuracy: 27797/60000 (46.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.4664,                   Accuracy: 25437/60000 (42.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.2158,                   Accuracy: 24072/60000 (40.12%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.7024,                   Accuracy: 24923/60000 (41.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9166,                   Accuracy: 28384/60000 (47.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.9393,                   Accuracy: 33961/60000 (56.60%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.1855,                   Accuracy: 40247/60000 (67.08%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7297,                   Accuracy: 46065/60000 (76.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6926,                   Accuracy: 46508/60000 (77.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7520,                   Accuracy: 45420/60000 (75.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8849,                   Accuracy: 43079/60000 (71.80%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9488,                   Accuracy: 42475/60000 (70.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8208,                   Accuracy: 45083/60000 (75.14%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4674,                   Accuracy: 51344/60000 (85.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1837,                   Accuracy: 56748/60000 (94.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0808,                   Accuracy: 58598/60000 (97.66%)
{0: tensor(98.5117), 10: tensor(97.7217), 20: tensor(95.2167), 30: tensor(88.9633), 40: tensor(79.3800), 50: tensor(70.6833), 60: tensor(66.8317), 70: tensor(70.8400), 80: tensor(71.8850), 90: tensor(67.5583), 100: tensor(60.6700), 110: tensor(53.2783), 120: tensor(44.0050), 130: tensor(40.3567), 140: tensor(39.7567), 150: tensor(41.4633), 160: tensor(45.2083), 170: tensor(47.0283), 180: tensor(47.4167), 190: tensor(48.0150), 200: tensor(46.3283), 210: tensor(42.3950), 220: tensor(40.1200), 230: tensor(41.5383), 240: tensor(47.3067), 250: tensor(56.6017), 260: tensor(67.0783), 270: tensor(76.7750), 280: tensor(77.5133), 290: tensor(75.7000), 300: tensor(71.7983), 310: tensor(70.7917), 320: tensor(75.1383), 330: tensor(85.5733), 340: tensor(94.5800), 350: tensor(97.6633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=32, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8532,                   Accuracy: 493/2000.0 (24.65%)



-= Testing valid =-
Test set: Average loss: 0.8805,                   Accuracy: 1317/2000.0 (65.85%)



-= Testing valid =-
Test set: Average loss: 0.3729,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.1683,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 10 train accuracy: 97.94%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.59%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.68%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0492,                   Accuracy: 59162/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0781,                   Accuracy: 58672/60000 (97.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1696,                   Accuracy: 57124/60000 (95.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4018,                   Accuracy: 53157/60000 (88.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7932,                   Accuracy: 46573/60000 (77.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0971,                   Accuracy: 41234/60000 (68.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0660,                   Accuracy: 40962/60000 (68.27%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8404,                   Accuracy: 43689/60000 (72.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6824,                   Accuracy: 46024/60000 (76.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6852,                   Accuracy: 45961/60000 (76.60%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0215,                   Accuracy: 40908/60000 (68.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6463,                   Accuracy: 33547/60000 (55.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6024,                   Accuracy: 26667/60000 (44.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3791,                   Accuracy: 23297/60000 (38.83%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7460,                   Accuracy: 23436/60000 (39.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7219,                   Accuracy: 25724/60000 (42.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5501,                   Accuracy: 28936/60000 (48.23%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5007,                   Accuracy: 31192/60000 (51.99%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7708,                   Accuracy: 31997/60000 (53.33%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7565,                   Accuracy: 30936/60000 (51.56%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.0480,                   Accuracy: 28211/60000 (47.02%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.4058,                   Accuracy: 24475/60000 (40.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.2787,                   Accuracy: 23327/60000 (38.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.7237,                   Accuracy: 24692/60000 (41.15%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7116,                   Accuracy: 29571/60000 (49.28%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6525,                   Accuracy: 37276/60000 (62.13%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9017,                   Accuracy: 44335/60000 (73.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5128,                   Accuracy: 50113/60000 (83.52%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6111,                   Accuracy: 47916/60000 (79.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8738,                   Accuracy: 43364/60000 (72.27%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2325,                   Accuracy: 38454/60000 (64.09%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4530,                   Accuracy: 35776/60000 (59.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3766,                   Accuracy: 38372/60000 (63.95%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8356,                   Accuracy: 47001/60000 (78.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3067,                   Accuracy: 54826/60000 (91.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0957,                   Accuracy: 58310/60000 (97.18%)
{0: tensor(98.6033), 10: tensor(97.7867), 20: tensor(95.2067), 30: tensor(88.5950), 40: tensor(77.6217), 50: tensor(68.7233), 60: tensor(68.2700), 70: tensor(72.8150), 80: tensor(76.7067), 90: tensor(76.6017), 100: tensor(68.1800), 110: tensor(55.9117), 120: tensor(44.4450), 130: tensor(38.8283), 140: tensor(39.0600), 150: tensor(42.8733), 160: tensor(48.2267), 170: tensor(51.9867), 180: tensor(53.3283), 190: tensor(51.5600), 200: tensor(47.0183), 210: tensor(40.7917), 220: tensor(38.8783), 230: tensor(41.1533), 240: tensor(49.2850), 250: tensor(62.1267), 260: tensor(73.8917), 270: tensor(83.5217), 280: tensor(79.8600), 290: tensor(72.2733), 300: tensor(64.0900), 310: tensor(59.6267), 320: tensor(63.9533), 330: tensor(78.3350), 340: tensor(91.3767), 350: tensor(97.1833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=33, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.2020,                   Accuracy: 245/2000.0 (12.25%)



-= Testing valid =-
Test set: Average loss: 1.2077,                   Accuracy: 1055/2000.0 (52.75%)



-= Testing valid =-
Test set: Average loss: 0.6533,                   Accuracy: 1591/2000.0 (79.55%)



-= Testing valid =-
Test set: Average loss: 0.3283,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3738,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.2897,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2913,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 10 train accuracy: 97.70%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 99.04%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.38%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0168,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1990/2000.0 (99.50%)



Epoch 40 train accuracy: 99.56%, valid accuracy 99.50%
-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0168,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0155,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0191,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0178,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0169,                   Accuracy: 1991/2000.0 (99.55%)



Epoch 50 train accuracy: 99.59%, valid accuracy 99.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0520,                   Accuracy: 59089/60000 (98.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0744,                   Accuracy: 58714/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1594,                   Accuracy: 57227/60000 (95.38%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4065,                   Accuracy: 53005/60000 (88.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7375,                   Accuracy: 47421/60000 (79.04%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9895,                   Accuracy: 43095/60000 (71.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0286,                   Accuracy: 41956/60000 (69.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8318,                   Accuracy: 44346/60000 (73.91%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7852,                   Accuracy: 45014/60000 (75.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9008,                   Accuracy: 43650/60000 (72.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0556,                   Accuracy: 40820/60000 (68.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6518,                   Accuracy: 34106/60000 (56.84%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5757,                   Accuracy: 27424/60000 (45.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1662,                   Accuracy: 24321/60000 (40.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5038,                   Accuracy: 23603/60000 (39.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6418,                   Accuracy: 25226/60000 (42.04%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5134,                   Accuracy: 28358/60000 (47.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4839,                   Accuracy: 29956/60000 (49.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7540,                   Accuracy: 30494/60000 (50.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8747,                   Accuracy: 29111/60000 (48.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8426,                   Accuracy: 27171/60000 (45.28%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0533,                   Accuracy: 24538/60000 (40.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7517,                   Accuracy: 23136/60000 (38.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1163,                   Accuracy: 24603/60000 (41.01%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2086,                   Accuracy: 29621/60000 (49.37%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3129,                   Accuracy: 37859/60000 (63.10%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7120,                   Accuracy: 46146/60000 (76.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5149,                   Accuracy: 49887/60000 (83.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5991,                   Accuracy: 48167/60000 (80.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7965,                   Accuracy: 45046/60000 (75.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1676,                   Accuracy: 39904/60000 (66.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2117,                   Accuracy: 39225/60000 (65.38%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1058,                   Accuracy: 41529/60000 (69.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6565,                   Accuracy: 48671/60000 (81.12%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2223,                   Accuracy: 55856/60000 (93.09%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0778,                   Accuracy: 58551/60000 (97.58%)
{0: tensor(98.4817), 10: tensor(97.8567), 20: tensor(95.3783), 30: tensor(88.3417), 40: tensor(79.0350), 50: tensor(71.8250), 60: tensor(69.9267), 70: tensor(73.9100), 80: tensor(75.0233), 90: tensor(72.7500), 100: tensor(68.0333), 110: tensor(56.8433), 120: tensor(45.7067), 130: tensor(40.5350), 140: tensor(39.3383), 150: tensor(42.0433), 160: tensor(47.2633), 170: tensor(49.9267), 180: tensor(50.8233), 190: tensor(48.5183), 200: tensor(45.2850), 210: tensor(40.8967), 220: tensor(38.5600), 230: tensor(41.0050), 240: tensor(49.3683), 250: tensor(63.0983), 260: tensor(76.9100), 270: tensor(83.1450), 280: tensor(80.2783), 290: tensor(75.0767), 300: tensor(66.5067), 310: tensor(65.3750), 320: tensor(69.2150), 330: tensor(81.1183), 340: tensor(93.0933), 350: tensor(97.5850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=34, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9564,                   Accuracy: 605/2000.0 (30.25%)



-= Testing valid =-
Test set: Average loss: 1.3810,                   Accuracy: 1037/2000.0 (51.85%)



-= Testing valid =-
Test set: Average loss: 1.1507,                   Accuracy: 1227/2000.0 (61.35%)



-= Testing valid =-
Test set: Average loss: 1.5429,                   Accuracy: 1110/2000.0 (55.50%)



-= Testing valid =-
Test set: Average loss: 1.0196,                   Accuracy: 1425/2000.0 (71.25%)



-= Testing valid =-
Test set: Average loss: 0.1903,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 10 train accuracy: 98.26%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 99.11%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.55%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0436,                   Accuracy: 59234/60000 (98.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0688,                   Accuracy: 58806/60000 (98.01%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1642,                   Accuracy: 57278/60000 (95.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3988,                   Accuracy: 53163/60000 (88.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8132,                   Accuracy: 46110/60000 (76.85%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1791,                   Accuracy: 39720/60000 (66.20%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2052,                   Accuracy: 39183/60000 (65.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9829,                   Accuracy: 42720/60000 (71.20%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6815,                   Accuracy: 46891/60000 (78.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5914,                   Accuracy: 48209/60000 (80.35%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9442,                   Accuracy: 42259/60000 (70.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5403,                   Accuracy: 34496/60000 (57.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5590,                   Accuracy: 26131/60000 (43.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4832,                   Accuracy: 21949/60000 (36.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9680,                   Accuracy: 21294/60000 (35.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.1463,                   Accuracy: 23267/60000 (38.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1021,                   Accuracy: 27637/60000 (46.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.2118,                   Accuracy: 30128/60000 (50.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.1672,                   Accuracy: 31129/60000 (51.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.1898,                   Accuracy: 31463/60000 (52.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1125,                   Accuracy: 29908/60000 (49.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0679,                   Accuracy: 26873/60000 (44.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7555,                   Accuracy: 25351/60000 (42.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2355,                   Accuracy: 26023/60000 (43.37%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.4378,                   Accuracy: 30034/60000 (50.06%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7027,                   Accuracy: 36143/60000 (60.24%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.1136,                   Accuracy: 41119/60000 (68.53%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6723,                   Accuracy: 46008/60000 (76.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7815,                   Accuracy: 44328/60000 (73.88%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0669,                   Accuracy: 39623/60000 (66.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4438,                   Accuracy: 35478/60000 (59.13%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5125,                   Accuracy: 34866/60000 (58.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3401,                   Accuracy: 38354/60000 (63.92%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7747,                   Accuracy: 46547/60000 (77.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2696,                   Accuracy: 55019/60000 (91.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0832,                   Accuracy: 58493/60000 (97.49%)
{0: tensor(98.7233), 10: tensor(98.0100), 20: tensor(95.4633), 30: tensor(88.6050), 40: tensor(76.8500), 50: tensor(66.2000), 60: tensor(65.3050), 70: tensor(71.2000), 80: tensor(78.1517), 90: tensor(80.3483), 100: tensor(70.4317), 110: tensor(57.4933), 120: tensor(43.5517), 130: tensor(36.5817), 140: tensor(35.4900), 150: tensor(38.7783), 160: tensor(46.0617), 170: tensor(50.2133), 180: tensor(51.8817), 190: tensor(52.4383), 200: tensor(49.8467), 210: tensor(44.7883), 220: tensor(42.2517), 230: tensor(43.3717), 240: tensor(50.0567), 250: tensor(60.2383), 260: tensor(68.5317), 270: tensor(76.6800), 280: tensor(73.8800), 290: tensor(66.0383), 300: tensor(59.1300), 310: tensor(58.1100), 320: tensor(63.9233), 330: tensor(77.5783), 340: tensor(91.6983), 350: tensor(97.4883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=35, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4585,                   Accuracy: 445/2000.0 (22.25%)



-= Testing valid =-
Test set: Average loss: 1.0444,                   Accuracy: 1304/2000.0 (65.20%)



-= Testing valid =-
Test set: Average loss: 1.0575,                   Accuracy: 1312/2000.0 (65.60%)



-= Testing valid =-
Test set: Average loss: 0.2799,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2562,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1333,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 10 train accuracy: 98.01%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 98.84%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.51%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.66%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.60%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0534,                   Accuracy: 59068/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0774,                   Accuracy: 58674/60000 (97.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1833,                   Accuracy: 56851/60000 (94.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4732,                   Accuracy: 51981/60000 (86.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8968,                   Accuracy: 44723/60000 (74.54%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1585,                   Accuracy: 40113/60000 (66.86%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0703,                   Accuracy: 40993/60000 (68.32%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7248,                   Accuracy: 47257/60000 (78.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4923,                   Accuracy: 51111/60000 (85.18%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4371,                   Accuracy: 51946/60000 (86.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6775,                   Accuracy: 47362/60000 (78.94%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1936,                   Accuracy: 39736/60000 (66.23%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0450,                   Accuracy: 30301/60000 (50.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8886,                   Accuracy: 23246/60000 (38.74%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3265,                   Accuracy: 21553/60000 (35.92%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4496,                   Accuracy: 23090/60000 (38.48%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2087,                   Accuracy: 27198/60000 (45.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0691,                   Accuracy: 30410/60000 (50.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0963,                   Accuracy: 31489/60000 (52.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0516,                   Accuracy: 31375/60000 (52.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1262,                   Accuracy: 29661/60000 (49.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4668,                   Accuracy: 25737/60000 (42.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5165,                   Accuracy: 23334/60000 (38.89%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1417,                   Accuracy: 23721/60000 (39.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3589,                   Accuracy: 27530/60000 (45.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4588,                   Accuracy: 35393/60000 (58.99%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8805,                   Accuracy: 42068/60000 (70.11%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5953,                   Accuracy: 46610/60000 (77.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7243,                   Accuracy: 45388/60000 (75.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0065,                   Accuracy: 41109/60000 (68.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3334,                   Accuracy: 36280/60000 (60.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4300,                   Accuracy: 35640/60000 (59.40%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2150,                   Accuracy: 39071/60000 (65.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7250,                   Accuracy: 47158/60000 (78.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2987,                   Accuracy: 54687/60000 (91.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0994,                   Accuracy: 58167/60000 (96.94%)
{0: tensor(98.4467), 10: tensor(97.7900), 20: tensor(94.7517), 30: tensor(86.6350), 40: tensor(74.5383), 50: tensor(66.8550), 60: tensor(68.3217), 70: tensor(78.7617), 80: tensor(85.1850), 90: tensor(86.5767), 100: tensor(78.9367), 110: tensor(66.2267), 120: tensor(50.5017), 130: tensor(38.7433), 140: tensor(35.9217), 150: tensor(38.4833), 160: tensor(45.3300), 170: tensor(50.6833), 180: tensor(52.4817), 190: tensor(52.2917), 200: tensor(49.4350), 210: tensor(42.8950), 220: tensor(38.8900), 230: tensor(39.5350), 240: tensor(45.8833), 250: tensor(58.9883), 260: tensor(70.1133), 270: tensor(77.6833), 280: tensor(75.6467), 290: tensor(68.5150), 300: tensor(60.4667), 310: tensor(59.4000), 320: tensor(65.1183), 330: tensor(78.5967), 340: tensor(91.1450), 350: tensor(96.9450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=36, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2758,                   Accuracy: 199/2000.0 (9.95%)



-= Testing valid =-
Test set: Average loss: 1.0434,                   Accuracy: 1283/2000.0 (64.15%)



-= Testing valid =-
Test set: Average loss: 0.7062,                   Accuracy: 1521/2000.0 (76.05%)



-= Testing valid =-
Test set: Average loss: 0.3286,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2400,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1698,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1799,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1376,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 10 train accuracy: 98.24%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 99.16%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.53%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.76%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.79%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0425,                   Accuracy: 59214/60000 (98.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0622,                   Accuracy: 58845/60000 (98.07%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1558,                   Accuracy: 57256/60000 (95.43%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4605,                   Accuracy: 52018/60000 (86.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9408,                   Accuracy: 44351/60000 (73.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2882,                   Accuracy: 38035/60000 (63.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3238,                   Accuracy: 37081/60000 (61.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0972,                   Accuracy: 39301/60000 (65.50%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8257,                   Accuracy: 44269/60000 (73.78%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8217,                   Accuracy: 44161/60000 (73.60%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1937,                   Accuracy: 39945/60000 (66.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.0869,                   Accuracy: 32790/60000 (54.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.0782,                   Accuracy: 26975/60000 (44.96%)
-= Testing Rotation 130 =-
Test set: Average loss: 4.0704,                   Accuracy: 23015/60000 (38.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.5266,                   Accuracy: 22161/60000 (36.94%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.6403,                   Accuracy: 22958/60000 (38.26%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.5812,                   Accuracy: 25152/60000 (41.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.5764,                   Accuracy: 26698/60000 (44.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.7069,                   Accuracy: 27668/60000 (46.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.6355,                   Accuracy: 27396/60000 (45.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.7256,                   Accuracy: 24993/60000 (41.65%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.6664,                   Accuracy: 22615/60000 (37.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.2295,                   Accuracy: 21321/60000 (35.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4105,                   Accuracy: 22747/60000 (37.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.4417,                   Accuracy: 28800/60000 (48.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6055,                   Accuracy: 35964/60000 (59.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0163,                   Accuracy: 43115/60000 (71.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7233,                   Accuracy: 46732/60000 (77.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8351,                   Accuracy: 44605/60000 (74.34%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2209,                   Accuracy: 38915/60000 (64.86%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5994,                   Accuracy: 33865/60000 (56.44%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7636,                   Accuracy: 32682/60000 (54.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5264,                   Accuracy: 37291/60000 (62.15%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9639,                   Accuracy: 45671/60000 (76.12%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3935,                   Accuracy: 53671/60000 (89.45%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0989,                   Accuracy: 58188/60000 (96.98%)
{0: tensor(98.6900), 10: tensor(98.0750), 20: tensor(95.4267), 30: tensor(86.6967), 40: tensor(73.9183), 50: tensor(63.3917), 60: tensor(61.8017), 70: tensor(65.5017), 80: tensor(73.7817), 90: tensor(73.6017), 100: tensor(66.5750), 110: tensor(54.6500), 120: tensor(44.9583), 130: tensor(38.3583), 140: tensor(36.9350), 150: tensor(38.2633), 160: tensor(41.9200), 170: tensor(44.4967), 180: tensor(46.1133), 190: tensor(45.6600), 200: tensor(41.6550), 210: tensor(37.6917), 220: tensor(35.5350), 230: tensor(37.9117), 240: tensor(48.), 250: tensor(59.9400), 260: tensor(71.8583), 270: tensor(77.8867), 280: tensor(74.3417), 290: tensor(64.8583), 300: tensor(56.4417), 310: tensor(54.4700), 320: tensor(62.1517), 330: tensor(76.1183), 340: tensor(89.4517), 350: tensor(96.9800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=37, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7352,                   Accuracy: 677/2000.0 (33.85%)



-= Testing valid =-
Test set: Average loss: 1.2346,                   Accuracy: 1107/2000.0 (55.35%)



-= Testing valid =-
Test set: Average loss: 0.7668,                   Accuracy: 1469/2000.0 (73.45%)



-= Testing valid =-
Test set: Average loss: 0.5453,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 0.1492,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 10 train accuracy: 98.14%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 99.03%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.74%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0498,                   Accuracy: 59113/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0777,                   Accuracy: 58595/60000 (97.66%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1750,                   Accuracy: 56977/60000 (94.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4613,                   Accuracy: 51993/60000 (86.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8528,                   Accuracy: 45227/60000 (75.38%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0838,                   Accuracy: 40880/60000 (68.13%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0386,                   Accuracy: 40678/60000 (67.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8172,                   Accuracy: 44360/60000 (73.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6506,                   Accuracy: 47446/60000 (79.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6625,                   Accuracy: 47777/60000 (79.63%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0635,                   Accuracy: 42439/60000 (70.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6479,                   Accuracy: 35806/60000 (59.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4658,                   Accuracy: 28213/60000 (47.02%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2876,                   Accuracy: 24393/60000 (40.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5873,                   Accuracy: 23469/60000 (39.12%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6213,                   Accuracy: 24453/60000 (40.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5443,                   Accuracy: 26939/60000 (44.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4061,                   Accuracy: 28657/60000 (47.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4129,                   Accuracy: 29529/60000 (49.22%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6535,                   Accuracy: 28714/60000 (47.86%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7344,                   Accuracy: 26986/60000 (44.98%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8391,                   Accuracy: 24841/60000 (41.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7468,                   Accuracy: 24304/60000 (40.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2388,                   Accuracy: 26175/60000 (43.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.4301,                   Accuracy: 30592/60000 (50.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5779,                   Accuracy: 37713/60000 (62.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9844,                   Accuracy: 43397/60000 (72.33%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6173,                   Accuracy: 48330/60000 (80.55%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6160,                   Accuracy: 47637/60000 (79.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8148,                   Accuracy: 44640/60000 (74.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1018,                   Accuracy: 41105/60000 (68.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2574,                   Accuracy: 39383/60000 (65.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1139,                   Accuracy: 42398/60000 (70.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6978,                   Accuracy: 48799/60000 (81.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2417,                   Accuracy: 55728/60000 (92.88%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0750,                   Accuracy: 58605/60000 (97.68%)
{0: tensor(98.5217), 10: tensor(97.6583), 20: tensor(94.9617), 30: tensor(86.6550), 40: tensor(75.3783), 50: tensor(68.1333), 60: tensor(67.7967), 70: tensor(73.9333), 80: tensor(79.0767), 90: tensor(79.6283), 100: tensor(70.7317), 110: tensor(59.6767), 120: tensor(47.0217), 130: tensor(40.6550), 140: tensor(39.1150), 150: tensor(40.7550), 160: tensor(44.8983), 170: tensor(47.7617), 180: tensor(49.2150), 190: tensor(47.8567), 200: tensor(44.9767), 210: tensor(41.4017), 220: tensor(40.5067), 230: tensor(43.6250), 240: tensor(50.9867), 250: tensor(62.8550), 260: tensor(72.3283), 270: tensor(80.5500), 280: tensor(79.3950), 290: tensor(74.4000), 300: tensor(68.5083), 310: tensor(65.6383), 320: tensor(70.6633), 330: tensor(81.3317), 340: tensor(92.8800), 350: tensor(97.6750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=38, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6950,                   Accuracy: 765/2000.0 (38.25%)



-= Testing valid =-
Test set: Average loss: 1.4817,                   Accuracy: 921/2000.0 (46.05%)



-= Testing valid =-
Test set: Average loss: 0.6488,                   Accuracy: 1541/2000.0 (77.05%)



-= Testing valid =-
Test set: Average loss: 5.6660,                   Accuracy: 220/2000.0 (11.00%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1867,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.4211,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 10 train accuracy: 97.96%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.4541,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1823,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 99.03%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.51%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 40 train accuracy: 99.54%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0519,                   Accuracy: 59112/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1114,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2120,                   Accuracy: 55904/60000 (93.17%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4656,                   Accuracy: 52311/60000 (87.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8380,                   Accuracy: 46277/60000 (77.13%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0354,                   Accuracy: 42875/60000 (71.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9790,                   Accuracy: 43386/60000 (72.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6461,                   Accuracy: 48111/60000 (80.18%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5238,                   Accuracy: 49754/60000 (82.92%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5422,                   Accuracy: 49082/60000 (81.80%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8563,                   Accuracy: 43646/60000 (72.74%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4216,                   Accuracy: 35931/60000 (59.88%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2885,                   Accuracy: 27265/60000 (45.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9882,                   Accuracy: 23525/60000 (39.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3261,                   Accuracy: 23094/60000 (38.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4314,                   Accuracy: 24981/60000 (41.63%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2291,                   Accuracy: 28976/60000 (48.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1215,                   Accuracy: 30943/60000 (51.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3431,                   Accuracy: 31283/60000 (52.14%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4306,                   Accuracy: 31097/60000 (51.83%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4490,                   Accuracy: 29344/60000 (48.91%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7358,                   Accuracy: 26544/60000 (44.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4785,                   Accuracy: 25993/60000 (43.32%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8210,                   Accuracy: 28660/60000 (47.77%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8701,                   Accuracy: 35710/60000 (59.52%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0945,                   Accuracy: 43356/60000 (72.26%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6391,                   Accuracy: 48489/60000 (80.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3614,                   Accuracy: 53106/60000 (88.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5684,                   Accuracy: 48367/60000 (80.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8288,                   Accuracy: 43822/60000 (73.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1781,                   Accuracy: 38561/60000 (64.27%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2825,                   Accuracy: 37090/60000 (61.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0717,                   Accuracy: 41141/60000 (68.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6186,                   Accuracy: 48989/60000 (81.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2154,                   Accuracy: 55997/60000 (93.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0858,                   Accuracy: 58466/60000 (97.44%)
{0: tensor(98.5200), 10: tensor(96.2867), 20: tensor(93.1733), 30: tensor(87.1850), 40: tensor(77.1283), 50: tensor(71.4583), 60: tensor(72.3100), 70: tensor(80.1850), 80: tensor(82.9233), 90: tensor(81.8033), 100: tensor(72.7433), 110: tensor(59.8850), 120: tensor(45.4417), 130: tensor(39.2083), 140: tensor(38.4900), 150: tensor(41.6350), 160: tensor(48.2933), 170: tensor(51.5717), 180: tensor(52.1383), 190: tensor(51.8283), 200: tensor(48.9067), 210: tensor(44.2400), 220: tensor(43.3217), 230: tensor(47.7667), 240: tensor(59.5167), 250: tensor(72.2600), 260: tensor(80.8150), 270: tensor(88.5100), 280: tensor(80.6117), 290: tensor(73.0367), 300: tensor(64.2683), 310: tensor(61.8167), 320: tensor(68.5683), 330: tensor(81.6483), 340: tensor(93.3283), 350: tensor(97.4433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=39, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0247,                   Accuracy: 473/2000.0 (23.65%)



-= Testing valid =-
Test set: Average loss: 1.1133,                   Accuracy: 1346/2000.0 (67.30%)



-= Testing valid =-
Test set: Average loss: 0.5025,                   Accuracy: 1702/2000.0 (85.10%)



-= Testing valid =-
Test set: Average loss: 0.6174,                   Accuracy: 1612/2000.0 (80.60%)



-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 10 train accuracy: 98.29%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 99.09%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.32%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0574,                   Accuracy: 58988/60000 (98.31%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0906,                   Accuracy: 58457/60000 (97.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2007,                   Accuracy: 56569/60000 (94.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5101,                   Accuracy: 51021/60000 (85.04%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9833,                   Accuracy: 43008/60000 (71.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2459,                   Accuracy: 38235/60000 (63.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1517,                   Accuracy: 38730/60000 (64.55%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9220,                   Accuracy: 41681/60000 (69.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7597,                   Accuracy: 43844/60000 (73.07%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7513,                   Accuracy: 43624/60000 (72.71%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0796,                   Accuracy: 38653/60000 (64.42%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6481,                   Accuracy: 32804/60000 (54.67%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5513,                   Accuracy: 24787/60000 (41.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2792,                   Accuracy: 22227/60000 (37.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6459,                   Accuracy: 22392/60000 (37.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6497,                   Accuracy: 24754/60000 (41.26%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5495,                   Accuracy: 27158/60000 (45.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5670,                   Accuracy: 28281/60000 (47.13%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6941,                   Accuracy: 28376/60000 (47.29%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.9007,                   Accuracy: 26901/60000 (44.83%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1337,                   Accuracy: 24756/60000 (41.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.4325,                   Accuracy: 22357/60000 (37.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.3551,                   Accuracy: 21542/60000 (35.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.6823,                   Accuracy: 23797/60000 (39.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6178,                   Accuracy: 29459/60000 (49.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6053,                   Accuracy: 36782/60000 (61.30%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9368,                   Accuracy: 43052/60000 (71.75%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5468,                   Accuracy: 49098/60000 (81.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5677,                   Accuracy: 49154/60000 (81.92%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7854,                   Accuracy: 45456/60000 (75.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1844,                   Accuracy: 38974/60000 (64.96%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3260,                   Accuracy: 35798/60000 (59.66%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1646,                   Accuracy: 38994/60000 (64.99%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7087,                   Accuracy: 46916/60000 (78.19%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2751,                   Accuracy: 54717/60000 (91.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0979,                   Accuracy: 58100/60000 (96.83%)
{0: tensor(98.3133), 10: tensor(97.4283), 20: tensor(94.2817), 30: tensor(85.0350), 40: tensor(71.6800), 50: tensor(63.7250), 60: tensor(64.5500), 70: tensor(69.4683), 80: tensor(73.0733), 90: tensor(72.7067), 100: tensor(64.4217), 110: tensor(54.6733), 120: tensor(41.3117), 130: tensor(37.0450), 140: tensor(37.3200), 150: tensor(41.2567), 160: tensor(45.2633), 170: tensor(47.1350), 180: tensor(47.2933), 190: tensor(44.8350), 200: tensor(41.2600), 210: tensor(37.2617), 220: tensor(35.9033), 230: tensor(39.6617), 240: tensor(49.0983), 250: tensor(61.3033), 260: tensor(71.7533), 270: tensor(81.8300), 280: tensor(81.9233), 290: tensor(75.7600), 300: tensor(64.9567), 310: tensor(59.6633), 320: tensor(64.9900), 330: tensor(78.1933), 340: tensor(91.1950), 350: tensor(96.8333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=40, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0427,                   Accuracy: 376/2000.0 (18.80%)



-= Testing valid =-
Test set: Average loss: 3.8851,                   Accuracy: 277/2000.0 (13.85%)



-= Testing valid =-
Test set: Average loss: 1.0902,                   Accuracy: 1241/2000.0 (62.05%)



-= Testing valid =-
Test set: Average loss: 0.8212,                   Accuracy: 1406/2000.0 (70.30%)



-= Testing valid =-
Test set: Average loss: 0.4937,                   Accuracy: 1663/2000.0 (83.15%)



-= Testing valid =-
Test set: Average loss: 0.1998,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 97.90%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 98.78%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.41%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0189,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.54%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0492,                   Accuracy: 59155/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0737,                   Accuracy: 58716/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1559,                   Accuracy: 57373/60000 (95.62%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3951,                   Accuracy: 53410/60000 (89.02%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8093,                   Accuracy: 47254/60000 (78.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0734,                   Accuracy: 43140/60000 (71.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9906,                   Accuracy: 44040/60000 (73.40%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7316,                   Accuracy: 47447/60000 (79.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5643,                   Accuracy: 49306/60000 (82.18%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6211,                   Accuracy: 47937/60000 (79.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0336,                   Accuracy: 41709/60000 (69.51%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6402,                   Accuracy: 35393/60000 (58.99%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6332,                   Accuracy: 27657/60000 (46.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6235,                   Accuracy: 22842/60000 (38.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.1606,                   Accuracy: 21957/60000 (36.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.1343,                   Accuracy: 23995/60000 (39.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.9576,                   Accuracy: 27979/60000 (46.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.9112,                   Accuracy: 30404/60000 (50.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.0168,                   Accuracy: 30481/60000 (50.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.0560,                   Accuracy: 29343/60000 (48.90%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1413,                   Accuracy: 27001/60000 (45.00%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.4300,                   Accuracy: 23638/60000 (39.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.5694,                   Accuracy: 21492/60000 (35.82%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.2930,                   Accuracy: 21547/60000 (35.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.4203,                   Accuracy: 25097/60000 (41.83%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.3889,                   Accuracy: 31172/60000 (51.95%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.4611,                   Accuracy: 38647/60000 (64.41%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.8757,                   Accuracy: 44313/60000 (73.86%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9401,                   Accuracy: 43234/60000 (72.06%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1642,                   Accuracy: 39270/60000 (65.45%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4471,                   Accuracy: 35937/60000 (59.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6200,                   Accuracy: 33518/60000 (55.86%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4274,                   Accuracy: 37463/60000 (62.44%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8266,                   Accuracy: 46711/60000 (77.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2607,                   Accuracy: 55449/60000 (92.42%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0818,                   Accuracy: 58526/60000 (97.54%)
{0: tensor(98.5917), 10: tensor(97.8600), 20: tensor(95.6217), 30: tensor(89.0167), 40: tensor(78.7567), 50: tensor(71.9000), 60: tensor(73.4000), 70: tensor(79.0783), 80: tensor(82.1767), 90: tensor(79.8950), 100: tensor(69.5150), 110: tensor(58.9883), 120: tensor(46.0950), 130: tensor(38.0700), 140: tensor(36.5950), 150: tensor(39.9917), 160: tensor(46.6317), 170: tensor(50.6733), 180: tensor(50.8017), 190: tensor(48.9050), 200: tensor(45.0017), 210: tensor(39.3967), 220: tensor(35.8200), 230: tensor(35.9117), 240: tensor(41.8283), 250: tensor(51.9533), 260: tensor(64.4117), 270: tensor(73.8550), 280: tensor(72.0567), 290: tensor(65.4500), 300: tensor(59.8950), 310: tensor(55.8633), 320: tensor(62.4383), 330: tensor(77.8517), 340: tensor(92.4150), 350: tensor(97.5433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=11, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.1896,                   Accuracy: 1258/2000.0 (62.90%)



-= Testing valid =-
Test set: Average loss: 0.8120,                   Accuracy: 1458/2000.0 (72.90%)



-= Testing valid =-
Test set: Average loss: 0.3319,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.1677,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.3140,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 10 train accuracy: 97.49%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 98.93%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.49%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0553,                   Accuracy: 59080/60000 (98.47%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0873,                   Accuracy: 58545/60000 (97.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2136,                   Accuracy: 56422/60000 (94.04%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7067,                   Accuracy: 48958/60000 (81.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5263,                   Accuracy: 38795/60000 (64.66%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5708,                   Accuracy: 28404/60000 (47.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6357,                   Accuracy: 20005/60000 (33.34%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.2422,                   Accuracy: 15005/60000 (25.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.7251,                   Accuracy: 11963/60000 (19.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.2273,                   Accuracy: 10452/60000 (17.42%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2927,                   Accuracy: 10966/60000 (18.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.4097,                   Accuracy: 10903/60000 (18.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.6135,                   Accuracy: 12089/60000 (20.15%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.5441,                   Accuracy: 15029/60000 (25.05%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.5151,                   Accuracy: 18944/60000 (31.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.5997,                   Accuracy: 23021/60000 (38.37%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.8782,                   Accuracy: 25836/60000 (43.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2521,                   Accuracy: 26777/60000 (44.63%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.7705,                   Accuracy: 26316/60000 (43.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.4885,                   Accuracy: 26683/60000 (44.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4020,                   Accuracy: 25147/60000 (41.91%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3869,                   Accuracy: 22292/60000 (37.15%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2433,                   Accuracy: 20139/60000 (33.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.1496,                   Accuracy: 17981/60000 (29.97%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1664,                   Accuracy: 15123/60000 (25.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0828,                   Accuracy: 12859/60000 (21.43%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.9697,                   Accuracy: 11094/60000 (18.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0268,                   Accuracy: 9674/60000 (16.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.8860,                   Accuracy: 9596/60000 (15.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3792,                   Accuracy: 9755/60000 (16.26%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5951,                   Accuracy: 12289/60000 (20.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3599,                   Accuracy: 20146/60000 (33.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9083,                   Accuracy: 33081/60000 (55.13%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8110,                   Accuracy: 46829/60000 (78.05%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2535,                   Accuracy: 55471/60000 (92.45%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0841,                   Accuracy: 58469/60000 (97.45%)
{0: tensor(98.4667), 10: tensor(97.5750), 20: tensor(94.0367), 30: tensor(81.5967), 40: tensor(64.6583), 50: tensor(47.3400), 60: tensor(33.3417), 70: tensor(25.0083), 80: tensor(19.9383), 90: tensor(17.4200), 100: tensor(18.2767), 110: tensor(18.1717), 120: tensor(20.1483), 130: tensor(25.0483), 140: tensor(31.5733), 150: tensor(38.3683), 160: tensor(43.0600), 170: tensor(44.6283), 180: tensor(43.8600), 190: tensor(44.4717), 200: tensor(41.9117), 210: tensor(37.1533), 220: tensor(33.5650), 230: tensor(29.9683), 240: tensor(25.2050), 250: tensor(21.4317), 260: tensor(18.4900), 270: tensor(16.1233), 280: tensor(15.9933), 290: tensor(16.2583), 300: tensor(20.4817), 310: tensor(33.5767), 320: tensor(55.1350), 330: tensor(78.0483), 340: tensor(92.4517), 350: tensor(97.4483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=12, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.5799,                   Accuracy: 993/2000.0 (49.65%)



-= Testing valid =-
Test set: Average loss: 0.2838,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1556,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.3352,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.1711,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.4153,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 10 train accuracy: 97.85%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 98.95%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.25%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0498,                   Accuracy: 59119/60000 (98.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0801,                   Accuracy: 58608/60000 (97.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2052,                   Accuracy: 56489/60000 (94.15%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6053,                   Accuracy: 49835/60000 (83.06%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3280,                   Accuracy: 39768/60000 (66.28%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2922,                   Accuracy: 29616/60000 (49.36%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.3624,                   Accuracy: 20489/60000 (34.15%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.2632,                   Accuracy: 14677/60000 (24.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.8182,                   Accuracy: 11415/60000 (19.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.1140,                   Accuracy: 10474/60000 (17.46%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2508,                   Accuracy: 10204/60000 (17.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.4436,                   Accuracy: 10264/60000 (17.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.6353,                   Accuracy: 11438/60000 (19.06%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.6514,                   Accuracy: 14328/60000 (23.88%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.6080,                   Accuracy: 17800/60000 (29.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4976,                   Accuracy: 21725/60000 (36.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.6815,                   Accuracy: 25013/60000 (41.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.9875,                   Accuracy: 26419/60000 (44.03%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.4868,                   Accuracy: 26400/60000 (44.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.1885,                   Accuracy: 26498/60000 (44.16%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.0354,                   Accuracy: 24606/60000 (41.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.9139,                   Accuracy: 21306/60000 (35.51%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.7895,                   Accuracy: 18902/60000 (31.50%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.7898,                   Accuracy: 16585/60000 (27.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.8776,                   Accuracy: 14113/60000 (23.52%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.9960,                   Accuracy: 12320/60000 (20.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.7636,                   Accuracy: 10801/60000 (18.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.5897,                   Accuracy: 9590/60000 (15.98%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.2288,                   Accuracy: 8938/60000 (14.90%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.7975,                   Accuracy: 9990/60000 (16.65%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.2329,                   Accuracy: 12733/60000 (21.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.1757,                   Accuracy: 20241/60000 (33.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9649,                   Accuracy: 31977/60000 (53.29%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8639,                   Accuracy: 45529/60000 (75.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2537,                   Accuracy: 55369/60000 (92.28%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0783,                   Accuracy: 58557/60000 (97.60%)
{0: tensor(98.5317), 10: tensor(97.6800), 20: tensor(94.1483), 30: tensor(83.0583), 40: tensor(66.2800), 50: tensor(49.3600), 60: tensor(34.1483), 70: tensor(24.4617), 80: tensor(19.0250), 90: tensor(17.4567), 100: tensor(17.0067), 110: tensor(17.1067), 120: tensor(19.0633), 130: tensor(23.8800), 140: tensor(29.6667), 150: tensor(36.2083), 160: tensor(41.6883), 170: tensor(44.0317), 180: tensor(44.), 190: tensor(44.1633), 200: tensor(41.0100), 210: tensor(35.5100), 220: tensor(31.5033), 230: tensor(27.6417), 240: tensor(23.5217), 250: tensor(20.5333), 260: tensor(18.0017), 270: tensor(15.9833), 280: tensor(14.8967), 290: tensor(16.6500), 300: tensor(21.2217), 310: tensor(33.7350), 320: tensor(53.2950), 330: tensor(75.8817), 340: tensor(92.2817), 350: tensor(97.5950)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=13, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3602,                   Accuracy: 440/2000.0 (22.00%)



-= Testing valid =-
Test set: Average loss: 0.3606,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2053,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1608,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.2048,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1273,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 10 train accuracy: 98.06%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 98.89%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.49%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.51%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.51%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0625,                   Accuracy: 58962/60000 (98.27%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0957,                   Accuracy: 58403/60000 (97.34%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2130,                   Accuracy: 56490/60000 (94.15%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6105,                   Accuracy: 49996/60000 (83.33%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2458,                   Accuracy: 41405/60000 (69.01%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2029,                   Accuracy: 31627/60000 (52.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.3715,                   Accuracy: 22746/60000 (37.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.2176,                   Accuracy: 17628/60000 (29.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9466,                   Accuracy: 14773/60000 (24.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.3702,                   Accuracy: 13935/60000 (23.23%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.5768,                   Accuracy: 14472/60000 (24.12%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6502,                   Accuracy: 13962/60000 (23.27%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.4802,                   Accuracy: 14823/60000 (24.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.4852,                   Accuracy: 16185/60000 (26.98%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.5418,                   Accuracy: 18634/60000 (31.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6260,                   Accuracy: 22127/60000 (36.88%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.8980,                   Accuracy: 24708/60000 (41.18%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.1589,                   Accuracy: 25939/60000 (43.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6848,                   Accuracy: 25807/60000 (43.01%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5264,                   Accuracy: 25906/60000 (43.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5646,                   Accuracy: 24508/60000 (40.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3988,                   Accuracy: 21672/60000 (36.12%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2112,                   Accuracy: 19701/60000 (32.83%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.0663,                   Accuracy: 17783/60000 (29.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.0946,                   Accuracy: 15872/60000 (26.45%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0584,                   Accuracy: 14483/60000 (24.14%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0506,                   Accuracy: 12708/60000 (21.18%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0556,                   Accuracy: 12053/60000 (20.09%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.8163,                   Accuracy: 11347/60000 (18.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.2993,                   Accuracy: 11537/60000 (19.23%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.2607,                   Accuracy: 15216/60000 (25.36%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.0962,                   Accuracy: 22785/60000 (37.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.7284,                   Accuracy: 35706/60000 (59.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7157,                   Accuracy: 48532/60000 (80.89%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2244,                   Accuracy: 56115/60000 (93.53%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0844,                   Accuracy: 58601/60000 (97.67%)
{0: tensor(98.2700), 10: tensor(97.3383), 20: tensor(94.1500), 30: tensor(83.3267), 40: tensor(69.0083), 50: tensor(52.7117), 60: tensor(37.9100), 70: tensor(29.3800), 80: tensor(24.6217), 90: tensor(23.2250), 100: tensor(24.1200), 110: tensor(23.2700), 120: tensor(24.7050), 130: tensor(26.9750), 140: tensor(31.0567), 150: tensor(36.8783), 160: tensor(41.1800), 170: tensor(43.2317), 180: tensor(43.0117), 190: tensor(43.1767), 200: tensor(40.8467), 210: tensor(36.1200), 220: tensor(32.8350), 230: tensor(29.6383), 240: tensor(26.4533), 250: tensor(24.1383), 260: tensor(21.1800), 270: tensor(20.0883), 280: tensor(18.9117), 290: tensor(19.2283), 300: tensor(25.3600), 310: tensor(37.9750), 320: tensor(59.5100), 330: tensor(80.8867), 340: tensor(93.5250), 350: tensor(97.6683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=14, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7926,                   Accuracy: 705/2000.0 (35.25%)



-= Testing valid =-
Test set: Average loss: 0.7143,                   Accuracy: 1533/2000.0 (76.65%)



-= Testing valid =-
Test set: Average loss: 0.2405,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.2744,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 10 train accuracy: 97.80%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 98.89%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.29%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0534,                   Accuracy: 59050/60000 (98.42%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0802,                   Accuracy: 58614/60000 (97.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2012,                   Accuracy: 56554/60000 (94.26%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5865,                   Accuracy: 50471/60000 (84.12%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4582,                   Accuracy: 39263/60000 (65.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6891,                   Accuracy: 27782/60000 (46.30%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9830,                   Accuracy: 18210/60000 (30.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8535,                   Accuracy: 12368/60000 (20.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4299,                   Accuracy: 9196/60000 (15.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.9901,                   Accuracy: 8836/60000 (14.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0882,                   Accuracy: 10034/60000 (16.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.4259,                   Accuracy: 10434/60000 (17.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.5902,                   Accuracy: 11590/60000 (19.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2329,                   Accuracy: 14317/60000 (23.86%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8249,                   Accuracy: 17822/60000 (29.70%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4631,                   Accuracy: 21743/60000 (36.24%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.4158,                   Accuracy: 25010/60000 (41.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.7448,                   Accuracy: 27109/60000 (45.18%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.3100,                   Accuracy: 26914/60000 (44.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.2045,                   Accuracy: 26956/60000 (44.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.2978,                   Accuracy: 24474/60000 (40.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4985,                   Accuracy: 20463/60000 (34.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.6061,                   Accuracy: 17256/60000 (28.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6987,                   Accuracy: 15051/60000 (25.08%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6994,                   Accuracy: 12729/60000 (21.22%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6949,                   Accuracy: 10521/60000 (17.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6567,                   Accuracy: 9424/60000 (15.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.6994,                   Accuracy: 8801/60000 (14.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.5004,                   Accuracy: 8562/60000 (14.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.2050,                   Accuracy: 8575/60000 (14.29%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.4878,                   Accuracy: 10962/60000 (18.27%)
-= Testing Rotation 310 =-
Test set: Average loss: 4.2388,                   Accuracy: 17814/60000 (29.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.6737,                   Accuracy: 29203/60000 (48.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.2931,                   Accuracy: 42548/60000 (70.91%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3881,                   Accuracy: 53667/60000 (89.44%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0983,                   Accuracy: 58211/60000 (97.02%)
{0: tensor(98.4167), 10: tensor(97.6900), 20: tensor(94.2567), 30: tensor(84.1183), 40: tensor(65.4383), 50: tensor(46.3033), 60: tensor(30.3500), 70: tensor(20.6133), 80: tensor(15.3267), 90: tensor(14.7267), 100: tensor(16.7233), 110: tensor(17.3900), 120: tensor(19.3167), 130: tensor(23.8617), 140: tensor(29.7033), 150: tensor(36.2383), 160: tensor(41.6833), 170: tensor(45.1817), 180: tensor(44.8567), 190: tensor(44.9267), 200: tensor(40.7900), 210: tensor(34.1050), 220: tensor(28.7600), 230: tensor(25.0850), 240: tensor(21.2150), 250: tensor(17.5350), 260: tensor(15.7067), 270: tensor(14.6683), 280: tensor(14.2700), 290: tensor(14.2917), 300: tensor(18.2700), 310: tensor(29.6900), 320: tensor(48.6717), 330: tensor(70.9133), 340: tensor(89.4450), 350: tensor(97.0183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=15, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.2117,                   Accuracy: 1054/2000.0 (52.70%)



-= Testing valid =-
Test set: Average loss: 1.0264,                   Accuracy: 1295/2000.0 (64.75%)



-= Testing valid =-
Test set: Average loss: 0.1833,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1755,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1218,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1458,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.2507,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1387,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 10 train accuracy: 97.35%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.38%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0666,                   Accuracy: 58918/60000 (98.20%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1101,                   Accuracy: 58237/60000 (97.06%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2629,                   Accuracy: 55983/60000 (93.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7606,                   Accuracy: 49037/60000 (81.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.6725,                   Accuracy: 38756/60000 (64.59%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.9202,                   Accuracy: 28487/60000 (47.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.2080,                   Accuracy: 20279/60000 (33.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.2272,                   Accuracy: 15271/60000 (25.45%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.9323,                   Accuracy: 11817/60000 (19.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.3138,                   Accuracy: 11550/60000 (19.25%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.3146,                   Accuracy: 12143/60000 (20.24%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.2367,                   Accuracy: 12451/60000 (20.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9317,                   Accuracy: 14086/60000 (23.48%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7305,                   Accuracy: 16682/60000 (27.80%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.6845,                   Accuracy: 19654/60000 (32.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7759,                   Accuracy: 23224/60000 (38.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1267,                   Accuracy: 25632/60000 (42.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4566,                   Accuracy: 26677/60000 (44.46%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.0218,                   Accuracy: 27050/60000 (45.08%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.9537,                   Accuracy: 26725/60000 (44.54%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.0757,                   Accuracy: 24971/60000 (41.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.9310,                   Accuracy: 22203/60000 (37.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7274,                   Accuracy: 19917/60000 (33.19%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6441,                   Accuracy: 17551/60000 (29.25%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6470,                   Accuracy: 15373/60000 (25.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6766,                   Accuracy: 13622/60000 (22.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6305,                   Accuracy: 11815/60000 (19.69%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.7549,                   Accuracy: 10924/60000 (18.21%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.5156,                   Accuracy: 10202/60000 (17.00%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.9636,                   Accuracy: 10930/60000 (18.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0635,                   Accuracy: 14240/60000 (23.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6849,                   Accuracy: 21810/60000 (36.35%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0489,                   Accuracy: 34413/60000 (57.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8088,                   Accuracy: 47751/60000 (79.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2447,                   Accuracy: 55870/60000 (93.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0910,                   Accuracy: 58496/60000 (97.49%)
{0: tensor(98.1967), 10: tensor(97.0617), 20: tensor(93.3050), 30: tensor(81.7283), 40: tensor(64.5933), 50: tensor(47.4783), 60: tensor(33.7983), 70: tensor(25.4517), 80: tensor(19.6950), 90: tensor(19.2500), 100: tensor(20.2383), 110: tensor(20.7517), 120: tensor(23.4767), 130: tensor(27.8033), 140: tensor(32.7567), 150: tensor(38.7067), 160: tensor(42.7200), 170: tensor(44.4617), 180: tensor(45.0833), 190: tensor(44.5417), 200: tensor(41.6183), 210: tensor(37.0050), 220: tensor(33.1950), 230: tensor(29.2517), 240: tensor(25.6217), 250: tensor(22.7033), 260: tensor(19.6917), 270: tensor(18.2067), 280: tensor(17.0033), 290: tensor(18.2167), 300: tensor(23.7333), 310: tensor(36.3500), 320: tensor(57.3550), 330: tensor(79.5850), 340: tensor(93.1167), 350: tensor(97.4933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=16, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.0420,                   Accuracy: 1351/2000.0 (67.55%)



-= Testing valid =-
Test set: Average loss: 0.3765,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2852,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2384,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1555,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1916,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 10 train accuracy: 97.99%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 98.99%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.50%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0537,                   Accuracy: 59096/60000 (98.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0867,                   Accuracy: 58577/60000 (97.63%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2148,                   Accuracy: 56523/60000 (94.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6035,                   Accuracy: 50528/60000 (84.21%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3060,                   Accuracy: 40910/60000 (68.18%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.3079,                   Accuracy: 30691/60000 (51.15%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.3519,                   Accuracy: 22247/60000 (37.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.1723,                   Accuracy: 16005/60000 (26.67%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.8765,                   Accuracy: 12313/60000 (20.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4868,                   Accuracy: 11398/60000 (19.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.6413,                   Accuracy: 10904/60000 (18.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8656,                   Accuracy: 10914/60000 (18.19%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9338,                   Accuracy: 12451/60000 (20.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9360,                   Accuracy: 15132/60000 (25.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9692,                   Accuracy: 18343/60000 (30.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0791,                   Accuracy: 21870/60000 (36.45%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3577,                   Accuracy: 24130/60000 (40.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.7123,                   Accuracy: 24813/60000 (41.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.3397,                   Accuracy: 24702/60000 (41.17%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.0751,                   Accuracy: 25032/60000 (41.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.3098,                   Accuracy: 23597/60000 (39.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.3325,                   Accuracy: 20978/60000 (34.96%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.1199,                   Accuracy: 18271/60000 (30.45%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.9250,                   Accuracy: 15602/60000 (26.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7125,                   Accuracy: 13497/60000 (22.50%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4692,                   Accuracy: 11870/60000 (19.78%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.9998,                   Accuracy: 11739/60000 (19.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.8662,                   Accuracy: 11399/60000 (19.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.4267,                   Accuracy: 10983/60000 (18.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.0624,                   Accuracy: 10975/60000 (18.29%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.3473,                   Accuracy: 13083/60000 (21.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.1950,                   Accuracy: 20189/60000 (33.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8268,                   Accuracy: 32999/60000 (55.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7310,                   Accuracy: 47634/60000 (79.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2264,                   Accuracy: 55863/60000 (93.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0746,                   Accuracy: 58685/60000 (97.81%)
{0: tensor(98.4933), 10: tensor(97.6283), 20: tensor(94.2050), 30: tensor(84.2133), 40: tensor(68.1833), 50: tensor(51.1517), 60: tensor(37.0783), 70: tensor(26.6750), 80: tensor(20.5217), 90: tensor(18.9967), 100: tensor(18.1733), 110: tensor(18.1900), 120: tensor(20.7517), 130: tensor(25.2200), 140: tensor(30.5717), 150: tensor(36.4500), 160: tensor(40.2167), 170: tensor(41.3550), 180: tensor(41.1700), 190: tensor(41.7200), 200: tensor(39.3283), 210: tensor(34.9633), 220: tensor(30.4517), 230: tensor(26.0033), 240: tensor(22.4950), 250: tensor(19.7833), 260: tensor(19.5650), 270: tensor(18.9983), 280: tensor(18.3050), 290: tensor(18.2917), 300: tensor(21.8050), 310: tensor(33.6483), 320: tensor(54.9983), 330: tensor(79.3900), 340: tensor(93.1050), 350: tensor(97.8083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=17, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6308,                   Accuracy: 544/2000.0 (27.20%)



-= Testing valid =-
Test set: Average loss: 0.2848,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2205,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1493,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.2603,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 10 train accuracy: 98.01%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.99%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 30 train accuracy: 99.30%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.64%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0650,                   Accuracy: 58887/60000 (98.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1021,                   Accuracy: 58291/60000 (97.15%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2124,                   Accuracy: 56536/60000 (94.23%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5646,                   Accuracy: 51118/60000 (85.20%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2648,                   Accuracy: 42181/60000 (70.30%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2408,                   Accuracy: 32736/60000 (54.56%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.2759,                   Accuracy: 24765/60000 (41.28%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.0847,                   Accuracy: 18456/60000 (30.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.7210,                   Accuracy: 14055/60000 (23.42%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.1056,                   Accuracy: 12955/60000 (21.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2980,                   Accuracy: 12273/60000 (20.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.5509,                   Accuracy: 11689/60000 (19.48%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.5397,                   Accuracy: 13113/60000 (21.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.5711,                   Accuracy: 15864/60000 (26.44%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.4420,                   Accuracy: 19155/60000 (31.92%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.3858,                   Accuracy: 22969/60000 (38.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.6918,                   Accuracy: 25738/60000 (42.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.0567,                   Accuracy: 26858/60000 (44.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6746,                   Accuracy: 27160/60000 (45.27%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5674,                   Accuracy: 27615/60000 (46.03%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.6477,                   Accuracy: 26014/60000 (43.36%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5494,                   Accuracy: 22928/60000 (38.21%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3536,                   Accuracy: 20132/60000 (33.55%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.2199,                   Accuracy: 17685/60000 (29.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.9726,                   Accuracy: 16438/60000 (27.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.6880,                   Accuracy: 15956/60000 (26.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.4248,                   Accuracy: 16090/60000 (26.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.0071,                   Accuracy: 16552/60000 (27.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 4.8258,                   Accuracy: 14634/60000 (24.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.3899,                   Accuracy: 14638/60000 (24.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.7819,                   Accuracy: 15747/60000 (26.25%)
-= Testing Rotation 310 =-
Test set: Average loss: 2.9612,                   Accuracy: 23170/60000 (38.62%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8581,                   Accuracy: 34851/60000 (58.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7925,                   Accuracy: 47743/60000 (79.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2482,                   Accuracy: 55677/60000 (92.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0911,                   Accuracy: 58418/60000 (97.36%)
{0: tensor(98.1450), 10: tensor(97.1517), 20: tensor(94.2267), 30: tensor(85.1967), 40: tensor(70.3017), 50: tensor(54.5600), 60: tensor(41.2750), 70: tensor(30.7600), 80: tensor(23.4250), 90: tensor(21.5917), 100: tensor(20.4550), 110: tensor(19.4817), 120: tensor(21.8550), 130: tensor(26.4400), 140: tensor(31.9250), 150: tensor(38.2817), 160: tensor(42.8967), 170: tensor(44.7633), 180: tensor(45.2667), 190: tensor(46.0250), 200: tensor(43.3567), 210: tensor(38.2133), 220: tensor(33.5533), 230: tensor(29.4750), 240: tensor(27.3967), 250: tensor(26.5933), 260: tensor(26.8167), 270: tensor(27.5867), 280: tensor(24.3900), 290: tensor(24.3967), 300: tensor(26.2450), 310: tensor(38.6167), 320: tensor(58.0850), 330: tensor(79.5717), 340: tensor(92.7950), 350: tensor(97.3633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=18, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.4565,                   Accuracy: 797/2000.0 (39.85%)



-= Testing valid =-
Test set: Average loss: 0.2689,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.3134,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2047,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1379,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 98.03%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 99.06%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.31%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.78%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0463,                   Accuracy: 59195/60000 (98.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0863,                   Accuracy: 58588/60000 (97.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2148,                   Accuracy: 56573/60000 (94.29%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6134,                   Accuracy: 50506/60000 (84.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4249,                   Accuracy: 40244/60000 (67.07%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5809,                   Accuracy: 29560/60000 (49.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8968,                   Accuracy: 20431/60000 (34.05%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9298,                   Accuracy: 13462/60000 (22.44%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.6047,                   Accuracy: 10262/60000 (17.10%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.1520,                   Accuracy: 9746/60000 (16.24%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0889,                   Accuracy: 9663/60000 (16.10%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.3332,                   Accuracy: 10048/60000 (16.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.3166,                   Accuracy: 12123/60000 (20.20%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0098,                   Accuracy: 15318/60000 (25.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7428,                   Accuracy: 19253/60000 (32.09%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7586,                   Accuracy: 23206/60000 (38.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0310,                   Accuracy: 25853/60000 (43.09%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.3477,                   Accuracy: 26816/60000 (44.69%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6819,                   Accuracy: 26612/60000 (44.35%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5998,                   Accuracy: 26570/60000 (44.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7194,                   Accuracy: 24814/60000 (41.36%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.6414,                   Accuracy: 21985/60000 (36.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.6050,                   Accuracy: 19227/60000 (32.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6485,                   Accuracy: 16530/60000 (27.55%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7797,                   Accuracy: 13953/60000 (23.25%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7962,                   Accuracy: 11900/60000 (19.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6358,                   Accuracy: 10726/60000 (17.88%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.5643,                   Accuracy: 9263/60000 (15.44%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.1583,                   Accuracy: 9123/60000 (15.20%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6779,                   Accuracy: 9395/60000 (15.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7693,                   Accuracy: 13123/60000 (21.87%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3998,                   Accuracy: 21355/60000 (35.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9252,                   Accuracy: 34312/60000 (57.19%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7740,                   Accuracy: 47904/60000 (79.84%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2200,                   Accuracy: 56191/60000 (93.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0685,                   Accuracy: 58770/60000 (97.95%)
{0: tensor(98.6583), 10: tensor(97.6467), 20: tensor(94.2883), 30: tensor(84.1767), 40: tensor(67.0733), 50: tensor(49.2667), 60: tensor(34.0517), 70: tensor(22.4367), 80: tensor(17.1033), 90: tensor(16.2433), 100: tensor(16.1050), 110: tensor(16.7467), 120: tensor(20.2050), 130: tensor(25.5300), 140: tensor(32.0883), 150: tensor(38.6767), 160: tensor(43.0883), 170: tensor(44.6933), 180: tensor(44.3533), 190: tensor(44.2833), 200: tensor(41.3567), 210: tensor(36.6417), 220: tensor(32.0450), 230: tensor(27.5500), 240: tensor(23.2550), 250: tensor(19.8333), 260: tensor(17.8767), 270: tensor(15.4383), 280: tensor(15.2050), 290: tensor(15.6583), 300: tensor(21.8717), 310: tensor(35.5917), 320: tensor(57.1867), 330: tensor(79.8400), 340: tensor(93.6517), 350: tensor(97.9500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=19, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1709,                   Accuracy: 476/2000.0 (23.80%)



-= Testing valid =-
Test set: Average loss: 1.0479,                   Accuracy: 1446/2000.0 (72.30%)



-= Testing valid =-
Test set: Average loss: 0.1832,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.3337,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 10 train accuracy: 97.90%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 98.95%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.44%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.54%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0559,                   Accuracy: 59064/60000 (98.44%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0911,                   Accuracy: 58498/60000 (97.50%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2035,                   Accuracy: 56708/60000 (94.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6307,                   Accuracy: 50232/60000 (83.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4150,                   Accuracy: 40587/60000 (67.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4576,                   Accuracy: 30754/60000 (51.26%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6203,                   Accuracy: 22237/60000 (37.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5179,                   Accuracy: 16206/60000 (27.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.2112,                   Accuracy: 12015/60000 (20.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.5805,                   Accuracy: 11078/60000 (18.46%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.7176,                   Accuracy: 10316/60000 (17.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8197,                   Accuracy: 10183/60000 (16.97%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7681,                   Accuracy: 11565/60000 (19.27%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7520,                   Accuracy: 14645/60000 (24.41%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.6612,                   Accuracy: 17885/60000 (29.81%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7243,                   Accuracy: 22143/60000 (36.90%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1380,                   Accuracy: 25163/60000 (41.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5055,                   Accuracy: 26647/60000 (44.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.7621,                   Accuracy: 27420/60000 (45.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5944,                   Accuracy: 27000/60000 (45.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4828,                   Accuracy: 25730/60000 (42.88%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.2623,                   Accuracy: 23131/60000 (38.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2169,                   Accuracy: 19899/60000 (33.17%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.2659,                   Accuracy: 17870/60000 (29.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.3332,                   Accuracy: 15920/60000 (26.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.3147,                   Accuracy: 13984/60000 (23.31%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.1659,                   Accuracy: 12041/60000 (20.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.9365,                   Accuracy: 10798/60000 (18.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.5973,                   Accuracy: 10053/60000 (16.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.1343,                   Accuracy: 10128/60000 (16.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4115,                   Accuracy: 13432/60000 (22.39%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3553,                   Accuracy: 20999/60000 (35.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9624,                   Accuracy: 33296/60000 (55.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7795,                   Accuracy: 47289/60000 (78.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2218,                   Accuracy: 56016/60000 (93.36%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0751,                   Accuracy: 58722/60000 (97.87%)
{0: tensor(98.4400), 10: tensor(97.4967), 20: tensor(94.5133), 30: tensor(83.7200), 40: tensor(67.6450), 50: tensor(51.2567), 60: tensor(37.0617), 70: tensor(27.0100), 80: tensor(20.0250), 90: tensor(18.4633), 100: tensor(17.1933), 110: tensor(16.9717), 120: tensor(19.2750), 130: tensor(24.4083), 140: tensor(29.8083), 150: tensor(36.9050), 160: tensor(41.9383), 170: tensor(44.4117), 180: tensor(45.7000), 190: tensor(45.), 200: tensor(42.8833), 210: tensor(38.5517), 220: tensor(33.1650), 230: tensor(29.7833), 240: tensor(26.5333), 250: tensor(23.3067), 260: tensor(20.0683), 270: tensor(17.9967), 280: tensor(16.7550), 290: tensor(16.8800), 300: tensor(22.3867), 310: tensor(34.9983), 320: tensor(55.4933), 330: tensor(78.8150), 340: tensor(93.3600), 350: tensor(97.8700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=20, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7489,                   Accuracy: 838/2000.0 (41.90%)



-= Testing valid =-
Test set: Average loss: 0.3123,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.3389,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1932,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1512,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1635,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 10 train accuracy: 97.94%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 99.06%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.36%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.62%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0575,                   Accuracy: 59056/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0893,                   Accuracy: 58542/60000 (97.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2323,                   Accuracy: 56379/60000 (93.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7104,                   Accuracy: 49367/60000 (82.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5115,                   Accuracy: 39895/60000 (66.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6492,                   Accuracy: 29200/60000 (48.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9905,                   Accuracy: 19876/60000 (33.13%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9017,                   Accuracy: 14545/60000 (24.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4735,                   Accuracy: 11158/60000 (18.60%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.0474,                   Accuracy: 10052/60000 (16.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0760,                   Accuracy: 10617/60000 (17.69%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1526,                   Accuracy: 10819/60000 (18.03%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1755,                   Accuracy: 11828/60000 (19.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.3294,                   Accuracy: 14264/60000 (23.77%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.4794,                   Accuracy: 17826/60000 (29.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.7798,                   Accuracy: 22375/60000 (37.29%)
-= Testing Rotation 160 =-
Test set: Average loss: 7.3361,                   Accuracy: 25926/60000 (43.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.7386,                   Accuracy: 27306/60000 (45.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 8.3005,                   Accuracy: 28162/60000 (46.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 8.0259,                   Accuracy: 28309/60000 (47.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 8.0659,                   Accuracy: 26312/60000 (43.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.7854,                   Accuracy: 23161/60000 (38.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.5458,                   Accuracy: 20326/60000 (33.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 7.2954,                   Accuracy: 17823/60000 (29.70%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.2007,                   Accuracy: 14879/60000 (24.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.1316,                   Accuracy: 12703/60000 (21.17%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.7838,                   Accuracy: 10575/60000 (17.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.6827,                   Accuracy: 8886/60000 (14.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2374,                   Accuracy: 8995/60000 (14.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6267,                   Accuracy: 9602/60000 (16.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7812,                   Accuracy: 12385/60000 (20.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4797,                   Accuracy: 19647/60000 (32.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0421,                   Accuracy: 31855/60000 (53.09%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8288,                   Accuracy: 46591/60000 (77.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2394,                   Accuracy: 55731/60000 (92.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0771,                   Accuracy: 58654/60000 (97.76%)
{0: tensor(98.4267), 10: tensor(97.5700), 20: tensor(93.9650), 30: tensor(82.2783), 40: tensor(66.4917), 50: tensor(48.6667), 60: tensor(33.1267), 70: tensor(24.2417), 80: tensor(18.5967), 90: tensor(16.7533), 100: tensor(17.6950), 110: tensor(18.0317), 120: tensor(19.7133), 130: tensor(23.7733), 140: tensor(29.7100), 150: tensor(37.2917), 160: tensor(43.2100), 170: tensor(45.5100), 180: tensor(46.9367), 190: tensor(47.1817), 200: tensor(43.8533), 210: tensor(38.6017), 220: tensor(33.8767), 230: tensor(29.7050), 240: tensor(24.7983), 250: tensor(21.1717), 260: tensor(17.6250), 270: tensor(14.8100), 280: tensor(14.9917), 290: tensor(16.0033), 300: tensor(20.6417), 310: tensor(32.7450), 320: tensor(53.0917), 330: tensor(77.6517), 340: tensor(92.8850), 350: tensor(97.7567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=21, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7041,                   Accuracy: 324/2000.0 (16.20%)



-= Testing valid =-
Test set: Average loss: 0.8564,                   Accuracy: 1376/2000.0 (68.80%)



-= Testing valid =-
Test set: Average loss: 0.2537,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.5511,                   Accuracy: 1662/2000.0 (83.10%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 97.61%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 20 train accuracy: 98.75%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.24%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.49%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0659,                   Accuracy: 58911/60000 (98.18%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1231,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2967,                   Accuracy: 55229/60000 (92.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7565,                   Accuracy: 48354/60000 (80.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5608,                   Accuracy: 38356/60000 (63.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6158,                   Accuracy: 28210/60000 (47.02%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6849,                   Accuracy: 20033/60000 (33.39%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.4921,                   Accuracy: 15075/60000 (25.12%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.0791,                   Accuracy: 11195/60000 (18.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4543,                   Accuracy: 9494/60000 (15.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.7781,                   Accuracy: 8944/60000 (14.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.2606,                   Accuracy: 8881/60000 (14.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.4296,                   Accuracy: 10077/60000 (16.80%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2260,                   Accuracy: 13002/60000 (21.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.0296,                   Accuracy: 16717/60000 (27.86%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.8674,                   Accuracy: 21719/60000 (36.20%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0045,                   Accuracy: 25565/60000 (42.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.1144,                   Accuracy: 27165/60000 (45.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.5225,                   Accuracy: 26998/60000 (45.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.3817,                   Accuracy: 27081/60000 (45.13%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.3902,                   Accuracy: 24860/60000 (41.43%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3565,                   Accuracy: 21744/60000 (36.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.4190,                   Accuracy: 18560/60000 (30.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4986,                   Accuracy: 15601/60000 (26.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5962,                   Accuracy: 12755/60000 (21.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7062,                   Accuracy: 10841/60000 (18.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5504,                   Accuracy: 9475/60000 (15.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3368,                   Accuracy: 8825/60000 (14.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2174,                   Accuracy: 9357/60000 (15.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.8568,                   Accuracy: 10566/60000 (17.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0433,                   Accuracy: 13180/60000 (21.97%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6372,                   Accuracy: 20384/60000 (33.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1278,                   Accuracy: 32026/60000 (53.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8913,                   Accuracy: 46216/60000 (77.03%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2716,                   Accuracy: 55494/60000 (92.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0977,                   Accuracy: 58298/60000 (97.16%)
{0: tensor(98.1850), 10: tensor(96.4817), 20: tensor(92.0483), 30: tensor(80.5900), 40: tensor(63.9267), 50: tensor(47.0167), 60: tensor(33.3883), 70: tensor(25.1250), 80: tensor(18.6583), 90: tensor(15.8233), 100: tensor(14.9067), 110: tensor(14.8017), 120: tensor(16.7950), 130: tensor(21.6700), 140: tensor(27.8617), 150: tensor(36.1983), 160: tensor(42.6083), 170: tensor(45.2750), 180: tensor(44.9967), 190: tensor(45.1350), 200: tensor(41.4333), 210: tensor(36.2400), 220: tensor(30.9333), 230: tensor(26.0017), 240: tensor(21.2583), 250: tensor(18.0683), 260: tensor(15.7917), 270: tensor(14.7083), 280: tensor(15.5950), 290: tensor(17.6100), 300: tensor(21.9667), 310: tensor(33.9733), 320: tensor(53.3767), 330: tensor(77.0267), 340: tensor(92.4900), 350: tensor(97.1633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=22, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3026,                   Accuracy: 649/2000.0 (32.45%)



-= Testing valid =-
Test set: Average loss: 0.4305,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2567,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2157,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1434,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1535,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1695,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1891,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 10 train accuracy: 97.86%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.96%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 99.25%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.43%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0588,                   Accuracy: 59029/60000 (98.38%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0995,                   Accuracy: 58403/60000 (97.34%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2225,                   Accuracy: 56547/60000 (94.25%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6008,                   Accuracy: 50648/60000 (84.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3504,                   Accuracy: 40640/60000 (67.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.3740,                   Accuracy: 30084/60000 (50.14%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.4627,                   Accuracy: 20798/60000 (34.66%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.3444,                   Accuracy: 14635/60000 (24.39%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.8999,                   Accuracy: 11807/60000 (19.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.2130,                   Accuracy: 11574/60000 (19.29%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.3738,                   Accuracy: 11591/60000 (19.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6173,                   Accuracy: 11538/60000 (19.23%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9695,                   Accuracy: 13136/60000 (21.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2838,                   Accuracy: 15276/60000 (25.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.4804,                   Accuracy: 18236/60000 (30.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.6495,                   Accuracy: 22235/60000 (37.06%)
-= Testing Rotation 160 =-
Test set: Average loss: 7.0610,                   Accuracy: 25305/60000 (42.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.3560,                   Accuracy: 26926/60000 (44.88%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.8323,                   Accuracy: 27326/60000 (45.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.4612,                   Accuracy: 27574/60000 (45.96%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.4903,                   Accuracy: 25641/60000 (42.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.3086,                   Accuracy: 22218/60000 (37.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.1209,                   Accuracy: 18356/60000 (30.59%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.9272,                   Accuracy: 15637/60000 (26.06%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6969,                   Accuracy: 13448/60000 (22.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4992,                   Accuracy: 12162/60000 (20.27%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.2188,                   Accuracy: 11749/60000 (19.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0380,                   Accuracy: 11442/60000 (19.07%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.5628,                   Accuracy: 12071/60000 (20.12%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.1769,                   Accuracy: 12039/60000 (20.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6117,                   Accuracy: 13729/60000 (22.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5361,                   Accuracy: 21096/60000 (35.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1155,                   Accuracy: 33570/60000 (55.95%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9373,                   Accuracy: 46323/60000 (77.21%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2953,                   Accuracy: 55061/60000 (91.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0908,                   Accuracy: 58439/60000 (97.40%)
{0: tensor(98.3817), 10: tensor(97.3383), 20: tensor(94.2450), 30: tensor(84.4133), 40: tensor(67.7333), 50: tensor(50.1400), 60: tensor(34.6633), 70: tensor(24.3917), 80: tensor(19.6783), 90: tensor(19.2900), 100: tensor(19.3183), 110: tensor(19.2300), 120: tensor(21.8933), 130: tensor(25.4600), 140: tensor(30.3933), 150: tensor(37.0583), 160: tensor(42.1750), 170: tensor(44.8767), 180: tensor(45.5433), 190: tensor(45.9567), 200: tensor(42.7350), 210: tensor(37.0300), 220: tensor(30.5933), 230: tensor(26.0617), 240: tensor(22.4133), 250: tensor(20.2700), 260: tensor(19.5817), 270: tensor(19.0700), 280: tensor(20.1183), 290: tensor(20.0650), 300: tensor(22.8817), 310: tensor(35.1600), 320: tensor(55.9500), 330: tensor(77.2050), 340: tensor(91.7683), 350: tensor(97.3983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=23, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.0539,                   Accuracy: 1334/2000.0 (66.70%)



-= Testing valid =-
Test set: Average loss: 0.5592,                   Accuracy: 1613/2000.0 (80.65%)



-= Testing valid =-
Test set: Average loss: 0.5092,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.1389,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1466,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.3286,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.1807,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 97.76%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 98.89%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 98.99%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0703,                   Accuracy: 58813/60000 (98.02%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1362,                   Accuracy: 57782/60000 (96.30%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3403,                   Accuracy: 54566/60000 (90.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.8289,                   Accuracy: 47330/60000 (78.88%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.7350,                   Accuracy: 36745/60000 (61.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.8853,                   Accuracy: 26904/60000 (44.84%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.0942,                   Accuracy: 19054/60000 (31.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9439,                   Accuracy: 14449/60000 (24.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4134,                   Accuracy: 12018/60000 (20.03%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7143,                   Accuracy: 11290/60000 (18.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8454,                   Accuracy: 10538/60000 (17.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1912,                   Accuracy: 10333/60000 (17.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.3300,                   Accuracy: 11551/60000 (19.25%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.3941,                   Accuracy: 14010/60000 (23.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.4674,                   Accuracy: 17020/60000 (28.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.4924,                   Accuracy: 20799/60000 (34.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.6354,                   Accuracy: 24187/60000 (40.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.6753,                   Accuracy: 27570/60000 (45.95%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1686,                   Accuracy: 28265/60000 (47.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.2061,                   Accuracy: 27462/60000 (45.77%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.2121,                   Accuracy: 25254/60000 (42.09%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.9132,                   Accuracy: 21636/60000 (36.06%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7600,                   Accuracy: 17940/60000 (29.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7109,                   Accuracy: 15478/60000 (25.80%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7866,                   Accuracy: 12967/60000 (21.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.9564,                   Accuracy: 11443/60000 (19.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.9659,                   Accuracy: 11206/60000 (18.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.8051,                   Accuracy: 10739/60000 (17.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2506,                   Accuracy: 10330/60000 (17.22%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6496,                   Accuracy: 11091/60000 (18.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7544,                   Accuracy: 13077/60000 (21.80%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5555,                   Accuracy: 20111/60000 (33.52%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1652,                   Accuracy: 31455/60000 (52.42%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0275,                   Accuracy: 43886/60000 (73.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3875,                   Accuracy: 53156/60000 (88.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1191,                   Accuracy: 57949/60000 (96.58%)
{0: tensor(98.0217), 10: tensor(96.3033), 20: tensor(90.9433), 30: tensor(78.8833), 40: tensor(61.2417), 50: tensor(44.8400), 60: tensor(31.7567), 70: tensor(24.0817), 80: tensor(20.0300), 90: tensor(18.8167), 100: tensor(17.5633), 110: tensor(17.2217), 120: tensor(19.2517), 130: tensor(23.3500), 140: tensor(28.3667), 150: tensor(34.6650), 160: tensor(40.3117), 170: tensor(45.9500), 180: tensor(47.1083), 190: tensor(45.7700), 200: tensor(42.0900), 210: tensor(36.0600), 220: tensor(29.9000), 230: tensor(25.7967), 240: tensor(21.6117), 250: tensor(19.0717), 260: tensor(18.6767), 270: tensor(17.8983), 280: tensor(17.2167), 290: tensor(18.4850), 300: tensor(21.7950), 310: tensor(33.5183), 320: tensor(52.4250), 330: tensor(73.1433), 340: tensor(88.5933), 350: tensor(96.5817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=24, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5267,                   Accuracy: 447/2000.0 (22.35%)



-= Testing valid =-
Test set: Average loss: 0.6779,                   Accuracy: 1550/2000.0 (77.50%)



-= Testing valid =-
Test set: Average loss: 0.3152,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2430,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2802,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 10 train accuracy: 98.09%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 20 train accuracy: 99.01%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.41%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0532,                   Accuracy: 59095/60000 (98.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0856,                   Accuracy: 58531/60000 (97.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2187,                   Accuracy: 56469/60000 (94.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6782,                   Accuracy: 49891/60000 (83.15%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.6316,                   Accuracy: 38656/60000 (64.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.9042,                   Accuracy: 28077/60000 (46.79%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.4891,                   Accuracy: 18542/60000 (30.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.3651,                   Accuracy: 13990/60000 (23.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.9974,                   Accuracy: 11316/60000 (18.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.6046,                   Accuracy: 10371/60000 (17.28%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.4320,                   Accuracy: 11550/60000 (19.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.2790,                   Accuracy: 10985/60000 (18.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.3185,                   Accuracy: 11568/60000 (19.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0892,                   Accuracy: 13890/60000 (23.15%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7338,                   Accuracy: 17201/60000 (28.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.5215,                   Accuracy: 21359/60000 (35.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.6029,                   Accuracy: 24892/60000 (41.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.7989,                   Accuracy: 26451/60000 (44.08%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.2429,                   Accuracy: 26542/60000 (44.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.3241,                   Accuracy: 26293/60000 (43.82%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4686,                   Accuracy: 24503/60000 (40.84%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5354,                   Accuracy: 21543/60000 (35.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7083,                   Accuracy: 18395/60000 (30.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.8391,                   Accuracy: 16548/60000 (27.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.0562,                   Accuracy: 14628/60000 (24.38%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.1099,                   Accuracy: 13492/60000 (22.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 7.0598,                   Accuracy: 12550/60000 (20.92%)
-= Testing Rotation 270 =-
Test set: Average loss: 7.1539,                   Accuracy: 10917/60000 (18.19%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.5103,                   Accuracy: 10433/60000 (17.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7916,                   Accuracy: 10470/60000 (17.45%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0020,                   Accuracy: 11728/60000 (19.55%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6469,                   Accuracy: 19415/60000 (32.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1613,                   Accuracy: 31517/60000 (52.53%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9339,                   Accuracy: 45640/60000 (76.07%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2671,                   Accuracy: 55353/60000 (92.25%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0802,                   Accuracy: 58533/60000 (97.56%)
{0: tensor(98.4917), 10: tensor(97.5517), 20: tensor(94.1150), 30: tensor(83.1517), 40: tensor(64.4267), 50: tensor(46.7950), 60: tensor(30.9033), 70: tensor(23.3167), 80: tensor(18.8600), 90: tensor(17.2850), 100: tensor(19.2500), 110: tensor(18.3083), 120: tensor(19.2800), 130: tensor(23.1500), 140: tensor(28.6683), 150: tensor(35.5983), 160: tensor(41.4867), 170: tensor(44.0850), 180: tensor(44.2367), 190: tensor(43.8217), 200: tensor(40.8383), 210: tensor(35.9050), 220: tensor(30.6583), 230: tensor(27.5800), 240: tensor(24.3800), 250: tensor(22.4867), 260: tensor(20.9167), 270: tensor(18.1950), 280: tensor(17.3883), 290: tensor(17.4500), 300: tensor(19.5467), 310: tensor(32.3583), 320: tensor(52.5283), 330: tensor(76.0667), 340: tensor(92.2550), 350: tensor(97.5550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=25, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7197,                   Accuracy: 814/2000.0 (40.70%)



-= Testing valid =-
Test set: Average loss: 0.4960,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.2310,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1885,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1484,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 10 train accuracy: 98.10%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 20 train accuracy: 98.96%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 30 train accuracy: 99.43%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 40 train accuracy: 99.50%, valid accuracy 99.40%
-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1989/2000.0 (99.45%)



Epoch 50 train accuracy: 99.61%, valid accuracy 99.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0455,                   Accuracy: 59245/60000 (98.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0735,                   Accuracy: 58763/60000 (97.94%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1764,                   Accuracy: 57098/60000 (95.16%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5135,                   Accuracy: 51815/60000 (86.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2091,                   Accuracy: 42385/60000 (70.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2401,                   Accuracy: 32164/60000 (53.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.4551,                   Accuracy: 22787/60000 (37.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.4993,                   Accuracy: 16240/60000 (27.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1910,                   Accuracy: 12650/60000 (21.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.9028,                   Accuracy: 11325/60000 (18.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.1926,                   Accuracy: 10389/60000 (17.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.5643,                   Accuracy: 10967/60000 (18.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.8341,                   Accuracy: 12676/60000 (21.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.7517,                   Accuracy: 15654/60000 (26.09%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.7115,                   Accuracy: 19016/60000 (31.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.7400,                   Accuracy: 22339/60000 (37.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.9980,                   Accuracy: 24758/60000 (41.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.4463,                   Accuracy: 25841/60000 (43.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.9662,                   Accuracy: 26013/60000 (43.35%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.6713,                   Accuracy: 26129/60000 (43.55%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.7562,                   Accuracy: 24798/60000 (41.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.6649,                   Accuracy: 21962/60000 (36.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.3647,                   Accuracy: 19415/60000 (32.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 7.2229,                   Accuracy: 16892/60000 (28.15%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.0319,                   Accuracy: 14841/60000 (24.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8909,                   Accuracy: 13082/60000 (21.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.7727,                   Accuracy: 11417/60000 (19.03%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.9350,                   Accuracy: 9807/60000 (16.34%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.6591,                   Accuracy: 8795/60000 (14.66%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.0944,                   Accuracy: 8877/60000 (14.80%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.1056,                   Accuracy: 12272/60000 (20.45%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6046,                   Accuracy: 20831/60000 (34.72%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0220,                   Accuracy: 33898/60000 (56.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8298,                   Accuracy: 47623/60000 (79.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2297,                   Accuracy: 56129/60000 (93.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0717,                   Accuracy: 58765/60000 (97.94%)
{0: tensor(98.7417), 10: tensor(97.9383), 20: tensor(95.1633), 30: tensor(86.3583), 40: tensor(70.6417), 50: tensor(53.6067), 60: tensor(37.9783), 70: tensor(27.0667), 80: tensor(21.0833), 90: tensor(18.8750), 100: tensor(17.3150), 110: tensor(18.2783), 120: tensor(21.1267), 130: tensor(26.0900), 140: tensor(31.6933), 150: tensor(37.2317), 160: tensor(41.2633), 170: tensor(43.0683), 180: tensor(43.3550), 190: tensor(43.5483), 200: tensor(41.3300), 210: tensor(36.6033), 220: tensor(32.3583), 230: tensor(28.1533), 240: tensor(24.7350), 250: tensor(21.8033), 260: tensor(19.0283), 270: tensor(16.3450), 280: tensor(14.6583), 290: tensor(14.7950), 300: tensor(20.4533), 310: tensor(34.7183), 320: tensor(56.4967), 330: tensor(79.3717), 340: tensor(93.5483), 350: tensor(97.9417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=26, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9175,                   Accuracy: 588/2000.0 (29.40%)



-= Testing valid =-
Test set: Average loss: 0.6232,                   Accuracy: 1612/2000.0 (80.60%)



-= Testing valid =-
Test set: Average loss: 0.1466,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.3021,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1593,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 10 train accuracy: 97.90%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 98.90%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.56%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0560,                   Accuracy: 59056/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0815,                   Accuracy: 58624/60000 (97.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2020,                   Accuracy: 56648/60000 (94.41%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6003,                   Accuracy: 50594/60000 (84.32%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3850,                   Accuracy: 40374/60000 (67.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4458,                   Accuracy: 29969/60000 (49.95%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6675,                   Accuracy: 20101/60000 (33.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5352,                   Accuracy: 13526/60000 (22.54%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1442,                   Accuracy: 10463/60000 (17.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7219,                   Accuracy: 8757/60000 (14.60%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.6742,                   Accuracy: 8865/60000 (14.77%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9482,                   Accuracy: 9371/60000 (15.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0857,                   Accuracy: 10652/60000 (17.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0326,                   Accuracy: 13298/60000 (22.16%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8959,                   Accuracy: 16924/60000 (28.21%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9697,                   Accuracy: 20933/60000 (34.89%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1817,                   Accuracy: 23904/60000 (39.84%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5829,                   Accuracy: 25563/60000 (42.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.2435,                   Accuracy: 25611/60000 (42.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.0070,                   Accuracy: 25766/60000 (42.94%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.8752,                   Accuracy: 24461/60000 (40.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.7221,                   Accuracy: 21483/60000 (35.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3897,                   Accuracy: 18766/60000 (31.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3976,                   Accuracy: 16299/60000 (27.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.4260,                   Accuracy: 13834/60000 (23.06%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.2660,                   Accuracy: 12039/60000 (20.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0219,                   Accuracy: 11209/60000 (18.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.2321,                   Accuracy: 9950/60000 (16.58%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.7797,                   Accuracy: 8597/60000 (14.33%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4002,                   Accuracy: 8119/60000 (13.53%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7533,                   Accuracy: 11022/60000 (18.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5981,                   Accuracy: 19529/60000 (32.55%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2349,                   Accuracy: 32417/60000 (54.03%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0607,                   Accuracy: 45395/60000 (75.66%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3346,                   Accuracy: 54546/60000 (90.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0875,                   Accuracy: 58441/60000 (97.40%)
{0: tensor(98.4267), 10: tensor(97.7067), 20: tensor(94.4133), 30: tensor(84.3233), 40: tensor(67.2900), 50: tensor(49.9483), 60: tensor(33.5017), 70: tensor(22.5433), 80: tensor(17.4383), 90: tensor(14.5950), 100: tensor(14.7750), 110: tensor(15.6183), 120: tensor(17.7533), 130: tensor(22.1633), 140: tensor(28.2067), 150: tensor(34.8883), 160: tensor(39.8400), 170: tensor(42.6050), 180: tensor(42.6850), 190: tensor(42.9433), 200: tensor(40.7683), 210: tensor(35.8050), 220: tensor(31.2767), 230: tensor(27.1650), 240: tensor(23.0567), 250: tensor(20.0650), 260: tensor(18.6817), 270: tensor(16.5833), 280: tensor(14.3283), 290: tensor(13.5317), 300: tensor(18.3700), 310: tensor(32.5483), 320: tensor(54.0283), 330: tensor(75.6583), 340: tensor(90.9100), 350: tensor(97.4017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=27, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.1994,                   Accuracy: 1312/2000.0 (65.60%)



-= Testing valid =-
Test set: Average loss: 0.2837,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1916,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.3139,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2075,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1739,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 10 train accuracy: 97.86%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 20 train accuracy: 98.89%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 30 train accuracy: 99.16%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.55%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.50%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0635,                   Accuracy: 58904/60000 (98.17%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0972,                   Accuracy: 58376/60000 (97.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2369,                   Accuracy: 56247/60000 (93.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6912,                   Accuracy: 49605/60000 (82.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5334,                   Accuracy: 39665/60000 (66.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6975,                   Accuracy: 28278/60000 (47.13%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8773,                   Accuracy: 19501/60000 (32.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5999,                   Accuracy: 14238/60000 (23.73%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9517,                   Accuracy: 11606/60000 (19.34%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.3191,                   Accuracy: 11571/60000 (19.28%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.0883,                   Accuracy: 10788/60000 (17.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.1330,                   Accuracy: 10970/60000 (18.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.3556,                   Accuracy: 12859/60000 (21.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7147,                   Accuracy: 15487/60000 (25.81%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9333,                   Accuracy: 19548/60000 (32.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1738,                   Accuracy: 23720/60000 (39.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2576,                   Accuracy: 26284/60000 (43.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.3862,                   Accuracy: 27330/60000 (45.55%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.4718,                   Accuracy: 27555/60000 (45.92%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.0672,                   Accuracy: 27095/60000 (45.16%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.7563,                   Accuracy: 25000/60000 (41.67%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.5547,                   Accuracy: 21589/60000 (35.98%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.5834,                   Accuracy: 18390/60000 (30.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.7584,                   Accuracy: 15352/60000 (25.59%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1618,                   Accuracy: 12324/60000 (20.54%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0808,                   Accuracy: 11165/60000 (18.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0715,                   Accuracy: 10683/60000 (17.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.1600,                   Accuracy: 9560/60000 (15.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.4735,                   Accuracy: 10138/60000 (16.90%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.8852,                   Accuracy: 11364/60000 (18.94%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.1364,                   Accuracy: 15621/60000 (26.03%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.0726,                   Accuracy: 24137/60000 (40.23%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8396,                   Accuracy: 36005/60000 (60.01%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7997,                   Accuracy: 47937/60000 (79.89%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2720,                   Accuracy: 55418/60000 (92.36%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0915,                   Accuracy: 58371/60000 (97.29%)
{0: tensor(98.1733), 10: tensor(97.2933), 20: tensor(93.7450), 30: tensor(82.6750), 40: tensor(66.1083), 50: tensor(47.1300), 60: tensor(32.5017), 70: tensor(23.7300), 80: tensor(19.3433), 90: tensor(19.2850), 100: tensor(17.9800), 110: tensor(18.2833), 120: tensor(21.4317), 130: tensor(25.8117), 140: tensor(32.5800), 150: tensor(39.5333), 160: tensor(43.8067), 170: tensor(45.5500), 180: tensor(45.9250), 190: tensor(45.1583), 200: tensor(41.6667), 210: tensor(35.9817), 220: tensor(30.6500), 230: tensor(25.5867), 240: tensor(20.5400), 250: tensor(18.6083), 260: tensor(17.8050), 270: tensor(15.9333), 280: tensor(16.8967), 290: tensor(18.9400), 300: tensor(26.0350), 310: tensor(40.2283), 320: tensor(60.0083), 330: tensor(79.8950), 340: tensor(92.3633), 350: tensor(97.2850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=28, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.5016,                   Accuracy: 754/2000.0 (37.70%)



-= Testing valid =-
Test set: Average loss: 1.2003,                   Accuracy: 1295/2000.0 (64.75%)



-= Testing valid =-
Test set: Average loss: 0.4247,                   Accuracy: 1722/2000.0 (86.10%)



-= Testing valid =-
Test set: Average loss: 0.5987,                   Accuracy: 1580/2000.0 (79.00%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.3192,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.4154,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.1373,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 10 train accuracy: 97.32%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 98.66%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 30 train accuracy: 99.26%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 99.35%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.53%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0813,                   Accuracy: 58602/60000 (97.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1205,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2967,                   Accuracy: 54957/60000 (91.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.8790,                   Accuracy: 46512/60000 (77.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.9457,                   Accuracy: 34114/60000 (56.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 3.2950,                   Accuracy: 23296/60000 (38.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.6454,                   Accuracy: 15679/60000 (26.13%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.3413,                   Accuracy: 11900/60000 (19.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.7773,                   Accuracy: 10677/60000 (17.80%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.1164,                   Accuracy: 11165/60000 (18.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0218,                   Accuracy: 11823/60000 (19.70%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1982,                   Accuracy: 11697/60000 (19.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.2149,                   Accuracy: 12834/60000 (21.39%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0473,                   Accuracy: 15777/60000 (26.30%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8436,                   Accuracy: 19614/60000 (32.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6731,                   Accuracy: 23697/60000 (39.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.5597,                   Accuracy: 26736/60000 (44.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.6481,                   Accuracy: 28945/60000 (48.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.0000,                   Accuracy: 29278/60000 (48.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.8508,                   Accuracy: 28633/60000 (47.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.8984,                   Accuracy: 26828/60000 (44.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.0246,                   Accuracy: 22911/60000 (38.19%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1684,                   Accuracy: 19039/60000 (31.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4538,                   Accuracy: 16606/60000 (27.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6751,                   Accuracy: 14023/60000 (23.37%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6686,                   Accuracy: 12647/60000 (21.08%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6481,                   Accuracy: 11874/60000 (19.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.8067,                   Accuracy: 10829/60000 (18.05%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.3381,                   Accuracy: 10750/60000 (17.92%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.9316,                   Accuracy: 11450/60000 (19.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.3130,                   Accuracy: 14100/60000 (23.50%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.9829,                   Accuracy: 21366/60000 (35.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.5155,                   Accuracy: 32002/60000 (53.34%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.2598,                   Accuracy: 43829/60000 (73.05%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.4584,                   Accuracy: 52900/60000 (88.17%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1307,                   Accuracy: 57726/60000 (96.21%)
{0: tensor(97.6700), 10: tensor(96.5283), 20: tensor(91.5950), 30: tensor(77.5200), 40: tensor(56.8567), 50: tensor(38.8267), 60: tensor(26.1317), 70: tensor(19.8333), 80: tensor(17.7950), 90: tensor(18.6083), 100: tensor(19.7050), 110: tensor(19.4950), 120: tensor(21.3900), 130: tensor(26.2950), 140: tensor(32.6900), 150: tensor(39.4950), 160: tensor(44.5600), 170: tensor(48.2417), 180: tensor(48.7967), 190: tensor(47.7217), 200: tensor(44.7133), 210: tensor(38.1850), 220: tensor(31.7317), 230: tensor(27.6767), 240: tensor(23.3717), 250: tensor(21.0783), 260: tensor(19.7900), 270: tensor(18.0483), 280: tensor(17.9167), 290: tensor(19.0833), 300: tensor(23.5000), 310: tensor(35.6100), 320: tensor(53.3367), 330: tensor(73.0483), 340: tensor(88.1667), 350: tensor(96.2100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=29, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.1866,                   Accuracy: 1037/2000.0 (51.85%)



-= Testing valid =-
Test set: Average loss: 0.5346,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.2698,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2068,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.2459,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 10 train accuracy: 97.66%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 98.54%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.38%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.61%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0503,                   Accuracy: 59089/60000 (98.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1001,                   Accuracy: 58239/60000 (97.07%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2058,                   Accuracy: 56548/60000 (94.25%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5720,                   Accuracy: 50825/60000 (84.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3592,                   Accuracy: 40883/60000 (68.14%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4452,                   Accuracy: 30063/60000 (50.10%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8271,                   Accuracy: 18962/60000 (31.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.6592,                   Accuracy: 12718/60000 (21.20%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4679,                   Accuracy: 8887/60000 (14.81%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.1647,                   Accuracy: 8512/60000 (14.19%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.1803,                   Accuracy: 9894/60000 (16.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.5234,                   Accuracy: 11295/60000 (18.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.6448,                   Accuracy: 13062/60000 (21.77%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.3519,                   Accuracy: 16356/60000 (27.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.1501,                   Accuracy: 19552/60000 (32.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1852,                   Accuracy: 22495/60000 (37.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2982,                   Accuracy: 24689/60000 (41.15%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.7217,                   Accuracy: 26004/60000 (43.34%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.3816,                   Accuracy: 26580/60000 (44.30%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.9903,                   Accuracy: 25890/60000 (43.15%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.8096,                   Accuracy: 24914/60000 (41.52%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.7314,                   Accuracy: 23287/60000 (38.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1023,                   Accuracy: 20252/60000 (33.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9133,                   Accuracy: 17239/60000 (28.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.9451,                   Accuracy: 14645/60000 (24.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.8452,                   Accuracy: 12921/60000 (21.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0713,                   Accuracy: 11556/60000 (19.26%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4257,                   Accuracy: 11088/60000 (18.48%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.1166,                   Accuracy: 9388/60000 (15.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4906,                   Accuracy: 10311/60000 (17.18%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6705,                   Accuracy: 13618/60000 (22.70%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3201,                   Accuracy: 22185/60000 (36.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9719,                   Accuracy: 34228/60000 (57.05%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9090,                   Accuracy: 46150/60000 (76.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3007,                   Accuracy: 54616/60000 (91.03%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1043,                   Accuracy: 58115/60000 (96.86%)
{0: tensor(98.4817), 10: tensor(97.0650), 20: tensor(94.2467), 30: tensor(84.7083), 40: tensor(68.1383), 50: tensor(50.1050), 60: tensor(31.6033), 70: tensor(21.1967), 80: tensor(14.8117), 90: tensor(14.1867), 100: tensor(16.4900), 110: tensor(18.8250), 120: tensor(21.7700), 130: tensor(27.2600), 140: tensor(32.5867), 150: tensor(37.4917), 160: tensor(41.1483), 170: tensor(43.3400), 180: tensor(44.3000), 190: tensor(43.1500), 200: tensor(41.5233), 210: tensor(38.8117), 220: tensor(33.7533), 230: tensor(28.7317), 240: tensor(24.4083), 250: tensor(21.5350), 260: tensor(19.2600), 270: tensor(18.4800), 280: tensor(15.6467), 290: tensor(17.1850), 300: tensor(22.6967), 310: tensor(36.9750), 320: tensor(57.0467), 330: tensor(76.9167), 340: tensor(91.0267), 350: tensor(96.8583)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=30, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9607,                   Accuracy: 735/2000.0 (36.75%)



-= Testing valid =-
Test set: Average loss: 0.6225,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.4161,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.3433,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.1883,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.7584,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.3267,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.1427,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 97.64%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 98.72%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 30 train accuracy: 99.36%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.53%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.65%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0559,                   Accuracy: 59030/60000 (98.38%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0901,                   Accuracy: 58488/60000 (97.48%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2257,                   Accuracy: 56344/60000 (93.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6280,                   Accuracy: 50222/60000 (83.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4569,                   Accuracy: 39486/60000 (65.81%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6866,                   Accuracy: 27113/60000 (45.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9543,                   Accuracy: 17341/60000 (28.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8387,                   Accuracy: 11449/60000 (19.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.2700,                   Accuracy: 9269/60000 (15.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4054,                   Accuracy: 9344/60000 (15.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.1097,                   Accuracy: 9989/60000 (16.65%)
-= Testing Rotation 110 =-
Test set: Average loss: 4.9352,                   Accuracy: 10629/60000 (17.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 4.9002,                   Accuracy: 12176/60000 (20.29%)
-= Testing Rotation 130 =-
Test set: Average loss: 4.9375,                   Accuracy: 15170/60000 (25.28%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.1615,                   Accuracy: 18873/60000 (31.45%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4892,                   Accuracy: 22587/60000 (37.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.7794,                   Accuracy: 25679/60000 (42.80%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.9458,                   Accuracy: 27261/60000 (45.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.2874,                   Accuracy: 27902/60000 (46.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.0755,                   Accuracy: 27758/60000 (46.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.9333,                   Accuracy: 26444/60000 (44.07%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.7504,                   Accuracy: 23665/60000 (39.44%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.6340,                   Accuracy: 20063/60000 (33.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.6920,                   Accuracy: 17280/60000 (28.80%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.9103,                   Accuracy: 15385/60000 (25.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0639,                   Accuracy: 13926/60000 (23.21%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0992,                   Accuracy: 12991/60000 (21.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.2439,                   Accuracy: 11160/60000 (18.60%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9119,                   Accuracy: 9816/60000 (16.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4079,                   Accuracy: 9293/60000 (15.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7392,                   Accuracy: 11507/60000 (19.18%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6436,                   Accuracy: 19035/60000 (31.73%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1706,                   Accuracy: 32008/60000 (53.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9482,                   Accuracy: 45820/60000 (76.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2859,                   Accuracy: 55196/60000 (91.99%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0843,                   Accuracy: 58441/60000 (97.40%)
{0: tensor(98.3833), 10: tensor(97.4800), 20: tensor(93.9067), 30: tensor(83.7033), 40: tensor(65.8100), 50: tensor(45.1883), 60: tensor(28.9017), 70: tensor(19.0817), 80: tensor(15.4483), 90: tensor(15.5733), 100: tensor(16.6483), 110: tensor(17.7150), 120: tensor(20.2933), 130: tensor(25.2833), 140: tensor(31.4550), 150: tensor(37.6450), 160: tensor(42.7983), 170: tensor(45.4350), 180: tensor(46.5033), 190: tensor(46.2633), 200: tensor(44.0733), 210: tensor(39.4417), 220: tensor(33.4383), 230: tensor(28.8000), 240: tensor(25.6417), 250: tensor(23.2100), 260: tensor(21.6517), 270: tensor(18.6000), 280: tensor(16.3600), 290: tensor(15.4883), 300: tensor(19.1783), 310: tensor(31.7250), 320: tensor(53.3467), 330: tensor(76.3667), 340: tensor(91.9933), 350: tensor(97.4017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=31, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2238,                   Accuracy: 309/2000.0 (15.45%)



-= Testing valid =-
Test set: Average loss: 1.1389,                   Accuracy: 1302/2000.0 (65.10%)



-= Testing valid =-
Test set: Average loss: 0.3043,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.1801,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1367,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.2213,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 10 train accuracy: 97.57%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 20 train accuracy: 98.90%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.29%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.46%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.60%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0492,                   Accuracy: 59172/60000 (98.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0866,                   Accuracy: 58546/60000 (97.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2306,                   Accuracy: 56350/60000 (93.92%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6620,                   Accuracy: 50346/60000 (83.91%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4899,                   Accuracy: 40589/60000 (67.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6544,                   Accuracy: 29745/60000 (49.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.0452,                   Accuracy: 19839/60000 (33.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.0531,                   Accuracy: 14536/60000 (24.23%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.6560,                   Accuracy: 12224/60000 (20.37%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.0265,                   Accuracy: 11898/60000 (19.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9279,                   Accuracy: 12335/60000 (20.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9862,                   Accuracy: 12481/60000 (20.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0293,                   Accuracy: 12974/60000 (21.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.1091,                   Accuracy: 14807/60000 (24.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.1815,                   Accuracy: 17449/60000 (29.08%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.2398,                   Accuracy: 21155/60000 (35.26%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.4938,                   Accuracy: 24482/60000 (40.80%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.8928,                   Accuracy: 26692/60000 (44.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.2333,                   Accuracy: 27382/60000 (45.64%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.1468,                   Accuracy: 27169/60000 (45.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.2818,                   Accuracy: 25541/60000 (42.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.0053,                   Accuracy: 22011/60000 (36.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.8350,                   Accuracy: 18587/60000 (30.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.8146,                   Accuracy: 15769/60000 (26.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7965,                   Accuracy: 13029/60000 (21.72%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7282,                   Accuracy: 11544/60000 (19.24%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5247,                   Accuracy: 10942/60000 (18.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3934,                   Accuracy: 9781/60000 (16.30%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9893,                   Accuracy: 9438/60000 (15.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.5753,                   Accuracy: 9685/60000 (16.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7574,                   Accuracy: 12021/60000 (20.03%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6213,                   Accuracy: 19261/60000 (32.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2272,                   Accuracy: 31586/60000 (52.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9871,                   Accuracy: 45302/60000 (75.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3154,                   Accuracy: 54675/60000 (91.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0828,                   Accuracy: 58560/60000 (97.60%)
{0: tensor(98.6200), 10: tensor(97.5767), 20: tensor(93.9167), 30: tensor(83.9100), 40: tensor(67.6483), 50: tensor(49.5750), 60: tensor(33.0650), 70: tensor(24.2267), 80: tensor(20.3733), 90: tensor(19.8300), 100: tensor(20.5583), 110: tensor(20.8017), 120: tensor(21.6233), 130: tensor(24.6783), 140: tensor(29.0817), 150: tensor(35.2583), 160: tensor(40.8033), 170: tensor(44.4867), 180: tensor(45.6367), 190: tensor(45.2817), 200: tensor(42.5683), 210: tensor(36.6850), 220: tensor(30.9783), 230: tensor(26.2817), 240: tensor(21.7150), 250: tensor(19.2400), 260: tensor(18.2367), 270: tensor(16.3017), 280: tensor(15.7300), 290: tensor(16.1417), 300: tensor(20.0350), 310: tensor(32.1017), 320: tensor(52.6433), 330: tensor(75.5033), 340: tensor(91.1250), 350: tensor(97.6000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=32, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.4907,                   Accuracy: 792/2000.0 (39.60%)



-= Testing valid =-
Test set: Average loss: 0.7728,                   Accuracy: 1513/2000.0 (75.65%)



-= Testing valid =-
Test set: Average loss: 0.2189,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.2778,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 97.47%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.91%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 30 train accuracy: 99.28%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.50%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.53%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0548,                   Accuracy: 59090/60000 (98.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0866,                   Accuracy: 58548/60000 (97.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2289,                   Accuracy: 56376/60000 (93.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6737,                   Accuracy: 50018/60000 (83.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5872,                   Accuracy: 39292/60000 (65.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.8586,                   Accuracy: 27863/60000 (46.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.1919,                   Accuracy: 18746/60000 (31.24%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.0429,                   Accuracy: 13108/60000 (21.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.6809,                   Accuracy: 10007/60000 (16.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.0436,                   Accuracy: 10730/60000 (17.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0631,                   Accuracy: 11362/60000 (18.94%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1824,                   Accuracy: 11856/60000 (19.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.3409,                   Accuracy: 12743/60000 (21.24%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0935,                   Accuracy: 14844/60000 (24.74%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9155,                   Accuracy: 17427/60000 (29.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7173,                   Accuracy: 20600/60000 (34.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.8151,                   Accuracy: 24205/60000 (40.34%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.1186,                   Accuracy: 26555/60000 (44.26%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6666,                   Accuracy: 26857/60000 (44.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5104,                   Accuracy: 27222/60000 (45.37%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4824,                   Accuracy: 25559/60000 (42.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5219,                   Accuracy: 22587/60000 (37.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7008,                   Accuracy: 18895/60000 (31.49%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.9455,                   Accuracy: 15697/60000 (26.16%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.1954,                   Accuracy: 13035/60000 (21.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.1960,                   Accuracy: 11511/60000 (19.18%)
-= Testing Rotation 260 =-
Test set: Average loss: 7.0286,                   Accuracy: 10894/60000 (18.16%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.8782,                   Accuracy: 10580/60000 (17.63%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2336,                   Accuracy: 10675/60000 (17.79%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6189,                   Accuracy: 11261/60000 (18.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.8485,                   Accuracy: 12660/60000 (21.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5968,                   Accuracy: 19225/60000 (32.04%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1544,                   Accuracy: 30831/60000 (51.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9640,                   Accuracy: 44586/60000 (74.31%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2850,                   Accuracy: 54946/60000 (91.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0845,                   Accuracy: 58524/60000 (97.54%)
{0: tensor(98.4833), 10: tensor(97.5800), 20: tensor(93.9600), 30: tensor(83.3633), 40: tensor(65.4867), 50: tensor(46.4383), 60: tensor(31.2433), 70: tensor(21.8467), 80: tensor(16.6783), 90: tensor(17.8833), 100: tensor(18.9367), 110: tensor(19.7600), 120: tensor(21.2383), 130: tensor(24.7400), 140: tensor(29.0450), 150: tensor(34.3333), 160: tensor(40.3417), 170: tensor(44.2583), 180: tensor(44.7617), 190: tensor(45.3700), 200: tensor(42.5983), 210: tensor(37.6450), 220: tensor(31.4917), 230: tensor(26.1617), 240: tensor(21.7250), 250: tensor(19.1850), 260: tensor(18.1567), 270: tensor(17.6333), 280: tensor(17.7917), 290: tensor(18.7683), 300: tensor(21.1000), 310: tensor(32.0417), 320: tensor(51.3850), 330: tensor(74.3100), 340: tensor(91.5767), 350: tensor(97.5400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=33, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3447,                   Accuracy: 1062/2000.0 (53.10%)



-= Testing valid =-
Test set: Average loss: 0.3521,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2488,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1717,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1953,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.1437,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 10 train accuracy: 97.66%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.24%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.50%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0557,                   Accuracy: 59063/60000 (98.44%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0953,                   Accuracy: 58461/60000 (97.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2531,                   Accuracy: 56138/60000 (93.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6893,                   Accuracy: 49762/60000 (82.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5005,                   Accuracy: 39985/60000 (66.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6353,                   Accuracy: 29310/60000 (48.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8549,                   Accuracy: 20521/60000 (34.20%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8278,                   Accuracy: 14326/60000 (23.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.3424,                   Accuracy: 11136/60000 (18.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.8415,                   Accuracy: 10448/60000 (17.41%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9545,                   Accuracy: 11209/60000 (18.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.3325,                   Accuracy: 11037/60000 (18.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.5880,                   Accuracy: 12861/60000 (21.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.5548,                   Accuracy: 15876/60000 (26.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.4104,                   Accuracy: 19724/60000 (32.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.3682,                   Accuracy: 24099/60000 (40.17%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.5709,                   Accuracy: 26814/60000 (44.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.7839,                   Accuracy: 27824/60000 (46.37%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.2365,                   Accuracy: 27988/60000 (46.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8378,                   Accuracy: 27534/60000 (45.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.9163,                   Accuracy: 25742/60000 (42.90%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.0267,                   Accuracy: 22835/60000 (38.06%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.8677,                   Accuracy: 19813/60000 (33.02%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7745,                   Accuracy: 17133/60000 (28.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.9455,                   Accuracy: 14348/60000 (23.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.0145,                   Accuracy: 12550/60000 (20.92%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.7853,                   Accuracy: 11261/60000 (18.77%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.7627,                   Accuracy: 10446/60000 (17.41%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.1453,                   Accuracy: 9344/60000 (15.57%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.5411,                   Accuracy: 9843/60000 (16.41%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.3776,                   Accuracy: 13394/60000 (22.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.1194,                   Accuracy: 21662/60000 (36.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.7147,                   Accuracy: 35143/60000 (58.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7176,                   Accuracy: 48235/60000 (80.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2172,                   Accuracy: 56178/60000 (93.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0795,                   Accuracy: 58618/60000 (97.70%)
{0: tensor(98.4383), 10: tensor(97.4350), 20: tensor(93.5633), 30: tensor(82.9367), 40: tensor(66.6417), 50: tensor(48.8500), 60: tensor(34.2017), 70: tensor(23.8767), 80: tensor(18.5600), 90: tensor(17.4133), 100: tensor(18.6817), 110: tensor(18.3950), 120: tensor(21.4350), 130: tensor(26.4600), 140: tensor(32.8733), 150: tensor(40.1650), 160: tensor(44.6900), 170: tensor(46.3733), 180: tensor(46.6467), 190: tensor(45.8900), 200: tensor(42.9033), 210: tensor(38.0583), 220: tensor(33.0217), 230: tensor(28.5550), 240: tensor(23.9133), 250: tensor(20.9167), 260: tensor(18.7683), 270: tensor(17.4100), 280: tensor(15.5733), 290: tensor(16.4050), 300: tensor(22.3233), 310: tensor(36.1033), 320: tensor(58.5717), 330: tensor(80.3917), 340: tensor(93.6300), 350: tensor(97.6967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=34, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0173,                   Accuracy: 675/2000.0 (33.75%)



-= Testing valid =-
Test set: Average loss: 0.3240,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2766,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.3496,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.1341,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 10 train accuracy: 97.53%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 98.84%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.26%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.46%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.62%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0588,                   Accuracy: 59006/60000 (98.34%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0922,                   Accuracy: 58452/60000 (97.42%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2522,                   Accuracy: 56085/60000 (93.47%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6791,                   Accuracy: 50254/60000 (83.76%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5279,                   Accuracy: 40397/60000 (67.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7032,                   Accuracy: 29720/60000 (49.53%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9876,                   Accuracy: 21016/60000 (35.03%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.0051,                   Accuracy: 14889/60000 (24.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.6717,                   Accuracy: 10960/60000 (18.27%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.9870,                   Accuracy: 10636/60000 (17.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.1617,                   Accuracy: 10212/60000 (17.02%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1623,                   Accuracy: 9824/60000 (16.37%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.2642,                   Accuracy: 10957/60000 (18.26%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2172,                   Accuracy: 13877/60000 (23.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.0449,                   Accuracy: 17304/60000 (28.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9392,                   Accuracy: 21760/60000 (36.27%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0254,                   Accuracy: 25371/60000 (42.28%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2520,                   Accuracy: 27938/60000 (46.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.5790,                   Accuracy: 28464/60000 (47.44%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.3545,                   Accuracy: 29061/60000 (48.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.2103,                   Accuracy: 27614/60000 (46.02%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.1572,                   Accuracy: 24108/60000 (40.18%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1912,                   Accuracy: 20758/60000 (34.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3998,                   Accuracy: 17110/60000 (28.52%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7499,                   Accuracy: 13760/60000 (22.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.0097,                   Accuracy: 11525/60000 (19.21%)
-= Testing Rotation 260 =-
Test set: Average loss: 7.0183,                   Accuracy: 9910/60000 (16.52%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.8931,                   Accuracy: 9084/60000 (15.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.6502,                   Accuracy: 8389/60000 (13.98%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.0217,                   Accuracy: 8796/60000 (14.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0662,                   Accuracy: 11611/60000 (19.35%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7669,                   Accuracy: 19900/60000 (33.17%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2722,                   Accuracy: 32083/60000 (53.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0145,                   Accuracy: 45418/60000 (75.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3122,                   Accuracy: 54860/60000 (91.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0910,                   Accuracy: 58410/60000 (97.35%)
{0: tensor(98.3433), 10: tensor(97.4200), 20: tensor(93.4750), 30: tensor(83.7567), 40: tensor(67.3283), 50: tensor(49.5333), 60: tensor(35.0267), 70: tensor(24.8150), 80: tensor(18.2667), 90: tensor(17.7267), 100: tensor(17.0200), 110: tensor(16.3733), 120: tensor(18.2617), 130: tensor(23.1283), 140: tensor(28.8400), 150: tensor(36.2667), 160: tensor(42.2850), 170: tensor(46.5633), 180: tensor(47.4400), 190: tensor(48.4350), 200: tensor(46.0233), 210: tensor(40.1800), 220: tensor(34.5967), 230: tensor(28.5167), 240: tensor(22.9333), 250: tensor(19.2083), 260: tensor(16.5167), 270: tensor(15.1400), 280: tensor(13.9817), 290: tensor(14.6600), 300: tensor(19.3517), 310: tensor(33.1667), 320: tensor(53.4717), 330: tensor(75.6967), 340: tensor(91.4333), 350: tensor(97.3500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=35, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.0813,                   Accuracy: 1328/2000.0 (66.40%)



-= Testing valid =-
Test set: Average loss: 0.8447,                   Accuracy: 1520/2000.0 (76.00%)



-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1550,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.2311,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 10 train accuracy: 97.86%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 98.84%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.29%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.62%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0214,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0514,                   Accuracy: 59103/60000 (98.50%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0855,                   Accuracy: 58524/60000 (97.54%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2120,                   Accuracy: 56461/60000 (94.10%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5761,                   Accuracy: 50591/60000 (84.32%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4199,                   Accuracy: 39195/60000 (65.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5484,                   Accuracy: 27384/60000 (45.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6361,                   Accuracy: 18505/60000 (30.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5135,                   Accuracy: 13215/60000 (22.02%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9756,                   Accuracy: 10448/60000 (17.41%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.2616,                   Accuracy: 10272/60000 (17.12%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2893,                   Accuracy: 10384/60000 (17.31%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.4067,                   Accuracy: 11067/60000 (18.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.3946,                   Accuracy: 12575/60000 (20.96%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.4447,                   Accuracy: 14686/60000 (24.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.5070,                   Accuracy: 17227/60000 (28.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6985,                   Accuracy: 20678/60000 (34.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2406,                   Accuracy: 23916/60000 (39.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.6160,                   Accuracy: 25462/60000 (42.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.8468,                   Accuracy: 25998/60000 (43.33%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7741,                   Accuracy: 26488/60000 (44.15%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.6827,                   Accuracy: 25800/60000 (43.00%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.2846,                   Accuracy: 23457/60000 (39.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1483,                   Accuracy: 19995/60000 (33.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.1168,                   Accuracy: 16834/60000 (28.06%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1919,                   Accuracy: 14213/60000 (23.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.3642,                   Accuracy: 11976/60000 (19.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.2430,                   Accuracy: 10542/60000 (17.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.1000,                   Accuracy: 10013/60000 (16.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.7667,                   Accuracy: 9851/60000 (16.42%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3227,                   Accuracy: 9964/60000 (16.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4632,                   Accuracy: 12072/60000 (20.12%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5498,                   Accuracy: 17787/60000 (29.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2351,                   Accuracy: 29236/60000 (48.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9971,                   Accuracy: 43853/60000 (73.09%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2846,                   Accuracy: 54925/60000 (91.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0852,                   Accuracy: 58475/60000 (97.46%)
{0: tensor(98.5050), 10: tensor(97.5400), 20: tensor(94.1017), 30: tensor(84.3183), 40: tensor(65.3250), 50: tensor(45.6400), 60: tensor(30.8417), 70: tensor(22.0250), 80: tensor(17.4133), 90: tensor(17.1200), 100: tensor(17.3067), 110: tensor(18.4450), 120: tensor(20.9583), 130: tensor(24.4767), 140: tensor(28.7117), 150: tensor(34.4633), 160: tensor(39.8600), 170: tensor(42.4367), 180: tensor(43.3300), 190: tensor(44.1467), 200: tensor(43.), 210: tensor(39.0950), 220: tensor(33.3250), 230: tensor(28.0567), 240: tensor(23.6883), 250: tensor(19.9600), 260: tensor(17.5700), 270: tensor(16.6883), 280: tensor(16.4183), 290: tensor(16.6067), 300: tensor(20.1200), 310: tensor(29.6450), 320: tensor(48.7267), 330: tensor(73.0883), 340: tensor(91.5417), 350: tensor(97.4583)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=36, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6298,                   Accuracy: 904/2000.0 (45.20%)



-= Testing valid =-
Test set: Average loss: 0.8896,                   Accuracy: 1427/2000.0 (71.35%)



-= Testing valid =-
Test set: Average loss: 0.1980,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.4304,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.1385,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 10 train accuracy: 97.78%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 98.84%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.59%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0485,                   Accuracy: 59180/60000 (98.63%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0808,                   Accuracy: 58671/60000 (97.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2095,                   Accuracy: 56733/60000 (94.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6476,                   Accuracy: 50127/60000 (83.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5414,                   Accuracy: 39349/60000 (65.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7501,                   Accuracy: 27936/60000 (46.56%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.0431,                   Accuracy: 18254/60000 (30.42%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9126,                   Accuracy: 12577/60000 (20.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4779,                   Accuracy: 10167/60000 (16.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7993,                   Accuracy: 10390/60000 (17.32%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.7610,                   Accuracy: 11049/60000 (18.42%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9910,                   Accuracy: 11823/60000 (19.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1964,                   Accuracy: 13387/60000 (22.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.1879,                   Accuracy: 16003/60000 (26.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.3269,                   Accuracy: 19142/60000 (31.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.5755,                   Accuracy: 22477/60000 (37.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 7.0433,                   Accuracy: 24757/60000 (41.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.4570,                   Accuracy: 25750/60000 (42.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.8590,                   Accuracy: 26289/60000 (43.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.7864,                   Accuracy: 25867/60000 (43.11%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.7137,                   Accuracy: 24166/60000 (40.28%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.3893,                   Accuracy: 20984/60000 (34.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.2515,                   Accuracy: 17289/60000 (28.82%)
-= Testing Rotation 230 =-
Test set: Average loss: 7.2116,                   Accuracy: 14841/60000 (24.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.9894,                   Accuracy: 12896/60000 (21.49%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7747,                   Accuracy: 11953/60000 (19.92%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5633,                   Accuracy: 11383/60000 (18.97%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4449,                   Accuracy: 10440/60000 (17.40%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9868,                   Accuracy: 9565/60000 (15.94%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4014,                   Accuracy: 10105/60000 (16.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6768,                   Accuracy: 12925/60000 (21.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4505,                   Accuracy: 20382/60000 (33.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0437,                   Accuracy: 32650/60000 (54.42%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8840,                   Accuracy: 46095/60000 (76.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2614,                   Accuracy: 55326/60000 (92.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0795,                   Accuracy: 58619/60000 (97.70%)
{0: tensor(98.6333), 10: tensor(97.7850), 20: tensor(94.5550), 30: tensor(83.5450), 40: tensor(65.5817), 50: tensor(46.5600), 60: tensor(30.4233), 70: tensor(20.9617), 80: tensor(16.9450), 90: tensor(17.3167), 100: tensor(18.4150), 110: tensor(19.7050), 120: tensor(22.3117), 130: tensor(26.6717), 140: tensor(31.9033), 150: tensor(37.4617), 160: tensor(41.2617), 170: tensor(42.9167), 180: tensor(43.8150), 190: tensor(43.1117), 200: tensor(40.2767), 210: tensor(34.9733), 220: tensor(28.8150), 230: tensor(24.7350), 240: tensor(21.4933), 250: tensor(19.9217), 260: tensor(18.9717), 270: tensor(17.4000), 280: tensor(15.9417), 290: tensor(16.8417), 300: tensor(21.5417), 310: tensor(33.9700), 320: tensor(54.4167), 330: tensor(76.8250), 340: tensor(92.2100), 350: tensor(97.6983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=37, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5912,                   Accuracy: 501/2000.0 (25.05%)



-= Testing valid =-
Test set: Average loss: 1.0317,                   Accuracy: 1243/2000.0 (62.15%)



-= Testing valid =-
Test set: Average loss: 0.4002,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.1859,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1845,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 10 train accuracy: 97.90%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 20 train accuracy: 98.81%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 30 train accuracy: 99.26%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.47%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.56%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0545,                   Accuracy: 59035/60000 (98.39%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0786,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1884,                   Accuracy: 56840/60000 (94.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5338,                   Accuracy: 51484/60000 (85.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2338,                   Accuracy: 42699/60000 (71.17%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.1772,                   Accuracy: 32361/60000 (53.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.2868,                   Accuracy: 22166/60000 (36.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.1169,                   Accuracy: 15876/60000 (26.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.8045,                   Accuracy: 11664/60000 (19.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.6885,                   Accuracy: 9264/60000 (15.44%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8456,                   Accuracy: 9198/60000 (15.33%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.5917,                   Accuracy: 9796/60000 (16.33%)
-= Testing Rotation 120 =-
Test set: Average loss: 7.0643,                   Accuracy: 11347/60000 (18.91%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.9883,                   Accuracy: 14642/60000 (24.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.8401,                   Accuracy: 18522/60000 (30.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.6631,                   Accuracy: 22326/60000 (37.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.6829,                   Accuracy: 25143/60000 (41.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.8745,                   Accuracy: 26721/60000 (44.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.4472,                   Accuracy: 26679/60000 (44.47%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.1201,                   Accuracy: 26567/60000 (44.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.9673,                   Accuracy: 25307/60000 (42.18%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.8932,                   Accuracy: 22563/60000 (37.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.5027,                   Accuracy: 18779/60000 (31.30%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3503,                   Accuracy: 15828/60000 (26.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.2291,                   Accuracy: 13161/60000 (21.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0704,                   Accuracy: 11356/60000 (18.93%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.9095,                   Accuracy: 10749/60000 (17.92%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.2408,                   Accuracy: 9594/60000 (15.99%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.8165,                   Accuracy: 8573/60000 (14.29%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7239,                   Accuracy: 8837/60000 (14.73%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.3695,                   Accuracy: 11063/60000 (18.44%)
-= Testing Rotation 310 =-
Test set: Average loss: 4.2441,                   Accuracy: 18411/60000 (30.68%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.8267,                   Accuracy: 29425/60000 (49.04%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.4431,                   Accuracy: 42017/60000 (70.03%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.4683,                   Accuracy: 52972/60000 (88.29%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1208,                   Accuracy: 57943/60000 (96.57%)
{0: tensor(98.3917), 10: tensor(97.7367), 20: tensor(94.7333), 30: tensor(85.8067), 40: tensor(71.1650), 50: tensor(53.9350), 60: tensor(36.9433), 70: tensor(26.4600), 80: tensor(19.4400), 90: tensor(15.4400), 100: tensor(15.3300), 110: tensor(16.3267), 120: tensor(18.9117), 130: tensor(24.4033), 140: tensor(30.8700), 150: tensor(37.2100), 160: tensor(41.9050), 170: tensor(44.5350), 180: tensor(44.4650), 190: tensor(44.2783), 200: tensor(42.1783), 210: tensor(37.6050), 220: tensor(31.2983), 230: tensor(26.3800), 240: tensor(21.9350), 250: tensor(18.9267), 260: tensor(17.9150), 270: tensor(15.9900), 280: tensor(14.2883), 290: tensor(14.7283), 300: tensor(18.4383), 310: tensor(30.6850), 320: tensor(49.0417), 330: tensor(70.0283), 340: tensor(88.2867), 350: tensor(96.5717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=38, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.0410,                   Accuracy: 1323/2000.0 (66.15%)



-= Testing valid =-
Test set: Average loss: 0.3843,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.4739,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.1783,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1696,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 97.75%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 98.90%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.22%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0579,                   Accuracy: 59008/60000 (98.35%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0809,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1867,                   Accuracy: 56983/60000 (94.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5582,                   Accuracy: 51141/60000 (85.24%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3303,                   Accuracy: 41280/60000 (68.80%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4759,                   Accuracy: 30489/60000 (50.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8835,                   Accuracy: 21334/60000 (35.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.7696,                   Accuracy: 15907/60000 (26.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5043,                   Accuracy: 12656/60000 (21.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.1191,                   Accuracy: 11688/60000 (19.48%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.1149,                   Accuracy: 12028/60000 (20.05%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1019,                   Accuracy: 11559/60000 (19.26%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1778,                   Accuracy: 11693/60000 (19.49%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0195,                   Accuracy: 14509/60000 (24.18%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8277,                   Accuracy: 18117/60000 (30.19%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6692,                   Accuracy: 21406/60000 (35.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.7428,                   Accuracy: 23966/60000 (39.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.0693,                   Accuracy: 25317/60000 (42.19%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6956,                   Accuracy: 25961/60000 (43.27%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5473,                   Accuracy: 26542/60000 (44.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.3868,                   Accuracy: 25224/60000 (42.04%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3157,                   Accuracy: 22319/60000 (37.20%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2751,                   Accuracy: 19187/60000 (31.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4234,                   Accuracy: 16405/60000 (27.34%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6527,                   Accuracy: 14005/60000 (23.34%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6812,                   Accuracy: 12401/60000 (20.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6751,                   Accuracy: 10802/60000 (18.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.9773,                   Accuracy: 9345/60000 (15.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.5665,                   Accuracy: 8960/60000 (14.93%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.1278,                   Accuracy: 8875/60000 (14.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.3508,                   Accuracy: 11427/60000 (19.05%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.9405,                   Accuracy: 19376/60000 (32.29%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3994,                   Accuracy: 31280/60000 (52.13%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0563,                   Accuracy: 44750/60000 (74.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3068,                   Accuracy: 54798/60000 (91.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0850,                   Accuracy: 58486/60000 (97.48%)
{0: tensor(98.3467), 10: tensor(97.7267), 20: tensor(94.9717), 30: tensor(85.2350), 40: tensor(68.8000), 50: tensor(50.8150), 60: tensor(35.5567), 70: tensor(26.5117), 80: tensor(21.0933), 90: tensor(19.4800), 100: tensor(20.0467), 110: tensor(19.2650), 120: tensor(19.4883), 130: tensor(24.1817), 140: tensor(30.1950), 150: tensor(35.6767), 160: tensor(39.9433), 170: tensor(42.1950), 180: tensor(43.2683), 190: tensor(44.2367), 200: tensor(42.0400), 210: tensor(37.1983), 220: tensor(31.9783), 230: tensor(27.3417), 240: tensor(23.3417), 250: tensor(20.6683), 260: tensor(18.0033), 270: tensor(15.5750), 280: tensor(14.9333), 290: tensor(14.7917), 300: tensor(19.0450), 310: tensor(32.2933), 320: tensor(52.1333), 330: tensor(74.5833), 340: tensor(91.3300), 350: tensor(97.4767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=39, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3058,                   Accuracy: 309/2000.0 (15.45%)



-= Testing valid =-
Test set: Average loss: 0.2026,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2353,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.3656,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1606,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.2074,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 97.86%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 20 train accuracy: 98.99%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.34%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0179,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0181,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 40 train accuracy: 99.56%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0169,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0178,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0179,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0172,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0180,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0171,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0162,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0512,                   Accuracy: 59150/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0817,                   Accuracy: 58669/60000 (97.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2112,                   Accuracy: 56678/60000 (94.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6717,                   Accuracy: 49907/60000 (83.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5902,                   Accuracy: 39270/60000 (65.45%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7988,                   Accuracy: 28563/60000 (47.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.0792,                   Accuracy: 19943/60000 (33.24%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9778,                   Accuracy: 14673/60000 (24.45%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5545,                   Accuracy: 11496/60000 (19.16%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.9278,                   Accuracy: 9969/60000 (16.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9619,                   Accuracy: 10141/60000 (16.90%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1507,                   Accuracy: 9901/60000 (16.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1861,                   Accuracy: 10656/60000 (17.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.1748,                   Accuracy: 13204/60000 (22.01%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9743,                   Accuracy: 16801/60000 (28.00%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.8569,                   Accuracy: 21120/60000 (35.20%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1460,                   Accuracy: 25048/60000 (41.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4367,                   Accuracy: 26954/60000 (44.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6896,                   Accuracy: 27311/60000 (45.52%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.6052,                   Accuracy: 27166/60000 (45.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.6575,                   Accuracy: 25580/60000 (42.63%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4760,                   Accuracy: 22385/60000 (37.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.4991,                   Accuracy: 19897/60000 (33.16%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.5220,                   Accuracy: 17309/60000 (28.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5879,                   Accuracy: 14825/60000 (24.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7270,                   Accuracy: 12897/60000 (21.50%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6666,                   Accuracy: 11344/60000 (18.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.8531,                   Accuracy: 9462/60000 (15.77%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.5503,                   Accuracy: 9133/60000 (15.22%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.3575,                   Accuracy: 8540/60000 (14.23%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.6586,                   Accuracy: 10393/60000 (17.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 4.3240,                   Accuracy: 18087/60000 (30.15%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.6203,                   Accuracy: 30650/60000 (51.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.1598,                   Accuracy: 44523/60000 (74.21%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3420,                   Accuracy: 54709/60000 (91.18%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0821,                   Accuracy: 58600/60000 (97.67%)
{0: tensor(98.5833), 10: tensor(97.7817), 20: tensor(94.4633), 30: tensor(83.1783), 40: tensor(65.4500), 50: tensor(47.6050), 60: tensor(33.2383), 70: tensor(24.4550), 80: tensor(19.1600), 90: tensor(16.6150), 100: tensor(16.9017), 110: tensor(16.5017), 120: tensor(17.7600), 130: tensor(22.0067), 140: tensor(28.0017), 150: tensor(35.2000), 160: tensor(41.7467), 170: tensor(44.9233), 180: tensor(45.5183), 190: tensor(45.2767), 200: tensor(42.6333), 210: tensor(37.3083), 220: tensor(33.1617), 230: tensor(28.8483), 240: tensor(24.7083), 250: tensor(21.4950), 260: tensor(18.9067), 270: tensor(15.7700), 280: tensor(15.2217), 290: tensor(14.2333), 300: tensor(17.3217), 310: tensor(30.1450), 320: tensor(51.0833), 330: tensor(74.2050), 340: tensor(91.1817), 350: tensor(97.6667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=40, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3975,                   Accuracy: 827/2000.0 (41.35%)



-= Testing valid =-
Test set: Average loss: 0.4445,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2414,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.3095,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.1839,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1609,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 10 train accuracy: 97.43%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 20 train accuracy: 98.93%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.25%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.51%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.56%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0533,                   Accuracy: 59070/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0941,                   Accuracy: 58431/60000 (97.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2201,                   Accuracy: 56356/60000 (93.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6219,                   Accuracy: 49918/60000 (83.20%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4355,                   Accuracy: 39928/60000 (66.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5233,                   Accuracy: 30100/60000 (50.17%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6085,                   Accuracy: 21548/60000 (35.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5576,                   Accuracy: 15498/60000 (25.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1827,                   Accuracy: 12095/60000 (20.16%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.5982,                   Accuracy: 10571/60000 (17.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9711,                   Accuracy: 9485/60000 (15.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1062,                   Accuracy: 9794/60000 (16.32%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0814,                   Accuracy: 11299/60000 (18.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.1063,                   Accuracy: 14439/60000 (24.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.0254,                   Accuracy: 17845/60000 (29.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0842,                   Accuracy: 21590/60000 (35.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3584,                   Accuracy: 24430/60000 (40.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5891,                   Accuracy: 26442/60000 (44.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.8291,                   Accuracy: 26932/60000 (44.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5185,                   Accuracy: 27139/60000 (45.23%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.3825,                   Accuracy: 25791/60000 (42.99%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.1673,                   Accuracy: 22781/60000 (37.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1726,                   Accuracy: 19440/60000 (32.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4114,                   Accuracy: 17101/60000 (28.50%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5174,                   Accuracy: 14907/60000 (24.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7422,                   Accuracy: 12547/60000 (20.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5613,                   Accuracy: 11950/60000 (19.92%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.5142,                   Accuracy: 10546/60000 (17.58%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.3834,                   Accuracy: 9065/60000 (15.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6459,                   Accuracy: 9159/60000 (15.27%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5861,                   Accuracy: 12469/60000 (20.78%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3028,                   Accuracy: 20998/60000 (35.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0011,                   Accuracy: 33193/60000 (55.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9448,                   Accuracy: 45551/60000 (75.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3104,                   Accuracy: 54556/60000 (90.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0886,                   Accuracy: 58400/60000 (97.33%)
{0: tensor(98.4500), 10: tensor(97.3850), 20: tensor(93.9267), 30: tensor(83.1967), 40: tensor(66.5467), 50: tensor(50.1667), 60: tensor(35.9133), 70: tensor(25.8300), 80: tensor(20.1583), 90: tensor(17.6183), 100: tensor(15.8083), 110: tensor(16.3233), 120: tensor(18.8317), 130: tensor(24.0650), 140: tensor(29.7417), 150: tensor(35.9833), 160: tensor(40.7167), 170: tensor(44.0700), 180: tensor(44.8867), 190: tensor(45.2317), 200: tensor(42.9850), 210: tensor(37.9683), 220: tensor(32.4000), 230: tensor(28.5017), 240: tensor(24.8450), 250: tensor(20.9117), 260: tensor(19.9167), 270: tensor(17.5767), 280: tensor(15.1083), 290: tensor(15.2650), 300: tensor(20.7817), 310: tensor(34.9967), 320: tensor(55.3217), 330: tensor(75.9183), 340: tensor(90.9267), 350: tensor(97.3333)}
